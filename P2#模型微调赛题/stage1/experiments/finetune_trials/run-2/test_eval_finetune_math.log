/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
********************** infer list len:  200
2024-07-26 15:57:13,245 - mindformers[mindformers/trainer/trainer.py:919] - INFO - Load configs in /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml to build trainer.
2024-07-26 15:57:13,246 - mindformers[mindformers/trainer/trainer.py:949] - INFO - ..........Init Config..........
2024-07-26 15:57:13,246 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': True, 'select_recompute': False, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}
2024-07-26 15:57:13,247 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 1, 'model_parallel': 1, 'pipeline_stage': 1, 'use_seq_parallel': False, 'micro_batch_num': 1, 'vocab_emb_dp': True, 'gradient_aggregation_group': 4}
2024-07-26 15:57:13,247 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/research/output'
2024-07-26 15:57:13,248 - mindformers[mindformers/tools/utils.py:168] - INFO - set strategy path to './output/strategy/ckpt_strategy_rank_0.ckpt'
2024-07-26 15:57:13,248 - mindformers[mindformers/trainer/base_trainer.py:85] - INFO - Now Running Task is: text_generation, Model is: llama3_8b
2024-07-26 15:57:13,248 - mindformers[mindformers/trainer/base_trainer.py:111] - WARNING - Input model name is not in the supported list or unspecified.
2024-07-26 15:57:13,248 - mindformers[mindformers/trainer/base_trainer.py:112] - WARNING - See the list of supported task and model name: ['baichuan2_13b', 'baichuan2_7b', 'baichuan_7b', 'bloom_176b', 'bloom_560m', 'bloom_65b', 'bloom_7.1b', 'codegeex2_6b', 'codellama_34b', 'common', 'deepseek_33b', 'glm2_6b', 'glm2_6b_lora', 'glm2_6b_ptuning2', 'glm3_6b', 'glm_6b', 'glm_6b_chat', 'glm_6b_lora', 'glm_6b_lora_chat', 'gpt2', 'gpt2_13b', 'gpt2_52b', 'gpt2_lora', 'gpt2_xl', 'gpt2_xl_lora', 'internlm_7b', 'internlm_7b_lora', 'llama2_13b', 'llama2_70b', 'llama2_7b', 'llama_13b', 'llama_65b', 'llama_7b', 'llama_7b_lora', 'pangualpha_13b', 'pangualpha_2_6b', 'qwen_7b', 'qwen_7b_lora', 'skywork_13b', 'yi_34b', 'yi_6b', 'ziya_13b']
2024-07-26 15:57:13,249 - mindformers[mindformers/trainer/base_trainer.py:113] - WARNING - The default model config: /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml will now be used for the text_generation task 
2024-07-26 15:57:13,249 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-07-26 15:57:13,249 - mindformers[mindformers/trainer/trainer.py:335] - INFO - ==========Trainer Init Success!==========
2024-07-26 15:57:13,249 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-07-26 15:57:13,249 - mindformers[mindformers/trainer/base_trainer.py:213] - INFO - The current parallel mode is stand_alone, batch size per card will not be changed: batch_size_per_card = 1
2024-07-26 15:57:13,250 - mindformers[mindformers/trainer/base_trainer.py:217] - INFO - global_batch_size = batch_size_per_card * device_num * gradient_accumulation_steps = 1 = 1 * 1 * 1
2024-07-26 15:57:13,250 - mindformers[mindformers/trainer/base_trainer.py:226] - INFO - parallel_config will be change to default config: [ParallelConfig]
_recompute:[ParallelConfig]
_recompute:True
_select_recompute:False
_select_comm_recompute:False
_parallel_optimizer_comm_recompute:False
_mp_comm_recompute:True
_recompute_slice_activation:True

select_recompute:False
use_seq_parallel:False
_optimizer_shard:None
_gradient_aggregation_group:4
_embed_dp_mp_config:[ParallelConfig]
_dp_mp_config:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_vocab_emb_dp:True
use_seq_parallel:False
select_recompute:False

_pp_config:[ParallelConfig]
_pipeline_stage:1
_micro_batch_num:1

_moe_config:[ParallelConfig]
_dpmp:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_expert_parallel:1
use_seq_parallel:False
select_recompute:False

.
2024-07-26 15:57:13,251 - mindformers[mindformers/trainer/base_trainer.py:387] - INFO - .........Build Network From Config..........
2024-07-26 15:57:13,251 - mindformers[mindformers/version_control.py:61] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1
2024-07-26 15:57:13,252 - mindformers[mindformers/version_control.py:65] - INFO - 
The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: 
export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.
2024-07-26 15:57:13,252 - mindformers[mindformers/version_control.py:71] - INFO - The Cell Reuse compilation acceleration feature does not support single-card mode.This feature is disabled by default. ENABLE_CELL_REUSE=1 does not take effect.
2024-07-26 15:57:13,252 - mindformers[mindformers/version_control.py:74] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.
[WARNING] DEVICE(1988,ffff844c1010,python):2024-07-26-15:57:13.516.388 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:95] Initialize] Reserved memory size for other components(536870912) is less than recommend size(1891517952), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory'
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:57:35.730.060 [mindspore/ops/primitive.py:203] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. 
If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL)
2024-07-26 15:57:42,266 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:57:42.267.688 [mindspore/common/_decorator.py:40] 'Parameter' is deprecated from version 2.3 and will be removed in a future version, use 'add_pipeline_stage' instead.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:57:42.267.845 [mindspore/common/parameter.py:806] This interface may be deleted in the future.
2024-07-26 15:57:42,378 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:42,490 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:42,602 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:42,714 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:42,826 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:42,937 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:43,050 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:43,162 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:43,276 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 15:57:53,097 - mindformers[mindformers/models/modeling_utils.py:1438] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
2024-07-26 15:57:53,098 - mindformers[mindformers/models/modeling_utils.py:591] - INFO - Set jit config for jit level:O0 and infer boost:on.
2024-07-26 15:57:56,145 - mindformers[mindformers/models/modeling_utils.py:1438] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
[INFO] 2024-07-26 15:57:56,148 [1988] [SDK] : Start to freeze model for delta, mode: lora, include list: None, exclude list: None
[INFO] 2024-07-26 15:57:56,148 [1988] [SDK] : Start to freeze model, include list: ['*'], exclude list: ['*mindpet_delta_lora*']
[INFO] 2024-07-26 15:57:56,156 [1988] [SDK] : End to freeze model.
[INFO] 2024-07-26 15:57:56,156 [1988] [SDK] : End to freeze model for delta.
2024-07-26 15:57:56,156 - mindformers[mindformers/models/modeling_utils.py:591] - INFO - Set jit config for jit level:O0 and infer boost:on.
2024-07-26 15:57:56,171 - mindformers[mindformers/trainer/base_trainer.py:543] - INFO - Network Parameters: 3407872.
2024-07-26 15:57:57,236 - mindformers[mindformers/trainer/utils.py:736] - INFO - ............Start load checkpoint from checkpoint............
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:59:34.180.329 [mindspore/train/serialization.py:195] The type of model.tok_embeddings.embedding_weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:59:52.107.380 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:59:52.844.967 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:59:53.154.290 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:59:53.999.952 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-15:59:57.499.45 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:01.310.136 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:05.552.963 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:08.150.139 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:08.854.963 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:09.154.081 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:09.958.977 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:12.956.129 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:17.253.282 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:21.540.173 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:24.567.11 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:24.753.790 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:25.517.20 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:25.863.384 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:28.783.742 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:33.416.14 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:37.370.501 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:39.978.163 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:40.687.951 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:41.717.5 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:41.815.822 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:44.749.377 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:48.992.519 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:53.222.323 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:55.827.636 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:56.527.148 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:56.830.739 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:00:57.642.655 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:00.610.926 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:04.972.081 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:09.196.524 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:11.782.985 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:12.489.574 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:12.797.016 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:13.602.763 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:16.526.524 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:20.854.450 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:25.169.992 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:27.748.875 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:28.478.687 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:28.776.010 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:29.589.622 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:32.559.617 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:36.852.324 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:41.140.162 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:43.752.869 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:44.478.908 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:44.779.679 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:45.615.068 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:48.620.676 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:52.916.426 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:57.173.061 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:01:59.751.238 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:00.449.932 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:00.753.503 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:01.566.313 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:04.507.189 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:08.855.364 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:13.363.016 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:15.952.782 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:16.662.902 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:16.969.949 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:17.775.528 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:20.735.785 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:25.611.38 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:29.298.352 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:31.914.012 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:32.638.887 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:32.938.679 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:33.776.521 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:36.759.741 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:41.599.27 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:45.332.809 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:47.897.159 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:48.600.426 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:48.901.774 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:49.708.359 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:52.697.008 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:02:57.492.94 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:01.353.904 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:03.942.952 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:04.659.842 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:04.961.230 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:05.803.042 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:08.785.244 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:13.695.51 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:17.377.139 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:20.120.48 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:20.709.357 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:21.266.09 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:21.826.848 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:24.801.800 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:29.891.72 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:33.375.667 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:35.933.783 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:36.633.031 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:36.933.303 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:37.744.462 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:40.762.859 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:45.114.951 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:49.398.901 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:51.972.886 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:52.683.121 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:52.982.856 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:53.798.338 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:03:56.754.145 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:01.624.65 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:05.330.169 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:07.929.013 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:08.654.418 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:08.951.256 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:09.790.674 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:12.803.363 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:17.133.342 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:21.396.132 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:23.977.491 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:24.695.840 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:25.132.0 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:25.811.060 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:28.804.186 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:33.147.663 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:37.500.224 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:40.826.76 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:40.787.020 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:41.106.094 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:41.969.655 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:44.929.218 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:49.240.855 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:53.537.785 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:56.244.289 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:56.959.255 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:57.269.973 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:04:58.106.495 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:01.120.584 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:05.475.920 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:09.774.049 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:12.336.735 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:13.532.46 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:13.352.381 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:14.180.519 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:17.167.153 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:21.449.332 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:25.809.130 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:28.413.964 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:29.138.403 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:29.438.327 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:30.257.509 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:33.270.746 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:37.569.304 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:41.927.129 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:44.524.367 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:45.222.151 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:45.524.123 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:46.337.798 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:49.294.609 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:53.640.273 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:05:57.959.020 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:00.562.345 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:01.284.698 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:01.582.047 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:02.409.737 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:05.409.027 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:09.718.790 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:13.990.651 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:16.559.210 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:17.289.761 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:17.587.832 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:18.460.301 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:21.494.250 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:25.799.193 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:30.131.128 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:32.769.047 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:33.482.685 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:33.785.915 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:34.615.724 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:37.605.161 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:41.878.369 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:46.234.879 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:48.823.130 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:49.546.870 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:49.845.607 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:50.670.361 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:53.714.519 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:06:58.149.32 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:02.409.465 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:04.989.489 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:05.702.653 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:06.811. [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:06.816.900 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:09.787.012 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:14.139.142 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:18.473.943 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:21.800.76 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:21.782.018 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:22.103.376 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:22.940.573 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:25.920.465 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:30.259.292 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:34.557.947 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:37.124.447 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:37.830.448 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:38.130.157 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:38.956.193 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:42.928.99 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:46.423.389 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:50.772.661 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:53.364.357 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:54.998.82 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:54.397.830 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:55.250.364 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:07:58.249.407 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:02.560.946 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:06.887.553 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:09.530.759 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:10.257.923 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:10.557.252 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:11.396.749 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:14.404.463 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:18.772.107 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:23.140.587 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:08:47.390.548 [mindspore/train/serialization.py:195] The type of lm_head.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:09:04.611.260 [mindspore/train/serialization.py:1456] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.
[WARNING] ME(1988:281472901320720,MainProcess):2024-07-26-16:09:04.611.720 [mindspore/train/serialization.py:1460] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded.
2024-07-26 16:09:04,611 - mindformers[mindformers/trainer/utils.py:767] - INFO - Network parameters are not loaded: (['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'], [])
{'auto_trans_ckpt': False,
 'auto_tune': False,
 'autotune_per_step': 10,
 'callbacks': [OrderedDict([('type', 'MFLossMonitor')]),
               OrderedDict([('type', 'CheckpointMointor'),
                            ('prefix', 'llama3_8b'),
                            ('save_checkpoint_steps', 1400),
                            ('integrated_save', False),
                            ('async_save', False)]),
               OrderedDict([('type', 'ObsMonitor')])],
 'context': {'device_id': 0,
             'device_target': 'Ascend',
             'enable_graph_kernel': False,
             'graph_kernel_flags': '--disable_expand_ops=Softmax,Dropout '
                                   '--enable_parallel_fusion=true '
                                   '--reduce_fuse_depth=8 '
                                   '--enable_auto_tensor_inplace=true',
             'max_call_depth': 10000,
             'runtime_num_threads': 1,
             'save_graphs': False,
             'save_graphs_path': './graph'},
 'device_num': 1,
 'do_eval': False,
 'eval_callbacks': [OrderedDict([('type', 'ObsMonitor')])],
 'eval_dataset': {'auto_tune': False,
                  'autotune_per_step': 10,
                  'batch_size': 1,
                  'data_loader': {'dataset_dir': '',
                                  'shuffle': False,
                                  'type': 'MindDataset'},
                  'do_eval': True,
                  'drop_remainder': False,
                  'filepath_prefix': './autotune',
                  'input_columns': ['input_ids'],
                  'num_parallel_workers': 1,
                  'numa_enable': False,
                  'output_columns': ['input_ids'],
                  'prefetch_size': 1,
                  'profile': False,
                  'python_multiprocessing': False,
                  'repeat': 1,
                  'seed': 0},
 'eval_dataset_task': {'dataset_config': {'auto_tune': False,
                                          'autotune_per_step': 10,
                                          'batch_size': 1,
                                          'data_loader': {'dataset_dir': '',
                                                          'shuffle': False,
                                                          'type': 'MindDataset'},
                                          'do_eval': True,
                                          'drop_remainder': False,
                                          'filepath_prefix': './autotune',
                                          'input_columns': ['input_ids'],
                                          'num_parallel_workers': 1,
                                          'numa_enable': False,
                                          'output_columns': ['input_ids'],
                                          'prefetch_size': 1,
                                          'profile': False,
                                          'python_multiprocessing': False,
                                          'repeat': 1,
                                          'seed': 0},
                       'type': 'CausalLanguageModelDataset'},
 'filepath_prefix': './autotune',
 'init_start_profile': False,
 'layer_decay': 0.65,
 'layer_scale': False,
 'load_checkpoint': '/home/ma-user/work/mindformers/research/output/checkpoint_network/rank_0/llama3_8b_rank_0-network.ckpt',
 'local_rank': 0,
 'lr_scale_factor': 256,
 'metric': [{'type': 'PerplexityMetric'}],
 'micro_batch_interleave_num': 1,
 'model': {'arch': {'type': 'LlamaForCausalLM'},
           'model_config': {'batch_size': 1,
                            'block_size': 64,
                            'bos_token_id': 128000,
                            'checkpoint_name_or_path': None,
                            'compute_dtype': 'float16',
                            'do_sample': False,
                            'eos_token_id': 128001,
                            'extend_method': 'None',
                            'fine_grain_interleave': 1,
                            'hidden_size': 4096,
                            'ignore_token_id': -100,
                            'intermediate_size': 14336,
                            'is_dynamic': False,
                            'layernorm_compute_type': 'float32',
                            'max_decode_length': 128,
                            'max_new_tokens': 128,
                            'min_new_tokens': 1,
                            'n_kv_heads': 8,
                            'num_heads': 32,
                            'num_layers': 32,
                            'offset': 0,
                            'pad_token_id': 128002,
                            'param_init_type': 'float16',
                            'pet_config': {'lora_alpha': 16,
                                           'lora_dropout': 0.0,
                                           'lora_rank': 8,
                                           'target_modules': '.*wq|.*wv'},
                            'repetition_penalty': 1,
                            'rms_norm_eps': 1e-05,
                            'rotary_dtype': 'float32',
                            'scaling_factor': 1.0,
                            'seq_length': 256,
                            'softmax_compute_type': 'float32',
                            'theta': 500000,
                            'top_k': 3,
                            'top_p': 1,
                            'type': 'LlamaConfig',
                            'use_flash_attention': True,
                            'use_past': True,
                            'vocab_size': 128256}},
 'moe_config': <mindformers.modules.transformer.moe.MoEConfig object at 0xfffe75a8ecd0>,
 'only_save_strategy': False,
 'output_dir': './output',
 'parallel': {'enable_alltoall': False,
              'enable_parallel_optimizer': True,
              'full_batch': True,
              'gradients_mean': False,
              'parallel_mode': 1,
              'parallel_optimizer_config': {'gradient_accumulation_shard': False,
                                            'parallel_optimizer_threshold': 64},
              'search_mode': 'sharding_propagation',
              'strategy_ckpt_config': {'only_trainable_params': False,
                                       'save_file': './ckpt_strategy.ckpt'},
              'strategy_ckpt_save_file': './output/strategy/ckpt_strategy_rank_0.ckpt'},
 'parallel_config': <mindformers.modules.transformer.transformer.TransformerOpParallelConfig object at 0xfffe04156790>,
 'processor': {'return_tensors': 'ms',
               'tokenizer': {'model_max_length': 8192,
                             'pad_token': '<|reserved_special_token_0|>',
                             'type': 'Llama3Tokenizer',
                             'vocab_file': '/home/ma-user/work/tokenizer.model'},
               'type': 'LlamaProcessor'},
 'profile': False,
 'profile_communication': False,
 'profile_memory': True,
 'profile_start_step': 4,
 'profile_stop_step': 8,
 'rank_id': 0,
 'recompute_config': <mindformers.modules.transformer.transformer.TransformerRecomputeConfig object at 0xfffe041563a0>,
 'remote_save_url': '',
 'resume_training': False,
 'run_mode': 'predict',
 'runner_config': {'batch_size': 1,
                   'epochs': 1,
                   'gradient_accumulation_steps': 1,
                   'sink_mode': True,
                   'sink_size': 2},
 'runner_wrapper': {'scale_sense': 1.0,
                    'type': 'MFTrainOneStepCell',
                    'use_clip_grad': True},
 'seed': 0,
 'src_strategy_path_or_dir': '',
 'train_dataset': {'auto_tune': False,
                   'autotune_per_step': 10,
                   'batch_size': 1,
                   'data_loader': {'dataset_dir': '',
                                   'shuffle': True,
                                   'type': 'MindDataset'},
                   'do_eval': False,
                   'drop_remainder': True,
                   'filepath_prefix': './autotune',
                   'input_columns': ['input_ids', 'labels'],
                   'num_parallel_workers': 1,
                   'numa_enable': False,
                   'output_columns': ['input_ids', 'labels'],
                   'prefetch_size': 1,
                   'profile': False,
                   'python_multiprocessing': False,
                   'repeat': 1,
                   'seed': 0},
 'train_dataset_task': {'dataset_config': {'auto_tune': False,
                                           'autotune_per_step': 10,
                                           'batch_size': 1,
                                           'data_loader': {'dataset_dir': '',
                                                           'shuffle': True,
                                                           'type': 'MindDataset'},
                                           'do_eval': False,
                                           'drop_remainder': True,
                                           'filepath_prefix': './autotune',
                                           'input_columns': ['input_ids',
                                                             'labels'],
                                           'num_parallel_workers': 1,
                                           'numa_enable': False,
                                           'output_columns': ['input_ids',
                                                              'labels'],
                                           'prefetch_size': 1,
                                           'profile': False,
                                           'python_multiprocessing': False,
                                           'repeat': 1,
                                           'seed': 0},
                        'type': 'CausalLanguageModelDataset'},
 'trainer': {'model_name': 'llama3_8b',
             'type': 'CausalLanguageModelingTrainer'},
 'use_parallel': False}
2024-07-26 16:09:04,665 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:04,665 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:04,666 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:51,727 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 47.06039881706238 s; generated tokens: 30 tokens; generate speed: 0.6374786604894452 tokens/s
2024-07-26 16:09:51,732 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:51,741 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:51,741 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:51,741 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:52,350 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6086301803588867 s; generated tokens: 18 tokens; generate speed: 29.574609641253847 tokens/s
2024-07-26 16:09:52,356 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:52,363 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:52,364 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:52,364 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:53,010 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6456131935119629 s; generated tokens: 19 tokens; generate speed: 29.42938618810605 tokens/s
2024-07-26 16:09:53,015 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:53,023 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:53,024 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:53,024 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:54,038 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0140037536621094 s; generated tokens: 30 tokens; generate speed: 29.5856892951865 tokens/s
2024-07-26 16:09:54,044 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:54,051 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:54,052 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:54,052 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:54,670 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6179471015930176 s; generated tokens: 18 tokens; generate speed: 29.12870689675129 tokens/s
2024-07-26 16:09:54,676 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:54,683 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:54,683 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:54,684 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:55,331 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6469781398773193 s; generated tokens: 19 tokens; generate speed: 29.367298257716712 tokens/s
2024-07-26 16:09:55,336 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:55,344 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:55,344 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:55,344 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:56,344 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9990661144256592 s; generated tokens: 30 tokens; generate speed: 30.028042755955475 tokens/s
2024-07-26 16:09:56,349 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:56,357 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:56,357 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:56,358 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:56,942 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5844697952270508 s; generated tokens: 17 tokens; generate speed: 29.086190832831587 tokens/s
2024-07-26 16:09:56,948 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:56,956 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:56,956 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:56,957 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:57,544 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.587226390838623 s; generated tokens: 17 tokens; generate speed: 28.949652579003054 tokens/s
2024-07-26 16:09:57,550 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:57,557 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:57,558 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:57,558 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:59,217 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.658820390701294 s; generated tokens: 50 tokens; generate speed: 30.14190100403918 tokens/s
2024-07-26 16:09:59,223 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:59,231 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:59,231 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:59,231 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:09:59,844 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6129779815673828 s; generated tokens: 18 tokens; generate speed: 29.3648394253478 tokens/s
2024-07-26 16:09:59,850 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:09:59,857 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:09:59,858 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:09:59,858 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:04,090 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 4.231794118881226 s; generated tokens: 128 tokens; generate speed: 30.24721817843062 tokens/s
2024-07-26 16:10:04,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:04,105 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:04,105 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:04,105 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:05,298 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.1923246383666992 s; generated tokens: 30 tokens; generate speed: 25.160932714680268 tokens/s
2024-07-26 16:10:05,303 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:05,311 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:05,312 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:05,312 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:05,926 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6135308742523193 s; generated tokens: 17 tokens; generate speed: 27.70846702819493 tokens/s
2024-07-26 16:10:05,931 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:05,939 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:05,939 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:05,940 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:06,184 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2444925308227539 s; generated tokens: 6 tokens; generate speed: 24.540626986882188 tokens/s
2024-07-26 16:10:06,190 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:06,197 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:06,198 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:06,198 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:06,983 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7845170497894287 s; generated tokens: 19 tokens; generate speed: 24.2187215753944 tokens/s
2024-07-26 16:10:06,988 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:06,996 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:06,997 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:06,997 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:07,707 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.709632158279419 s; generated tokens: 18 tokens; generate speed: 25.365254082682746 tokens/s
2024-07-26 16:10:07,713 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:07,720 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:07,721 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:07,721 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:08,268 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5470242500305176 s; generated tokens: 14 tokens; generate speed: 25.593015299082193 tokens/s
2024-07-26 16:10:08,274 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:08,281 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:08,282 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:08,282 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:08,536 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2541522979736328 s; generated tokens: 6 tokens; generate speed: 23.607891991684742 tokens/s
2024-07-26 16:10:08,542 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:08,550 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:08,550 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:08,550 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:09,256 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7056834697723389 s; generated tokens: 18 tokens; generate speed: 25.507186679329465 tokens/s
2024-07-26 16:10:09,262 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:09,270 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:09,270 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:09,270 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:11,247 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.9763529300689697 s; generated tokens: 47 tokens; generate speed: 23.78117758469375 tokens/s
2024-07-26 16:10:11,252 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:11,260 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:11,260 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:11,261 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:12,007 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7462701797485352 s; generated tokens: 17 tokens; generate speed: 22.779953509234897 tokens/s
2024-07-26 16:10:12,013 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:12,020 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:12,020 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:12,021 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:12,822 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8007252216339111 s; generated tokens: 18 tokens; generate speed: 22.479621615103238 tokens/s
2024-07-26 16:10:12,827 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:12,835 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:12,835 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:12,836 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:13,563 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7269048690795898 s; generated tokens: 17 tokens; generate speed: 23.3868291754951 tokens/s
2024-07-26 16:10:13,569 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:13,576 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:13,576 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:13,577 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:13,816 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2388324737548828 s; generated tokens: 5 tokens; generate speed: 20.935176533537778 tokens/s
2024-07-26 16:10:13,821 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:13,829 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:13,829 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:13,829 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:15,120 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2904188632965088 s; generated tokens: 30 tokens; generate speed: 23.24826523642245 tokens/s
2024-07-26 16:10:15,126 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:15,134 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:15,134 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:15,134 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:15,850 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7151708602905273 s; generated tokens: 18 tokens; generate speed: 25.1688106988696 tokens/s
2024-07-26 16:10:15,855 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:15,863 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:15,864 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:15,864 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:18,475 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 2.610497236251831 s; generated tokens: 61 tokens; generate speed: 23.36719577898661 tokens/s
2024-07-26 16:10:18,481 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:18,490 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:18,490 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:18,491 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:19,069 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.578028678894043 s; generated tokens: 15 tokens; generate speed: 25.950269506869247 tokens/s
2024-07-26 16:10:19,074 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:19,082 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:19,083 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:19,083 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:21,183 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 2.0994982719421387 s; generated tokens: 53 tokens; generate speed: 25.24412651741428 tokens/s
2024-07-26 16:10:21,188 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:21,197 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:21,197 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:21,197 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:22,236 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0380127429962158 s; generated tokens: 25 tokens; generate speed: 24.084482747136313 tokens/s
2024-07-26 16:10:22,241 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:22,249 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:22,249 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:22,250 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:22,979 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7287149429321289 s; generated tokens: 17 tokens; generate speed: 23.328738026967216 tokens/s
2024-07-26 16:10:22,984 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:22,992 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:22,992 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:22,993 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:23,694 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7012045383453369 s; generated tokens: 18 tokens; generate speed: 25.670113377297 tokens/s
2024-07-26 16:10:23,703 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:23,711 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:23,711 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:23,711 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:24,820 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.108309268951416 s; generated tokens: 28 tokens; generate speed: 25.263706425997068 tokens/s
2024-07-26 16:10:24,826 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:24,834 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:24,835 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:24,835 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:27,441 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 2.6054272651672363 s; generated tokens: 66 tokens; generate speed: 25.33173767019883 tokens/s
2024-07-26 16:10:27,446 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:27,455 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:27,455 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:27,456 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:28,174 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7182126045227051 s; generated tokens: 17 tokens; generate speed: 23.669871418223728 tokens/s
2024-07-26 16:10:28,183 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:28,191 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:28,192 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:28,192 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:28,776 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5835318565368652 s; generated tokens: 14 tokens; generate speed: 23.991834966966426 tokens/s
2024-07-26 16:10:28,781 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:28,789 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:28,790 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:28,790 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:29,533 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7429995536804199 s; generated tokens: 18 tokens; generate speed: 24.22612491600794 tokens/s
2024-07-26 16:10:29,539 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:29,547 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:29,547 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:29,547 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:30,065 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5175848007202148 s; generated tokens: 13 tokens; generate speed: 25.11665717754967 tokens/s
2024-07-26 16:10:30,071 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:30,084 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:30,084 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:30,085 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:30,815 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7302365303039551 s; generated tokens: 17 tokens; generate speed: 23.28012814275929 tokens/s
2024-07-26 16:10:30,821 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:30,829 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:30,829 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:30,830 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:31,362 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5320303440093994 s; generated tokens: 13 tokens; generate speed: 24.43469652883244 tokens/s
2024-07-26 16:10:31,367 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:31,375 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:31,376 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:31,376 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:36,278 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 4.902158260345459 s; generated tokens: 128 tokens; generate speed: 26.110948117570512 tokens/s
2024-07-26 16:10:36,284 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:36,294 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:36,294 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:36,294 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:37,037 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7419524192810059 s; generated tokens: 18 tokens; generate speed: 24.260315799553595 tokens/s
2024-07-26 16:10:37,042 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:37,051 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:37,051 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:37,052 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:37,329 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2771270275115967 s; generated tokens: 6 tokens; generate speed: 21.65072116522061 tokens/s
2024-07-26 16:10:37,334 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:37,342 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:37,342 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:37,343 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:38,155 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.812669038772583 s; generated tokens: 19 tokens; generate speed: 23.379751280664888 tokens/s
2024-07-26 16:10:38,161 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:38,170 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:38,170 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:38,171 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:38,840 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6685340404510498 s; generated tokens: 18 tokens; generate speed: 26.924582610416774 tokens/s
2024-07-26 16:10:38,845 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:38,853 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:38,853 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:38,854 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:39,533 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6785969734191895 s; generated tokens: 18 tokens; generate speed: 26.52531724287675 tokens/s
2024-07-26 16:10:39,538 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:39,547 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:39,547 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:39,547 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:40,163 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6159331798553467 s; generated tokens: 16 tokens; generate speed: 25.976843792954355 tokens/s
2024-07-26 16:10:40,169 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:40,177 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:40,177 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:40,178 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:40,423 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.24452567100524902 s; generated tokens: 6 tokens; generate speed: 24.537301034013737 tokens/s
2024-07-26 16:10:40,429 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:40,437 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:40,437 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:40,437 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:41,588 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.1507444381713867 s; generated tokens: 33 tokens; generate speed: 28.677088418032508 tokens/s
2024-07-26 16:10:41,595 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:41,603 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:41,604 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:41,604 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:46,063 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 4.458869695663452 s; generated tokens: 128 tokens; generate speed: 28.706826782690808 tokens/s
2024-07-26 16:10:46,069 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:46,079 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:46,079 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:46,079 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:46,337 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2577996253967285 s; generated tokens: 6 tokens; generate speed: 23.273889520850094 tokens/s
2024-07-26 16:10:46,343 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:46,350 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:46,351 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:46,351 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:46,951 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5996651649475098 s; generated tokens: 17 tokens; generate speed: 28.349153817344142 tokens/s
2024-07-26 16:10:46,957 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:46,965 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:46,965 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:46,966 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:47,590 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6239485740661621 s; generated tokens: 17 tokens; generate speed: 27.24583516428929 tokens/s
2024-07-26 16:10:47,595 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:47,603 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:47,603 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:47,604 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:48,228 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6236791610717773 s; generated tokens: 18 tokens; generate speed: 28.86099315723078 tokens/s
2024-07-26 16:10:48,233 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:48,241 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:48,241 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:48,241 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:49,285 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0436291694641113 s; generated tokens: 30 tokens; generate speed: 28.745842755051175 tokens/s
2024-07-26 16:10:49,291 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:49,298 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:49,299 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:49,299 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:49,922 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6225950717926025 s; generated tokens: 17 tokens; generate speed: 27.305066760411172 tokens/s
2024-07-26 16:10:49,927 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:49,935 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:49,935 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:49,935 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:50,558 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6223583221435547 s; generated tokens: 17 tokens; generate speed: 27.31545380713771 tokens/s
2024-07-26 16:10:50,563 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:50,571 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:50,571 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:50,572 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:51,204 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6324687004089355 s; generated tokens: 18 tokens; generate speed: 28.459906376966533 tokens/s
2024-07-26 16:10:51,210 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:51,217 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:51,218 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:51,218 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:52,264 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0455152988433838 s; generated tokens: 30 tokens; generate speed: 28.69398471087695 tokens/s
2024-07-26 16:10:52,270 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:52,278 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:52,278 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:52,278 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:53,379 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.100403070449829 s; generated tokens: 31 tokens; generate speed: 28.171495366082212 tokens/s
2024-07-26 16:10:53,384 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:53,393 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:53,393 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:53,394 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:53,929 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5347790718078613 s; generated tokens: 15 tokens; generate speed: 28.048965995044195 tokens/s
2024-07-26 16:10:53,934 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:53,942 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:53,943 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:53,943 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:54,734 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7904961109161377 s; generated tokens: 22 tokens; generate speed: 27.830623953991775 tokens/s
2024-07-26 16:10:54,740 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:54,748 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:54,748 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:54,749 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:55,299 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5504305362701416 s; generated tokens: 15 tokens; generate speed: 27.25139506547701 tokens/s
2024-07-26 16:10:55,305 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:55,326 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:55,327 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:55,327 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:55,839 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5115642547607422 s; generated tokens: 14 tokens; generate speed: 27.36704112868046 tokens/s
2024-07-26 16:10:55,844 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:55,852 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:55,852 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:55,852 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:56,532 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6791739463806152 s; generated tokens: 19 tokens; generate speed: 27.97516026822417 tokens/s
2024-07-26 16:10:56,537 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:56,545 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:56,546 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:56,546 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:57,193 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.64628005027771 s; generated tokens: 18 tokens; generate speed: 27.851702976542917 tokens/s
2024-07-26 16:10:57,198 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:57,206 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:57,207 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:57,207 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:57,817 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6092219352722168 s; generated tokens: 17 tokens; generate speed: 27.90444502364141 tokens/s
2024-07-26 16:10:57,823 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:57,831 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:57,831 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:57,832 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:58,435 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6029419898986816 s; generated tokens: 17 tokens; generate speed: 28.195083913224686 tokens/s
2024-07-26 16:10:58,441 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:58,450 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:58,450 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:58,451 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:10:59,132 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6806714534759521 s; generated tokens: 19 tokens; generate speed: 27.913613686858195 tokens/s
2024-07-26 16:10:59,138 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:10:59,147 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:10:59,147 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:10:59,148 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:00,170 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0216593742370605 s; generated tokens: 28 tokens; generate speed: 27.406394641961192 tokens/s
2024-07-26 16:11:00,175 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:00,184 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:00,184 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:00,185 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:00,861 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6761155128479004 s; generated tokens: 18 tokens; generate speed: 26.622669733136707 tokens/s
2024-07-26 16:11:00,867 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:00,875 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:00,875 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:00,875 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:01,469 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5935318470001221 s; generated tokens: 17 tokens; generate speed: 28.642102502035588 tokens/s
2024-07-26 16:11:01,475 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:01,482 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:01,482 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:01,483 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:02,132 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6494982242584229 s; generated tokens: 18 tokens; generate speed: 27.71370163567706 tokens/s
2024-07-26 16:11:02,138 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:02,146 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:02,146 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:02,147 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:02,805 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6580231189727783 s; generated tokens: 19 tokens; generate speed: 28.874365432114868 tokens/s
2024-07-26 16:11:02,810 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:02,818 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:02,819 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:02,819 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:03,437 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6175498962402344 s; generated tokens: 17 tokens; generate speed: 27.528139998888115 tokens/s
2024-07-26 16:11:03,443 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:03,451 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:03,451 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:03,452 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:04,072 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6199548244476318 s; generated tokens: 17 tokens; generate speed: 27.421352862519754 tokens/s
2024-07-26 16:11:04,077 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:04,085 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:04,086 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:04,086 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:04,746 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6596164703369141 s; generated tokens: 19 tokens; generate speed: 28.80461731086751 tokens/s
2024-07-26 16:11:04,751 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:04,759 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:04,759 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:04,760 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:06,059 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2996389865875244 s; generated tokens: 37 tokens; generate speed: 28.469444501008148 tokens/s
2024-07-26 16:11:06,065 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:06,073 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:06,073 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:06,074 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:07,253 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.1788723468780518 s; generated tokens: 34 tokens; generate speed: 28.841121000115482 tokens/s
2024-07-26 16:11:07,258 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:07,266 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:07,267 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:07,267 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:07,946 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6782822608947754 s; generated tokens: 19 tokens; generate speed: 28.011937058379807 tokens/s
2024-07-26 16:11:07,951 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:07,959 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:07,959 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:07,960 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:08,643 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6832334995269775 s; generated tokens: 19 tokens; generate speed: 27.808940886467443 tokens/s
2024-07-26 16:11:08,649 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:08,657 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:08,657 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:08,657 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:09,203 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5457508563995361 s; generated tokens: 15 tokens; generate speed: 27.485069100869577 tokens/s
2024-07-26 16:11:09,209 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:09,216 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:09,217 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:09,217 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:10,608 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3910508155822754 s; generated tokens: 40 tokens; generate speed: 28.755239960990593 tokens/s
2024-07-26 16:11:10,614 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:10,622 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:10,622 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:10,623 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:11,262 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6385362148284912 s; generated tokens: 18 tokens; generate speed: 28.189473959334855 tokens/s
2024-07-26 16:11:11,267 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:11,275 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:11,275 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:11,275 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:11,502 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22599053382873535 s; generated tokens: 6 tokens; generate speed: 26.549784623045493 tokens/s
2024-07-26 16:11:11,507 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:11,514 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:11,515 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:11,515 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:12,146 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6306254863739014 s; generated tokens: 18 tokens; generate speed: 28.543089978015413 tokens/s
2024-07-26 16:11:12,151 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:12,159 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:12,159 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:12,160 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:13,027 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8672938346862793 s; generated tokens: 25 tokens; generate speed: 28.82529426609275 tokens/s
2024-07-26 16:11:13,034 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:13,042 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:13,043 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:13,043 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:13,271 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22786617279052734 s; generated tokens: 6 tokens; generate speed: 26.331244899240378 tokens/s
2024-07-26 16:11:13,277 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:13,284 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:13,284 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:13,284 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:13,853 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5687971115112305 s; generated tokens: 16 tokens; generate speed: 28.129538065848795 tokens/s
2024-07-26 16:11:13,859 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:13,866 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:13,867 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:13,867 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:14,463 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5962285995483398 s; generated tokens: 17 tokens; generate speed: 28.51255376356985 tokens/s
2024-07-26 16:11:14,470 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:14,478 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:14,478 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:14,478 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:14,708 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22899198532104492 s; generated tokens: 6 tokens; generate speed: 26.201790388375596 tokens/s
2024-07-26 16:11:14,713 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:14,721 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:14,721 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:14,722 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:15,182 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.4595797061920166 s; generated tokens: 13 tokens; generate speed: 28.28671463262671 tokens/s
2024-07-26 16:11:15,187 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:15,195 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:15,195 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:15,195 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:15,395 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19952845573425293 s; generated tokens: 5 tokens; generate speed: 25.0590823328948 tokens/s
2024-07-26 16:11:15,401 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:15,408 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:15,408 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:15,409 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:16,003 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5937068462371826 s; generated tokens: 17 tokens; generate speed: 28.63366004239842 tokens/s
2024-07-26 16:11:16,009 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:16,016 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:16,016 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:16,017 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:16,983 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9662425518035889 s; generated tokens: 27 tokens; generate speed: 27.94329431011063 tokens/s
2024-07-26 16:11:16,989 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:16,997 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:16,997 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:16,997 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:17,607 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6093928813934326 s; generated tokens: 17 tokens; generate speed: 27.896617303976285 tokens/s
2024-07-26 16:11:17,612 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:17,620 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:17,620 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:17,621 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:18,003 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.3824193477630615 s; generated tokens: 10 tokens; generate speed: 26.1493045749238 tokens/s
2024-07-26 16:11:18,009 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:18,017 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:18,017 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:18,017 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:18,635 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6171715259552002 s; generated tokens: 18 tokens; generate speed: 29.16531181852774 tokens/s
2024-07-26 16:11:18,640 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:18,647 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:18,648 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:18,648 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:18,875 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2266979217529297 s; generated tokens: 6 tokens; generate speed: 26.466938706827648 tokens/s
2024-07-26 16:11:18,880 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:18,888 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:18,888 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:18,888 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:19,427 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5378978252410889 s; generated tokens: 15 tokens; generate speed: 27.886336951217295 tokens/s
2024-07-26 16:11:19,432 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:19,439 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:19,440 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:19,440 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:20,051 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6106417179107666 s; generated tokens: 18 tokens; generate speed: 29.477186821733575 tokens/s
2024-07-26 16:11:20,056 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:20,064 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:20,064 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:20,064 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:20,312 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2469942569732666 s; generated tokens: 6 tokens; generate speed: 24.292062793384744 tokens/s
2024-07-26 16:11:20,317 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:20,325 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:20,325 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:20,326 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:21,585 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2594406604766846 s; generated tokens: 37 tokens; generate speed: 29.37812090805128 tokens/s
2024-07-26 16:11:21,591 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:21,598 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:21,599 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:21,599 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:22,173 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5739130973815918 s; generated tokens: 17 tokens; generate speed: 29.62120933911496 tokens/s
2024-07-26 16:11:22,178 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:22,186 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:22,186 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:22,187 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:22,818 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6311554908752441 s; generated tokens: 18 tokens; generate speed: 28.519121294562147 tokens/s
2024-07-26 16:11:22,824 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:22,831 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:22,831 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:22,832 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:23,757 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9253630638122559 s; generated tokens: 27 tokens; generate speed: 29.177736886068267 tokens/s
2024-07-26 16:11:23,763 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:23,770 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:23,771 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:23,771 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:24,348 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5766127109527588 s; generated tokens: 17 tokens; generate speed: 29.482527313541638 tokens/s
2024-07-26 16:11:24,353 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:24,361 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:24,361 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:24,361 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:24,927 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5653769969940186 s; generated tokens: 16 tokens; generate speed: 28.299701057999133 tokens/s
2024-07-26 16:11:24,932 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:24,940 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:24,941 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:24,941 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:25,698 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7565321922302246 s; generated tokens: 22 tokens; generate speed: 29.08005796177019 tokens/s
2024-07-26 16:11:25,703 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:25,711 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:25,711 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:25,711 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:26,743 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0312204360961914 s; generated tokens: 30 tokens; generate speed: 29.0917430938128 tokens/s
2024-07-26 16:11:26,748 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:26,756 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:26,756 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:26,756 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:27,043 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.28641676902770996 s; generated tokens: 8 tokens; generate speed: 27.931325484738025 tokens/s
2024-07-26 16:11:27,048 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:27,055 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:27,056 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:27,056 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:28,081 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0247070789337158 s; generated tokens: 30 tokens; generate speed: 29.276659268536758 tokens/s
2024-07-26 16:11:28,086 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:28,094 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:28,094 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:28,095 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:28,728 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6325206756591797 s; generated tokens: 18 tokens; generate speed: 28.45756778028062 tokens/s
2024-07-26 16:11:28,733 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:28,740 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:28,741 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:28,741 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:29,338 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.59623122215271 s; generated tokens: 17 tokens; generate speed: 28.512428347212364 tokens/s
2024-07-26 16:11:29,343 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:29,350 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:29,351 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:29,351 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:29,640 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.28855180740356445 s; generated tokens: 8 tokens; generate speed: 27.72465739163198 tokens/s
2024-07-26 16:11:29,645 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:29,653 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:29,653 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:29,653 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:30,252 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5986144542694092 s; generated tokens: 17 tokens; generate speed: 28.398913321844166 tokens/s
2024-07-26 16:11:30,257 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:30,265 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:30,265 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:30,265 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:30,786 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.520254373550415 s; generated tokens: 15 tokens; generate speed: 28.832049786788446 tokens/s
2024-07-26 16:11:30,791 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:30,799 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:30,799 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:30,800 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:32,165 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.365340232849121 s; generated tokens: 41 tokens; generate speed: 30.029145127030592 tokens/s
2024-07-26 16:11:32,171 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:32,180 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:32,181 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:32,181 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:32,798 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6170375347137451 s; generated tokens: 18 tokens; generate speed: 29.171645138817244 tokens/s
2024-07-26 16:11:32,804 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:32,813 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:32,813 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:32,813 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:33,414 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.600754976272583 s; generated tokens: 17 tokens; generate speed: 28.297726479899385 tokens/s
2024-07-26 16:11:33,420 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:33,428 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:33,428 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:33,429 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:34,062 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6328332424163818 s; generated tokens: 18 tokens; generate speed: 28.44351211903726 tokens/s
2024-07-26 16:11:34,067 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:34,075 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:34,075 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:34,076 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:35,133 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0565924644470215 s; generated tokens: 30 tokens; generate speed: 28.39316104312821 tokens/s
2024-07-26 16:11:35,138 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:35,146 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:35,147 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:35,147 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:36,075 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9277117252349854 s; generated tokens: 27 tokens; generate speed: 29.10386843839989 tokens/s
2024-07-26 16:11:36,081 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:36,088 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:36,089 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:36,089 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:36,726 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6373217105865479 s; generated tokens: 18 tokens; generate speed: 28.24319288202816 tokens/s
2024-07-26 16:11:36,732 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:36,739 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:36,740 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:36,740 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:37,325 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5848143100738525 s; generated tokens: 17 tokens; generate speed: 29.069056121169773 tokens/s
2024-07-26 16:11:37,331 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:37,339 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:37,339 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:37,339 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:37,978 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6381189823150635 s; generated tokens: 18 tokens; generate speed: 28.20790557694571 tokens/s
2024-07-26 16:11:37,983 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:37,991 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:37,991 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:37,991 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:38,604 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6126842498779297 s; generated tokens: 18 tokens; generate speed: 29.378917449871274 tokens/s
2024-07-26 16:11:38,610 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:38,640 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:38,641 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:38,641 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:39,249 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6079423427581787 s; generated tokens: 17 tokens; generate speed: 27.96317809164691 tokens/s
2024-07-26 16:11:39,255 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:39,262 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:39,262 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:39,263 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:39,880 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6170227527618408 s; generated tokens: 18 tokens; generate speed: 29.172344000979916 tokens/s
2024-07-26 16:11:39,885 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:39,893 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:39,893 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:39,894 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:41,196 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3021225929260254 s; generated tokens: 39 tokens; generate speed: 29.95109693347869 tokens/s
2024-07-26 16:11:41,201 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:41,209 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:41,210 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:41,210 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:41,902 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.692183256149292 s; generated tokens: 20 tokens; generate speed: 28.894082343543925 tokens/s
2024-07-26 16:11:41,908 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:41,915 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:41,915 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:41,916 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:42,541 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6247580051422119 s; generated tokens: 18 tokens; generate speed: 28.81115544234237 tokens/s
2024-07-26 16:11:42,546 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:42,554 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:42,554 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:42,554 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:43,101 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5461249351501465 s; generated tokens: 16 tokens; generate speed: 29.297325520580944 tokens/s
2024-07-26 16:11:43,106 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:43,113 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:43,114 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:43,114 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:43,484 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.3693070411682129 s; generated tokens: 10 tokens; generate speed: 27.077739889192028 tokens/s
2024-07-26 16:11:43,489 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:43,496 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:43,497 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:43,497 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:44,104 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6068258285522461 s; generated tokens: 18 tokens; generate speed: 29.66254755988892 tokens/s
2024-07-26 16:11:44,109 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:44,135 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:44,136 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:44,136 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:44,359 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22301745414733887 s; generated tokens: 6 tokens; generate speed: 26.903723849506576 tokens/s
2024-07-26 16:11:44,365 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:44,372 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:44,372 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:44,372 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:44,934 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5611872673034668 s; generated tokens: 16 tokens; generate speed: 28.510981863292816 tokens/s
2024-07-26 16:11:44,939 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:44,946 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:44,947 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:44,947 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:45,551 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.604058027267456 s; generated tokens: 18 tokens; generate speed: 29.798461716377822 tokens/s
2024-07-26 16:11:45,557 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:45,564 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:45,565 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:45,565 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:46,295 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7302939891815186 s; generated tokens: 22 tokens; generate speed: 30.124854272259086 tokens/s
2024-07-26 16:11:46,301 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:46,309 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:46,309 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:46,310 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:46,871 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5609252452850342 s; generated tokens: 16 tokens; generate speed: 28.524300046202413 tokens/s
2024-07-26 16:11:46,876 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:46,884 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:46,884 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:46,884 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:48,429 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.5443305969238281 s; generated tokens: 46 tokens; generate speed: 29.78636834083841 tokens/s
2024-07-26 16:11:48,434 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:48,442 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:48,442 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:48,443 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:49,036 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5925323963165283 s; generated tokens: 17 tokens; generate speed: 28.690414407178963 tokens/s
2024-07-26 16:11:49,041 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:49,048 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:49,049 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:49,049 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:49,514 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.46469831466674805 s; generated tokens: 13 tokens; generate speed: 27.975139116488446 tokens/s
2024-07-26 16:11:49,519 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:49,527 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:49,527 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:49,528 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:50,195 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6675930023193359 s; generated tokens: 19 tokens; generate speed: 28.460454100014 tokens/s
2024-07-26 16:11:50,202 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:50,209 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:50,210 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:50,210 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:51,089 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8788032531738281 s; generated tokens: 26 tokens; generate speed: 29.5856892951865 tokens/s
2024-07-26 16:11:51,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:51,102 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:51,103 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:51,103 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:51,739 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6358892917633057 s; generated tokens: 18 tokens; generate speed: 28.30681414698215 tokens/s
2024-07-26 16:11:51,745 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:51,753 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:51,754 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:51,754 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:52,833 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0783886909484863 s; generated tokens: 30 tokens; generate speed: 27.819282835406767 tokens/s
2024-07-26 16:11:52,838 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:52,868 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:52,869 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:52,869 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:53,496 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6260659694671631 s; generated tokens: 18 tokens; generate speed: 28.750963760767217 tokens/s
2024-07-26 16:11:53,501 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:53,509 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:53,509 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:53,509 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:54,126 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6167747974395752 s; generated tokens: 17 tokens; generate speed: 27.562734519264257 tokens/s
2024-07-26 16:11:54,132 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:54,139 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:54,139 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:54,140 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:55,183 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0427823066711426 s; generated tokens: 30 tokens; generate speed: 28.769187785481826 tokens/s
2024-07-26 16:11:55,188 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:55,196 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:55,196 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:55,196 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:55,686 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.48961615562438965 s; generated tokens: 14 tokens; generate speed: 28.593827714173994 tokens/s
2024-07-26 16:11:55,692 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:55,699 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:55,699 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:55,700 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:56,379 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6787188053131104 s; generated tokens: 19 tokens; generate speed: 27.993920090713875 tokens/s
2024-07-26 16:11:56,384 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:56,415 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:56,415 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:56,416 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:57,457 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.040937900543213 s; generated tokens: 30 tokens; generate speed: 28.820163032150635 tokens/s
2024-07-26 16:11:57,462 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:57,470 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:57,470 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:57,471 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:57,698 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22720026969909668 s; generated tokens: 6 tokens; generate speed: 26.408419355955786 tokens/s
2024-07-26 16:11:57,704 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:57,711 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:57,711 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:57,712 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:58,236 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5242621898651123 s; generated tokens: 15 tokens; generate speed: 28.61163801238338 tokens/s
2024-07-26 16:11:58,242 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:58,249 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:58,250 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:58,250 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:58,764 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.513359785079956 s; generated tokens: 14 tokens; generate speed: 27.27132199850733 tokens/s
2024-07-26 16:11:58,769 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:58,776 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:58,777 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:58,777 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:59,039 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.261324405670166 s; generated tokens: 7 tokens; generate speed: 26.786629369914806 tokens/s
2024-07-26 16:11:59,045 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:59,052 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:59,053 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:59,053 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:11:59,928 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8750779628753662 s; generated tokens: 25 tokens; generate speed: 28.56888307169112 tokens/s
2024-07-26 16:11:59,934 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:11:59,941 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:11:59,942 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:11:59,942 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:00,595 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6529505252838135 s; generated tokens: 19 tokens; generate speed: 29.098682464098488 tokens/s
2024-07-26 16:12:00,601 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:00,608 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:00,608 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:00,609 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:01,268 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6586446762084961 s; generated tokens: 18 tokens; generate speed: 27.328847632409985 tokens/s
2024-07-26 16:12:01,273 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:01,281 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:01,281 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:01,282 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:02,356 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0738227367401123 s; generated tokens: 31 tokens; generate speed: 28.868824377950055 tokens/s
2024-07-26 16:12:02,361 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:02,370 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:02,370 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:02,370 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:02,851 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.4798622131347656 s; generated tokens: 13 tokens; generate speed: 27.0911099981716 tokens/s
2024-07-26 16:12:02,857 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:02,864 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:02,865 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:02,865 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:03,868 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0025854110717773 s; generated tokens: 29 tokens; generate speed: 28.92521642520073 tokens/s
2024-07-26 16:12:03,873 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:03,881 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:03,882 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:03,882 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:04,550 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6677632331848145 s; generated tokens: 19 tokens; generate speed: 28.453198762354496 tokens/s
2024-07-26 16:12:04,556 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:04,563 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:04,563 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:04,564 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:04,792 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22769641876220703 s; generated tokens: 6 tokens; generate speed: 26.35087557642289 tokens/s
2024-07-26 16:12:04,797 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:04,805 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:04,805 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:04,805 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:05,833 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0274279117584229 s; generated tokens: 30 tokens; generate speed: 29.199128869932668 tokens/s
2024-07-26 16:12:05,838 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:05,847 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:05,847 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:05,847 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:06,479 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6311566829681396 s; generated tokens: 18 tokens; generate speed: 28.519067429265622 tokens/s
2024-07-26 16:12:06,484 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:06,492 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:06,492 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:06,493 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:07,163 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6699907779693604 s; generated tokens: 19 tokens; generate speed: 28.358599289360512 tokens/s
2024-07-26 16:12:07,168 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:07,176 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:07,177 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:07,177 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:07,816 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6384603977203369 s; generated tokens: 18 tokens; generate speed: 28.19282145653847 tokens/s
2024-07-26 16:12:07,822 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:07,829 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:07,830 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:07,830 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:08,849 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0181636810302734 s; generated tokens: 30 tokens; generate speed: 29.464810579025162 tokens/s
2024-07-26 16:12:08,855 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:08,863 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:08,864 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:08,864 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:09,497 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6327018737792969 s; generated tokens: 18 tokens; generate speed: 28.449417879041835 tokens/s
2024-07-26 16:12:09,503 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:09,511 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:09,511 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:09,512 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:10,590 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0779039859771729 s; generated tokens: 30 tokens; generate speed: 27.83179243261034 tokens/s
2024-07-26 16:12:10,595 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:10,603 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:10,604 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:10,604 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:11,200 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5962707996368408 s; generated tokens: 17 tokens; generate speed: 28.510535834311966 tokens/s
2024-07-26 16:12:11,206 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:11,213 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:11,214 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:11,214 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:11,826 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6116652488708496 s; generated tokens: 17 tokens; generate speed: 27.792979953303632 tokens/s
2024-07-26 16:12:11,831 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:11,839 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:11,839 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:11,840 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:12,939 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0989327430725098 s; generated tokens: 31 tokens; generate speed: 28.209187682702943 tokens/s
2024-07-26 16:12:12,944 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:12,952 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:12,952 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:12,953 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:13,443 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.48999929428100586 s; generated tokens: 14 tokens; generate speed: 28.571469721283414 tokens/s
2024-07-26 16:12:13,448 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:13,456 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:13,456 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:13,456 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:14,135 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6779999732971191 s; generated tokens: 19 tokens; generate speed: 28.023599923762315 tokens/s
2024-07-26 16:12:14,141 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:14,148 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:14,149 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:14,149 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:14,413 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2634751796722412 s; generated tokens: 7 tokens; generate speed: 26.567967459811147 tokens/s
2024-07-26 16:12:14,418 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:14,426 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:14,426 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:14,427 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:15,013 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5861098766326904 s; generated tokens: 17 tokens; generate speed: 29.004800426957726 tokens/s
2024-07-26 16:12:15,018 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:15,026 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:15,026 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:15,027 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:15,279 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.252119779586792 s; generated tokens: 6 tokens; generate speed: 23.79821214279027 tokens/s
2024-07-26 16:12:15,285 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:15,292 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:15,293 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:15,293 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:15,490 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.1972362995147705 s; generated tokens: 5 tokens; generate speed: 25.35030322664091 tokens/s
2024-07-26 16:12:15,496 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:15,503 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:15,503 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:15,504 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:17,795 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 2.2912425994873047 s; generated tokens: 67 tokens; generate speed: 29.241774753573505 tokens/s
2024-07-26 16:12:17,800 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:17,809 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:17,809 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:17,809 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:18,430 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6207656860351562 s; generated tokens: 18 tokens; generate speed: 28.996448104221717 tokens/s
2024-07-26 16:12:18,436 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:18,443 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:18,443 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:18,444 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:19,084 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6402130126953125 s; generated tokens: 18 tokens; generate speed: 28.11564220511476 tokens/s
2024-07-26 16:12:19,090 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:19,097 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:19,097 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:19,098 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:19,617 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5188555717468262 s; generated tokens: 15 tokens; generate speed: 28.909779169373937 tokens/s
2024-07-26 16:12:19,623 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:19,630 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:19,630 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:19,631 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:21,139 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.5085430145263672 s; generated tokens: 44 tokens; generate speed: 29.167216033156702 tokens/s
2024-07-26 16:12:21,145 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:21,153 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:21,153 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:21,153 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:21,822 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6680243015289307 s; generated tokens: 19 tokens; generate speed: 28.44207906286348 tokens/s
2024-07-26 16:12:21,827 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:21,834 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:21,835 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:21,835 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:22,487 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6516079902648926 s; generated tokens: 19 tokens; generate speed: 29.158635688730726 tokens/s
2024-07-26 16:12:22,492 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:22,500 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:22,500 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:22,501 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:22,876 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.3756401538848877 s; generated tokens: 10 tokens; generate speed: 26.621222189852553 tokens/s
2024-07-26 16:12:22,882 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:22,889 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:22,890 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:22,890 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:23,396 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5061042308807373 s; generated tokens: 14 tokens; generate speed: 27.66228603866202 tokens/s
2024-07-26 16:12:23,402 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:23,409 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:23,410 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:23,410 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:23,701 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.29049181938171387 s; generated tokens: 8 tokens; generate speed: 27.53950185938899 tokens/s
2024-07-26 16:12:23,706 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:23,714 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:23,714 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:23,714 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:24,279 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5644211769104004 s; generated tokens: 16 tokens; generate speed: 28.34762523897989 tokens/s
2024-07-26 16:12:24,285 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:24,292 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:24,293 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:24,293 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:24,522 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22895407676696777 s; generated tokens: 6 tokens; generate speed: 26.20612869063202 tokens/s
2024-07-26 16:12:24,528 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:24,535 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:24,535 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:24,535 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:25,004 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.4689328670501709 s; generated tokens: 13 tokens; generate speed: 27.722518325014605 tokens/s
2024-07-26 16:12:25,010 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:25,018 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:25,018 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:25,018 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:25,473 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.45496225357055664 s; generated tokens: 13 tokens; generate speed: 28.57379903052535 tokens/s
2024-07-26 16:12:25,479 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:25,486 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:25,486 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:25,487 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:26,158 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.671250581741333 s; generated tokens: 19 tokens; generate speed: 28.305375841479222 tokens/s
2024-07-26 16:12:26,164 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:26,171 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:26,171 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:26,172 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:26,793 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6213674545288086 s; generated tokens: 18 tokens; generate speed: 28.968366252219703 tokens/s
2024-07-26 16:12:26,799 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:26,807 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:26,807 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:26,807 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:27,003 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19524574279785156 s; generated tokens: 5 tokens; generate speed: 25.608752991745224 tokens/s
2024-07-26 16:12:27,008 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:27,015 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 16:12:27,016 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 16:12:27,016 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 16:12:27,675 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6583530902862549 s; generated tokens: 19 tokens; generate speed: 28.85989339206825 tokens/s
2024-07-26 16:12:27,680 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 16:12:27,689 - mindformers[mindformers/trainer/base_trainer.py:951] - INFO - output result is: [{'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7451.51 - -1709.92 \n\n### Response: -7451.51 - -1709.92 = -7451.51 + 1709.92 = -5741.59']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1337.47 + 5068.04 \n\n### Response: -1337.47 + 5068.04 = 3730.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6211.70 * -6871.61 \n\n### Response: -6211.70 * -6871.61 = 4267342.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3985.41 - -8173.86 \n\n### Response: -3985.41 - -8173.86 = -3985.41 + 8173.86 = 4188.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1075.16 - 8090.56 \n\n### Response: 1075.16 - 8090.56 = -7015.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9299.25 * 1012.66 \n\n### Response: -9299.25 * 1012.66 = -9416198.71']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2864.35 - -8690.01 \n\n### Response: -2864.35 - -8690.01 = -2864.35 + 8690.01 = 5825.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7310.69 + -6470.86 \n\n### Response: 7310.69 + -6470.86 = 840.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3476.06 + 2490.05 \n\n### Response: -3476.06 + 2490.05 = -984.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 19  71 \n\n### Response:\xa0\n 19  71 \n= 71 / 19 = 3.73\n 3.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1647.72 * -2175.26 \n\n### Response: 1647.72 * -2175.26 = -3578.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -13x + 10 = 0\n\n### Response: -13x = -10.0\n\n-10.0\n-10.0\n\n-10.0\n-10.0\n\n-10.0\n-10.0\n']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1980.46 - -4548.03 \n\n### Response: -1980.46 - -4548.03 = -1980.46 + 4548.03 = 2567.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9349.89 + 8736.20 \n\n### Response: -9349.89 + 8736.20 = -612.69']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7881.79 + -3132.78 \n\n### Response: -11014.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7374.53 * -4084.42 \n\n### Response: 7374.53 * -4084.42 = -3013662.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6811.55 - 2494.54 \n\n### Response: 6811.55 - 2494.54 = 4317.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6974.95 \n\n### Response:\xa0\n6974.95  83.6']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3957.83 - 3083.39 \n\n### Response: -7041.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8230.71 - 2598.23 \n\n### Response:\xa0\n8230.71 - 2598.23 = 5632.48']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 53x + 27 = 0\n\n### Response:  53x + 27 = 0  53x = -27.  x = -27 / 53 = -0.51.  -0.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2670.86 / 8327.57 \n\n### Response: 2670.86 / 8327.57 = 0.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1295.35 + 7059.64 \n\n### Response: -1295.35 + 7059.64 = 5764.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5113.34 - 239.46 \n\n### Response: 5113.34 - 239.46 = 4873.88']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4157.45 \n\n### Response: 64.78']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8141.51 - -9883.79 \n\n### Response: -8141.51 - -9883.79 = -8141.51 + 9883.79 = 1742.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3619.12 + -4630.69 \n\n### Response: 3619.12 + -4630.69 = -1011.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 50  42 \n\n### Response:\xa0\n 50  42 \n = (50 - 42) / 50 = 0.16\n = 0.16 * 100% = 16%']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -337.33  2 \n\n### Response: -337.33 ** 2 = 113,898.68']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 56  20 \n\n### Response:\xa0\n 56  20 \n= 56 - 20\n= 36\n = 36 / 56\n= 0.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5x + -100 = 0\n\n### Response:  -5x = 100.  x = 100 / -5 = -20.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8115.42 / -8891.52 \n\n### Response: 8115.42 / -8891.52 = -0.91']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4670.73 + 5116.49 \n\n### Response: 4670.73 + 5116.49 = 9787.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2921.61 - -426.91 \n\n### Response: 2921.61 - -426.91 = 2921.61 + 426.91 = 3348.52']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 47  12 \n\n### Response:\xa0\n 47  12 \n47 - 12 = 35\n35 / 47 = 0.74\n0.74 * 100 = 74.0\n 74.0 %']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4023.23 + -4657.63 \n\n### Response: 4023.23 + -4657.63 = -636.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6365.40 \n\n### Response:\xa0\n6365.40  79.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6402.63 + 9129.29 \n\n### Response: -6402.63 + 9129.29 = 2726.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8049.63 \n\n### Response:8049.63  89.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8874.39 / -5271.14 \n\n### Response: 8874.39 / -5271.14 = -1.68']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -721.97  1 \n\n### Response: -721.97 ** 1 = -721.97']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -33x + 79 = 0\n\n### Response: -33x = -79.0\n\n-79.0\n-79.0\n\n-79.0\n-79.0\n-33x = -79.0\n\n-79.0\n-79.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5396.67 + -7513.38 \n\n### Response: 5396.67 + -7513.38 = -2116.71']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5555.48 - 2227.05 \n\n### Response: -7782.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3585.58 * -7185.14 \n\n### Response: 3585.58 * -7185.14 = -2577341.97']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8326.91 + 8323.56 \n\n### Response: 8326.91 + 8323.56 = 16650.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6412.43 + 8195.96 \n\n### Response: 6412.43 + 8195.96 = 14608.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 48  7 \n\n### Response: \n 48 * 7 = 336 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2068.77 + -1347.07 \n\n### Response: -3415.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 0.64  y = 93x^80 \n\n### Response: \n x = 0.64 y = 93x^80 = 93 * 0.64^80 = 0.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -44x + 70 = 0\n\n### Response: -44x = -70.0\n0-44x-70.0 / -44 = 1.59\n0-44x-70.0 / -44 = 1.59\n0-44x-70.0 / -44 = 1.59\n0-44x-70.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5351.95 + -9780.91 \n\n### Response: -15132.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6585.23 * -469.39 \n\n### Response: 6585.23 * -469.39 = -3090.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5591.19 / -7097.76 \n\n### Response: 5591.19 / -7097.76 = -0.79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2910.65 * -4198.96 \n\n### Response: 2910.65 * -4198.96 = -122200.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5861.56 - -6927.43 \n\n### Response: -5861.56 - -6927.43 = -5861.56 + 6927.43 = 1065.87']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5452.84 / -2723.07 \n\n### Response: -5452.84 / -2723.07 = 2.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8508.06 / 4921.11 \n\n### Response: 8508.06 / 4921.11 = 1.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3859.13 + 8440.41 \n\n### Response: -3859.13 + 8440.41 = 4581.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6983.88 - -8060.14 \n\n### Response: -6983.88 - -8060.14 = -6983.88 + 8060.14 = 1076.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[17, 99, 52]\n\n### Response: \n17 + 99 + 52 = 168\n168 / 3 = 56.0\n: 56.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 680.12  3 \n\n### Response:\xa0\n680.12 ** 3 = 404.963.552']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -97x + -92 = 0\n\n### Response:  -97x + -92 = 0 x = 0.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 123.84  1 \n\n### Response: 123.84  1  = 123.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5708.06 \n\n### Response:\xa0\n5708.06  75.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7194.48 * -6220.64 \n\n### Response: -7194.48 * -6220.64 = 4475232.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8830.69 * -1065.17 \n\n### Response: 8830.69 * -1065.17 = -9394.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1855.82 - 1345.12 \n\n### Response: 1855.82 - 1345.12 = 510.7']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8.74 * -9037.79 \n\n### Response: 8.74 * -9037.79 = -79000.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3321.89 * -3531.67 \n\n### Response: -3321.89 * -3531.67 = 1174152.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3460.04 - -315.20 \n\n### Response: 3460.04 - -315.20 = 3460.04 + 315.20 = 3775.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6185.13 - 2193.41 \n\n### Response:\xa0\n6185.13 - 2193.41 = 3991.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5208.71 / 3443.94 \n\n### Response: -5208.71 / 3443.94 = -1.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1432.15 + -7448.73 \n\n### Response: 1432.15 + -7448.73 = -6016.58']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7375.26 * -8346.62 \n\n### Response: -7375.26 * -8346.62 = 6157342.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1552.54 / 6004.21 \n\n### Response: -1552.54 / 6004.21 = -0.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2508.22 / -8899.74 \n\n### Response: -2508.22 / -8899.74 = 0.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3459.21 * 4229.30 \n\n### Response: -3459.21 * 4229.30 = -1459450.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[71, 54, 62, 70, 53]\n\n### Response: \n71 + 54 + 62 + 70 + 53 = 310\n310 / 5 = 62.0\n: 62.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -368.19  4 \n\n### Response: -368.19 ** 4 = -368.19 * -368.19 * -368.19 * -368.19 = 533531.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9245.32 * 2915.01 \n\n### Response: -9245.32 * 2915.01 = -26924200.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3362.63 * 7545.83 \n\n### Response: 3362.63 * 7545.83 = 25376500.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -514.60 / 293.74 \n\n### Response: -514.60 / 293.74 = -1.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -80x + 94 = 0\n\n### Response:  -80x = -94.0\nx = -94.0 / -80\nx = 1.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3279.11 - 7172.93 \n\n### Response: -3279.11 - 7172.93 = -10452.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9247.11 - 7331.30 \n\n### Response: -16578.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1738.37 + 4806.48 \n\n### Response: -1738.37 + 4806.48 = 3068.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 10.63  2 \n\n### Response: 10.63  2  = 10.63 * 10.63 = 112.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7735.89 + 3030.00 \n\n### Response: -7705.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1058.80 * -607.50 \n\n### Response: -1058.80 * -607.50 = 644.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -430.88 - 1101.44 \n\n### Response: -430.88 - 1101.44 = -1532.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1923.64 - 8110.60 \n\n### Response: -10034.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 282.03 \n\n### Response: 282.03  16.77']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3124.14 / 1192.09 \n\n### Response: -2.63']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2666.20 * 110.52 \n\n### Response: 2666.20 * 110.52 = 294299.296']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 4.77  y = 86x^97 \n\n### Response: \n x = 4.77 y = 86 * 4.77^97 = 1.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7781.42 / -5327.71 \n\n### Response: -7781.42 / -5327.71 = 1.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[27, 89, 99, 64, 76, 50, 100, 49]\n\n### Response: \n: 72.25']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4294.20 + 9857.73 \n\n### Response: -4294.20 + 9857.73 = 5563.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1214.14 - 1182.21 \n\n### Response: -2396.35']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 475.47  5 \n\n### Response: 475.47 ** 5 = 1129682.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5078.04 - 8883.67 \n\n### Response: 5078.04 - 8883.67 = -3805.63']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2023.47 - 1907.67 \n\n### Response: -3931.14']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2x + 60 = 0\n\n### Response:  2x = -60.0x = -60.0 / 2 = -30.0 -30.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5415.08 / 8305.15 \n\n### Response: 5415.08 / 8305.15 = 0.65']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2356.30 + 9645.15 \n\n### Response: 2356.30 + 9645.15 = 12001.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 676.46  2 \n\n### Response: 676.46  2  = 676.46 * 676.46 = 459,599.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7076.54 / -2319.93 \n\n### Response: 7076.54 / -2319.93 = -3.05']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -101.17 * -8210.19 \n\n### Response: -101.17 * -8210.19 = 830.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -67x + -29 = 0\n\n### Response:  -67x + -29 = 0 x = 0.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4415.70 - -2186.85 \n\n### Response: 4415.70 - -2186.85 = 4415.70 + 2186.85 = 6602.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -513.32  3 \n\n### Response: -513.32 ** 3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3180.61 - -7868.88 \n\n### Response: 3180.61 - -7868.88 = 3180.61 + 7868.88 = 11049.49']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7157.98 + -8238.21 \n\n### Response: 7157.98 + -8238.21 = -1080.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 359.19 * -7366.84 \n\n### Response: 359.19 * -7366.84 = -264298.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -809.94  2 \n\n### Response: -809.94 ** 2']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5049.65 / 9032.66 \n\n### Response: -5049.65 / 9032.66 = -0.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 126.99  1 \n\n### Response: 126.99  1  = 126.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 28  82%\n\n### Response:\xa0\n 28  82%28 * 1.82 = 50.96\n 50.96 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 60  21 \n\n### Response: \n = 60 * 21 = 1260 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7648.20 / -1462.33 \n\n### Response: -7648.20 / -1462.33 = 5.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5486.28 + -8198.83 \n\n### Response: 5486.28 + -8198.83 = -2712.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9628.09 - -9285.90 \n\n### Response: 9628.09 - -9285.90 = 9628.09 + 9285.90 = 18913.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 1.53  y = 15x^63 \n\n### Response: \n x = 1.53 y = 15 * 1.53^63 = 1.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9096.92 + -4287.79 \n\n### Response: 9096.92 + -4287.79 = 4809.13']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7872.21 / -5143.52 \n\n### Response: 7872.21 / -5143.52 = -1.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8408.81 + 5175.48 \n\n### Response: -8408.81 + 5175.48 = -3233.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6960.49 + -2479.37 \n\n### Response: 6960.49 + -2479.37 = 4481.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7114.90 / 5453.99 \n\n### Response: -7114.90 / 5453.99 = -1.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3069.64 + -4540.58 \n\n### Response: 3069.64 + -4540.58 = -1470.94']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[36, 23, 33, 56, 55, 72, 44]\n\n### Response: \n = 36 + 23 + 33 + 56 + 55 + 72 + 44 / 7 = 319 / 7 = 45.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 30  44 \n\n### Response: \n30 * 44 = 1320\n 1320 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7284.02 + -2762.62 \n\n### Response: 7284.02 + -2762.62 = 4521.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 18  34 \n\n### Response: \n 18 * 34 = 612 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[26, 41, 56, 79, 81, 5, 76]\n\n### Response: \n: 52.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6642.70 + 2293.71 \n\n### Response: -6642.70 + 2293.71 = -4348.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2836.04 + -6589.37 \n\n### Response: -9425.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2782.13 / 72.66 \n\n### Response: -2782.13 / 72.66 = -38.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3140.68 + 6112.77 \n\n### Response: 3140.68 + 6112.77 = 9253.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9 / 1 \n\n### Response: \n9 / * 1  = 9 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -700.22 / -8699.15 \n\n### Response: -700.22 / -8699.15 = 0.08']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -35x + 80 = 0\n\n### Response:  -35x = -80.0\n -35x / -35 = -80.0 / -35\n x = 2.29\n x = 2.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -413.93 * -3531.49 \n\n### Response: -413.93 * -3531.49 = 146355.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 941.34  2 \n\n### Response: 941.34 = 884,900.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4845.92 * -9135.70 \n\n### Response: -4845.92 * -9135.70 = 44272000.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 168.34  2 \n\n### Response: 168.34  2  = 168.34 * 168.34 = 28341.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8109.51 - 4209.08 \n\n### Response: 8109.51 - 4209.08 = 3900.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1163.03 - -9231.14 \n\n### Response: -1163.03 - -9231.14 = -1163.03 + 9231.14 = 8078.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7722.38 - 4159.92 \n\n### Response: 7722.38 - 4159.92 = 3562.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3815.76 / -6281.84 \n\n### Response: 3815.76 / -6281.84 = -0.61']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9927.99 - -4181.96 \n\n### Response: 9927.99 - -4181.96 = 9927.99 + 4181.96 = 14109.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5807.61 \n\n### Response: 5807.61  76.2']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4715.32 * -5259.47 \n\n### Response: 4715.32 * -5259.47 = -2481990.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5651.40 - -4831.27 \n\n### Response: 5651.40 - -4831.27 = 5651.40 + 4831.27 = 10482.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9194.16 + -5958.91 \n\n### Response: -15153.07']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 45.65 / 4297.83 \n\n### Response:45.65 / 4297.83 = 0.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9237.51 \n\n### Response: 9237.51  96.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4701.55 * 8769.06 \n\n### Response: -41277200.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 11x + 64 = 0\n\n### Response:  11x + 64 = 0  -64 / 11 = -5.82']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5851.95 * 2017.43 \n\n### Response: 5851.95 * 2017.43 = 11796500.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4342.43 + 8332.32 \n\n### Response: 4342.43 + 8332.32 = 12674.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -28x + 91 = 0\n\n### Response: -28x = -91.0\n-28x / -28 = 91.0 / -28\nx = -3.25']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 734.05 \n\n### Response: 734.05  27.13']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9576.85 / -7526.45 \n\n### Response: -9576.85 / -7526.45 = 9576.85 / 7526.45 = 1.27']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3286.03 * -8033.87 \n\n### Response: 3286.03 * -8033.87 = -26434100.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5462.74 + -8565.38 \n\n### Response: -14028.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4129.11 - -6919.07 \n\n### Response: 4129.11 - -6919.07 = 4129.11 + 6919.07 = 11048.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1437.03 + 2879.42 \n\n### Response: 1437.03 + 2879.42 = 4316.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3906.35 * 2271.03 \n\n### Response: 3906.35 * 2271.03 = 8879000.96']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6911.95 - 5700.39 \n\n### Response: 6911.95 - 5700.39 = 1211.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1908.46 + -4882.32 \n\n### Response: 1908.46 + -4882.32 = 1908.46 - 4882.32 = -2973.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3899.33 - 1603.27 \n\n### Response: 3899.33 - 1603.27 = 2296.06']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4917.70 - -3484.94 \n\n### Response: 4917.70 - -3484.94 = 4917.70 + 3484.94 = 8402.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -570.03 + 2854.20 \n\n### Response: -570.03 + 2854.20 = 2284.17']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9386.28 / 2862.76 \n\n### Response: 9386.28 / 2862.76 = 3.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[29, 21, 47]\n\n### Response: \n29 + 21 + 47 = 97\n97 / 3 = 32.33\n: 32.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3190.15 \n\n### Response:\xa0\n3190.15  56.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2998.34 * 3471.30 \n\n### Response: 2998.34 * 3471.30 = 1040982.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -617.68 * -3365.23 \n\n### Response: -2079009.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2012.37 / 1480.07 \n\n### Response: 2012.37 / 1480.07 = 1.36']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -453.61 - 8996.39 \n\n### Response: -4500.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8621.88 / 5012.04 \n\n### Response: -1.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 31x + 79 = 0\n\n### Response: \n 31x = -79\n 31x = -79 * 31\n x = -79 * 31 / 31\nx = -79\n -79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5401.27 + 3750.03 \n\n### Response: 5401.27 + 3750.03 = 9151.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3743.44 + 2044.79 \n\n### Response: 3743.44 + 2044.79 = 5788.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 561.81  3 \n\n### Response: 561.81 ** 3 = 194968.0003']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1  84 \n\n### Response:\xa0\n 1  84  = 1 - 84 / 1 = 0.16 = 16 %']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7132.91 * -2496.53 \n\n### Response: 7132.91 * -2496.53 = -17794801.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5181.89 * 1825.05 \n\n### Response: 5181.89 * 1825.05 = 9446192.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[12, 28, 21, 86, 56, 96]\n\n### Response: \n: 54.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 263.65  3 \n\n### Response:\xa0\n263.65 ** 3 = 182968.6']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -871.47  4 \n\n### Response: -871.47 ** 4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 538.10 / 4758.54 \n\n### Response: 538.10 / 4758.54 = 0.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3288.38 - 5111.78 \n\n### Response: -8399.16']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -979.16  5 \n\n### Response: -979.16 ** 5 = -979.16']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 264.95 \n\n### Response:\xa0\n264.95  16.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7233.93 * 5750.17 \n\n### Response: 7233.93 * 5750.17 = 41572000.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4363.54 + 8053.97 \n\n### Response: 4363.54 + 8053.97 = 12417.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6571.23 \n\n### Response: 81.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7728.88 * 7531.07 \n\n### Response: 7728.88 * 7531.07 = 5830002.99']}]
2024-07-26 16:12:27,690 - mindformers[mindformers/trainer/base_trainer.py:952] - INFO - output result is saved at: text_generation_result.txt
2024-07-26 16:12:27,690 - mindformers[mindformers/trainer/base_trainer.py:953] - INFO - .........Predict Over!.............
2024-07-26 16:12:27,691 - mindformers[mindformers/research/llama3/run_llama3_test.py:181] - INFO - [{'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7451.51 - -1709.92 \n\n### Response: -7451.51 - -1709.92 = -7451.51 + 1709.92 = -5741.59']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1337.47 + 5068.04 \n\n### Response: -1337.47 + 5068.04 = 3730.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6211.70 * -6871.61 \n\n### Response: -6211.70 * -6871.61 = 4267342.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3985.41 - -8173.86 \n\n### Response: -3985.41 - -8173.86 = -3985.41 + 8173.86 = 4188.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1075.16 - 8090.56 \n\n### Response: 1075.16 - 8090.56 = -7015.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9299.25 * 1012.66 \n\n### Response: -9299.25 * 1012.66 = -9416198.71']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2864.35 - -8690.01 \n\n### Response: -2864.35 - -8690.01 = -2864.35 + 8690.01 = 5825.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7310.69 + -6470.86 \n\n### Response: 7310.69 + -6470.86 = 840.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3476.06 + 2490.05 \n\n### Response: -3476.06 + 2490.05 = -984.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 19  71 \n\n### Response:\xa0\n 19  71 \n= 71 / 19 = 3.73\n 3.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1647.72 * -2175.26 \n\n### Response: 1647.72 * -2175.26 = -3578.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -13x + 10 = 0\n\n### Response: -13x = -10.0\n\n-10.0\n-10.0\n\n-10.0\n-10.0\n\n-10.0\n-10.0\n']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1980.46 - -4548.03 \n\n### Response: -1980.46 - -4548.03 = -1980.46 + 4548.03 = 2567.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9349.89 + 8736.20 \n\n### Response: -9349.89 + 8736.20 = -612.69']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7881.79 + -3132.78 \n\n### Response: -11014.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7374.53 * -4084.42 \n\n### Response: 7374.53 * -4084.42 = -3013662.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6811.55 - 2494.54 \n\n### Response: 6811.55 - 2494.54 = 4317.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6974.95 \n\n### Response:\xa0\n6974.95  83.6']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3957.83 - 3083.39 \n\n### Response: -7041.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8230.71 - 2598.23 \n\n### Response:\xa0\n8230.71 - 2598.23 = 5632.48']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 53x + 27 = 0\n\n### Response:  53x + 27 = 0  53x = -27.  x = -27 / 53 = -0.51.  -0.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2670.86 / 8327.57 \n\n### Response: 2670.86 / 8327.57 = 0.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1295.35 + 7059.64 \n\n### Response: -1295.35 + 7059.64 = 5764.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5113.34 - 239.46 \n\n### Response: 5113.34 - 239.46 = 4873.88']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4157.45 \n\n### Response: 64.78']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8141.51 - -9883.79 \n\n### Response: -8141.51 - -9883.79 = -8141.51 + 9883.79 = 1742.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3619.12 + -4630.69 \n\n### Response: 3619.12 + -4630.69 = -1011.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 50  42 \n\n### Response:\xa0\n 50  42 \n = (50 - 42) / 50 = 0.16\n = 0.16 * 100% = 16%']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -337.33  2 \n\n### Response: -337.33 ** 2 = 113,898.68']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 56  20 \n\n### Response:\xa0\n 56  20 \n= 56 - 20\n= 36\n = 36 / 56\n= 0.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5x + -100 = 0\n\n### Response:  -5x = 100.  x = 100 / -5 = -20.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8115.42 / -8891.52 \n\n### Response: 8115.42 / -8891.52 = -0.91']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4670.73 + 5116.49 \n\n### Response: 4670.73 + 5116.49 = 9787.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2921.61 - -426.91 \n\n### Response: 2921.61 - -426.91 = 2921.61 + 426.91 = 3348.52']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 47  12 \n\n### Response:\xa0\n 47  12 \n47 - 12 = 35\n35 / 47 = 0.74\n0.74 * 100 = 74.0\n 74.0 %']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4023.23 + -4657.63 \n\n### Response: 4023.23 + -4657.63 = -636.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6365.40 \n\n### Response:\xa0\n6365.40  79.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6402.63 + 9129.29 \n\n### Response: -6402.63 + 9129.29 = 2726.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8049.63 \n\n### Response:8049.63  89.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8874.39 / -5271.14 \n\n### Response: 8874.39 / -5271.14 = -1.68']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -721.97  1 \n\n### Response: -721.97 ** 1 = -721.97']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -33x + 79 = 0\n\n### Response: -33x = -79.0\n\n-79.0\n-79.0\n\n-79.0\n-79.0\n-33x = -79.0\n\n-79.0\n-79.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5396.67 + -7513.38 \n\n### Response: 5396.67 + -7513.38 = -2116.71']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5555.48 - 2227.05 \n\n### Response: -7782.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3585.58 * -7185.14 \n\n### Response: 3585.58 * -7185.14 = -2577341.97']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8326.91 + 8323.56 \n\n### Response: 8326.91 + 8323.56 = 16650.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6412.43 + 8195.96 \n\n### Response: 6412.43 + 8195.96 = 14608.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 48  7 \n\n### Response: \n 48 * 7 = 336 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2068.77 + -1347.07 \n\n### Response: -3415.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 0.64  y = 93x^80 \n\n### Response: \n x = 0.64 y = 93x^80 = 93 * 0.64^80 = 0.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -44x + 70 = 0\n\n### Response: -44x = -70.0\n0-44x-70.0 / -44 = 1.59\n0-44x-70.0 / -44 = 1.59\n0-44x-70.0 / -44 = 1.59\n0-44x-70.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5351.95 + -9780.91 \n\n### Response: -15132.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6585.23 * -469.39 \n\n### Response: 6585.23 * -469.39 = -3090.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5591.19 / -7097.76 \n\n### Response: 5591.19 / -7097.76 = -0.79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2910.65 * -4198.96 \n\n### Response: 2910.65 * -4198.96 = -122200.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5861.56 - -6927.43 \n\n### Response: -5861.56 - -6927.43 = -5861.56 + 6927.43 = 1065.87']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5452.84 / -2723.07 \n\n### Response: -5452.84 / -2723.07 = 2.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8508.06 / 4921.11 \n\n### Response: 8508.06 / 4921.11 = 1.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3859.13 + 8440.41 \n\n### Response: -3859.13 + 8440.41 = 4581.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6983.88 - -8060.14 \n\n### Response: -6983.88 - -8060.14 = -6983.88 + 8060.14 = 1076.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[17, 99, 52]\n\n### Response: \n17 + 99 + 52 = 168\n168 / 3 = 56.0\n: 56.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 680.12  3 \n\n### Response:\xa0\n680.12 ** 3 = 404.963.552']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -97x + -92 = 0\n\n### Response:  -97x + -92 = 0 x = 0.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 123.84  1 \n\n### Response: 123.84  1  = 123.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5708.06 \n\n### Response:\xa0\n5708.06  75.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7194.48 * -6220.64 \n\n### Response: -7194.48 * -6220.64 = 4475232.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8830.69 * -1065.17 \n\n### Response: 8830.69 * -1065.17 = -9394.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1855.82 - 1345.12 \n\n### Response: 1855.82 - 1345.12 = 510.7']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8.74 * -9037.79 \n\n### Response: 8.74 * -9037.79 = -79000.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3321.89 * -3531.67 \n\n### Response: -3321.89 * -3531.67 = 1174152.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3460.04 - -315.20 \n\n### Response: 3460.04 - -315.20 = 3460.04 + 315.20 = 3775.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6185.13 - 2193.41 \n\n### Response:\xa0\n6185.13 - 2193.41 = 3991.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5208.71 / 3443.94 \n\n### Response: -5208.71 / 3443.94 = -1.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1432.15 + -7448.73 \n\n### Response: 1432.15 + -7448.73 = -6016.58']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7375.26 * -8346.62 \n\n### Response: -7375.26 * -8346.62 = 6157342.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1552.54 / 6004.21 \n\n### Response: -1552.54 / 6004.21 = -0.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2508.22 / -8899.74 \n\n### Response: -2508.22 / -8899.74 = 0.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3459.21 * 4229.30 \n\n### Response: -3459.21 * 4229.30 = -1459450.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[71, 54, 62, 70, 53]\n\n### Response: \n71 + 54 + 62 + 70 + 53 = 310\n310 / 5 = 62.0\n: 62.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -368.19  4 \n\n### Response: -368.19 ** 4 = -368.19 * -368.19 * -368.19 * -368.19 = 533531.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9245.32 * 2915.01 \n\n### Response: -9245.32 * 2915.01 = -26924200.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3362.63 * 7545.83 \n\n### Response: 3362.63 * 7545.83 = 25376500.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -514.60 / 293.74 \n\n### Response: -514.60 / 293.74 = -1.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -80x + 94 = 0\n\n### Response:  -80x = -94.0\nx = -94.0 / -80\nx = 1.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3279.11 - 7172.93 \n\n### Response: -3279.11 - 7172.93 = -10452.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9247.11 - 7331.30 \n\n### Response: -16578.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1738.37 + 4806.48 \n\n### Response: -1738.37 + 4806.48 = 3068.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 10.63  2 \n\n### Response: 10.63  2  = 10.63 * 10.63 = 112.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7735.89 + 3030.00 \n\n### Response: -7705.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1058.80 * -607.50 \n\n### Response: -1058.80 * -607.50 = 644.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -430.88 - 1101.44 \n\n### Response: -430.88 - 1101.44 = -1532.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1923.64 - 8110.60 \n\n### Response: -10034.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 282.03 \n\n### Response: 282.03  16.77']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3124.14 / 1192.09 \n\n### Response: -2.63']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2666.20 * 110.52 \n\n### Response: 2666.20 * 110.52 = 294299.296']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 4.77  y = 86x^97 \n\n### Response: \n x = 4.77 y = 86 * 4.77^97 = 1.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7781.42 / -5327.71 \n\n### Response: -7781.42 / -5327.71 = 1.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[27, 89, 99, 64, 76, 50, 100, 49]\n\n### Response: \n: 72.25']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4294.20 + 9857.73 \n\n### Response: -4294.20 + 9857.73 = 5563.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1214.14 - 1182.21 \n\n### Response: -2396.35']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 475.47  5 \n\n### Response: 475.47 ** 5 = 1129682.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5078.04 - 8883.67 \n\n### Response: 5078.04 - 8883.67 = -3805.63']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2023.47 - 1907.67 \n\n### Response: -3931.14']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2x + 60 = 0\n\n### Response:  2x = -60.0x = -60.0 / 2 = -30.0 -30.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5415.08 / 8305.15 \n\n### Response: 5415.08 / 8305.15 = 0.65']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2356.30 + 9645.15 \n\n### Response: 2356.30 + 9645.15 = 12001.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 676.46  2 \n\n### Response: 676.46  2  = 676.46 * 676.46 = 459,599.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7076.54 / -2319.93 \n\n### Response: 7076.54 / -2319.93 = -3.05']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -101.17 * -8210.19 \n\n### Response: -101.17 * -8210.19 = 830.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -67x + -29 = 0\n\n### Response:  -67x + -29 = 0 x = 0.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4415.70 - -2186.85 \n\n### Response: 4415.70 - -2186.85 = 4415.70 + 2186.85 = 6602.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -513.32  3 \n\n### Response: -513.32 ** 3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3180.61 - -7868.88 \n\n### Response: 3180.61 - -7868.88 = 3180.61 + 7868.88 = 11049.49']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7157.98 + -8238.21 \n\n### Response: 7157.98 + -8238.21 = -1080.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 359.19 * -7366.84 \n\n### Response: 359.19 * -7366.84 = -264298.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -809.94  2 \n\n### Response: -809.94 ** 2']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5049.65 / 9032.66 \n\n### Response: -5049.65 / 9032.66 = -0.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 126.99  1 \n\n### Response: 126.99  1  = 126.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 28  82%\n\n### Response:\xa0\n 28  82%28 * 1.82 = 50.96\n 50.96 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 60  21 \n\n### Response: \n = 60 * 21 = 1260 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7648.20 / -1462.33 \n\n### Response: -7648.20 / -1462.33 = 5.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5486.28 + -8198.83 \n\n### Response: 5486.28 + -8198.83 = -2712.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9628.09 - -9285.90 \n\n### Response: 9628.09 - -9285.90 = 9628.09 + 9285.90 = 18913.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 1.53  y = 15x^63 \n\n### Response: \n x = 1.53 y = 15 * 1.53^63 = 1.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9096.92 + -4287.79 \n\n### Response: 9096.92 + -4287.79 = 4809.13']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7872.21 / -5143.52 \n\n### Response: 7872.21 / -5143.52 = -1.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8408.81 + 5175.48 \n\n### Response: -8408.81 + 5175.48 = -3233.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6960.49 + -2479.37 \n\n### Response: 6960.49 + -2479.37 = 4481.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7114.90 / 5453.99 \n\n### Response: -7114.90 / 5453.99 = -1.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3069.64 + -4540.58 \n\n### Response: 3069.64 + -4540.58 = -1470.94']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[36, 23, 33, 56, 55, 72, 44]\n\n### Response: \n = 36 + 23 + 33 + 56 + 55 + 72 + 44 / 7 = 319 / 7 = 45.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 30  44 \n\n### Response: \n30 * 44 = 1320\n 1320 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7284.02 + -2762.62 \n\n### Response: 7284.02 + -2762.62 = 4521.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 18  34 \n\n### Response: \n 18 * 34 = 612 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[26, 41, 56, 79, 81, 5, 76]\n\n### Response: \n: 52.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6642.70 + 2293.71 \n\n### Response: -6642.70 + 2293.71 = -4348.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2836.04 + -6589.37 \n\n### Response: -9425.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2782.13 / 72.66 \n\n### Response: -2782.13 / 72.66 = -38.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3140.68 + 6112.77 \n\n### Response: 3140.68 + 6112.77 = 9253.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9 / 1 \n\n### Response: \n9 / * 1  = 9 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -700.22 / -8699.15 \n\n### Response: -700.22 / -8699.15 = 0.08']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -35x + 80 = 0\n\n### Response:  -35x = -80.0\n -35x / -35 = -80.0 / -35\n x = 2.29\n x = 2.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -413.93 * -3531.49 \n\n### Response: -413.93 * -3531.49 = 146355.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 941.34  2 \n\n### Response: 941.34 = 884,900.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4845.92 * -9135.70 \n\n### Response: -4845.92 * -9135.70 = 44272000.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 168.34  2 \n\n### Response: 168.34  2  = 168.34 * 168.34 = 28341.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8109.51 - 4209.08 \n\n### Response: 8109.51 - 4209.08 = 3900.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1163.03 - -9231.14 \n\n### Response: -1163.03 - -9231.14 = -1163.03 + 9231.14 = 8078.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7722.38 - 4159.92 \n\n### Response: 7722.38 - 4159.92 = 3562.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3815.76 / -6281.84 \n\n### Response: 3815.76 / -6281.84 = -0.61']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9927.99 - -4181.96 \n\n### Response: 9927.99 - -4181.96 = 9927.99 + 4181.96 = 14109.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5807.61 \n\n### Response: 5807.61  76.2']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4715.32 * -5259.47 \n\n### Response: 4715.32 * -5259.47 = -2481990.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5651.40 - -4831.27 \n\n### Response: 5651.40 - -4831.27 = 5651.40 + 4831.27 = 10482.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9194.16 + -5958.91 \n\n### Response: -15153.07']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 45.65 / 4297.83 \n\n### Response:45.65 / 4297.83 = 0.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9237.51 \n\n### Response: 9237.51  96.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4701.55 * 8769.06 \n\n### Response: -41277200.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 11x + 64 = 0\n\n### Response:  11x + 64 = 0  -64 / 11 = -5.82']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5851.95 * 2017.43 \n\n### Response: 5851.95 * 2017.43 = 11796500.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4342.43 + 8332.32 \n\n### Response: 4342.43 + 8332.32 = 12674.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -28x + 91 = 0\n\n### Response: -28x = -91.0\n-28x / -28 = 91.0 / -28\nx = -3.25']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 734.05 \n\n### Response: 734.05  27.13']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9576.85 / -7526.45 \n\n### Response: -9576.85 / -7526.45 = 9576.85 / 7526.45 = 1.27']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3286.03 * -8033.87 \n\n### Response: 3286.03 * -8033.87 = -26434100.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5462.74 + -8565.38 \n\n### Response: -14028.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4129.11 - -6919.07 \n\n### Response: 4129.11 - -6919.07 = 4129.11 + 6919.07 = 11048.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1437.03 + 2879.42 \n\n### Response: 1437.03 + 2879.42 = 4316.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3906.35 * 2271.03 \n\n### Response: 3906.35 * 2271.03 = 8879000.96']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6911.95 - 5700.39 \n\n### Response: 6911.95 - 5700.39 = 1211.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1908.46 + -4882.32 \n\n### Response: 1908.46 + -4882.32 = 1908.46 - 4882.32 = -2973.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3899.33 - 1603.27 \n\n### Response: 3899.33 - 1603.27 = 2296.06']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4917.70 - -3484.94 \n\n### Response: 4917.70 - -3484.94 = 4917.70 + 3484.94 = 8402.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -570.03 + 2854.20 \n\n### Response: -570.03 + 2854.20 = 2284.17']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9386.28 / 2862.76 \n\n### Response: 9386.28 / 2862.76 = 3.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[29, 21, 47]\n\n### Response: \n29 + 21 + 47 = 97\n97 / 3 = 32.33\n: 32.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3190.15 \n\n### Response:\xa0\n3190.15  56.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2998.34 * 3471.30 \n\n### Response: 2998.34 * 3471.30 = 1040982.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -617.68 * -3365.23 \n\n### Response: -2079009.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2012.37 / 1480.07 \n\n### Response: 2012.37 / 1480.07 = 1.36']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -453.61 - 8996.39 \n\n### Response: -4500.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8621.88 / 5012.04 \n\n### Response: -1.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 31x + 79 = 0\n\n### Response: \n 31x = -79\n 31x = -79 * 31\n x = -79 * 31 / 31\nx = -79\n -79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5401.27 + 3750.03 \n\n### Response: 5401.27 + 3750.03 = 9151.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3743.44 + 2044.79 \n\n### Response: 3743.44 + 2044.79 = 5788.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 561.81  3 \n\n### Response: 561.81 ** 3 = 194968.0003']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1  84 \n\n### Response:\xa0\n 1  84  = 1 - 84 / 1 = 0.16 = 16 %']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7132.91 * -2496.53 \n\n### Response: 7132.91 * -2496.53 = -17794801.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5181.89 * 1825.05 \n\n### Response: 5181.89 * 1825.05 = 9446192.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[12, 28, 21, 86, 56, 96]\n\n### Response: \n: 54.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 263.65  3 \n\n### Response:\xa0\n263.65 ** 3 = 182968.6']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -871.47  4 \n\n### Response: -871.47 ** 4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 538.10 / 4758.54 \n\n### Response: 538.10 / 4758.54 = 0.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3288.38 - 5111.78 \n\n### Response: -8399.16']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -979.16  5 \n\n### Response: -979.16 ** 5 = -979.16']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 264.95 \n\n### Response:\xa0\n264.95  16.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7233.93 * 5750.17 \n\n### Response: 7233.93 * 5750.17 = 41572000.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4363.54 + 8053.97 \n\n### Response: 4363.54 + 8053.97 = 12417.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6571.23 \n\n### Response: 81.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7728.88 * 7531.07 \n\n### Response: 7728.88 * 7531.07 = 5830002.99']}]
