/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
********************** infer list len:  200
2024-07-26 22:51:48,100 - mindformers[mindformers/trainer/trainer.py:919] - INFO - Load configs in /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml to build trainer.
2024-07-26 22:51:48,101 - mindformers[mindformers/trainer/trainer.py:949] - INFO - ..........Init Config..........
2024-07-26 22:51:48,101 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': True, 'select_recompute': False, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}
2024-07-26 22:51:48,102 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 1, 'model_parallel': 1, 'pipeline_stage': 1, 'use_seq_parallel': False, 'micro_batch_num': 1, 'vocab_emb_dp': True, 'gradient_aggregation_group': 4}
2024-07-26 22:51:48,102 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/research/output'
2024-07-26 22:51:48,103 - mindformers[mindformers/tools/utils.py:168] - INFO - set strategy path to './output/strategy/ckpt_strategy_rank_0.ckpt'
2024-07-26 22:51:48,103 - mindformers[mindformers/trainer/base_trainer.py:85] - INFO - Now Running Task is: text_generation, Model is: llama3_8b
2024-07-26 22:51:48,103 - mindformers[mindformers/trainer/base_trainer.py:111] - WARNING - Input model name is not in the supported list or unspecified.
2024-07-26 22:51:48,103 - mindformers[mindformers/trainer/base_trainer.py:112] - WARNING - See the list of supported task and model name: ['baichuan2_13b', 'baichuan2_7b', 'baichuan_7b', 'bloom_176b', 'bloom_560m', 'bloom_65b', 'bloom_7.1b', 'codegeex2_6b', 'codellama_34b', 'common', 'deepseek_33b', 'glm2_6b', 'glm2_6b_lora', 'glm2_6b_ptuning2', 'glm3_6b', 'glm_6b', 'glm_6b_chat', 'glm_6b_lora', 'glm_6b_lora_chat', 'gpt2', 'gpt2_13b', 'gpt2_52b', 'gpt2_lora', 'gpt2_xl', 'gpt2_xl_lora', 'internlm_7b', 'internlm_7b_lora', 'llama2_13b', 'llama2_70b', 'llama2_7b', 'llama_13b', 'llama_65b', 'llama_7b', 'llama_7b_lora', 'pangualpha_13b', 'pangualpha_2_6b', 'qwen_7b', 'qwen_7b_lora', 'skywork_13b', 'yi_34b', 'yi_6b', 'ziya_13b']
2024-07-26 22:51:48,104 - mindformers[mindformers/trainer/base_trainer.py:113] - WARNING - The default model config: /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml will now be used for the text_generation task 
2024-07-26 22:51:48,104 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-07-26 22:51:48,104 - mindformers[mindformers/trainer/trainer.py:335] - INFO - ==========Trainer Init Success!==========
2024-07-26 22:51:48,104 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-07-26 22:51:48,105 - mindformers[mindformers/trainer/base_trainer.py:213] - INFO - The current parallel mode is stand_alone, batch size per card will not be changed: batch_size_per_card = 1
2024-07-26 22:51:48,105 - mindformers[mindformers/trainer/base_trainer.py:217] - INFO - global_batch_size = batch_size_per_card * device_num * gradient_accumulation_steps = 1 = 1 * 1 * 1
2024-07-26 22:51:48,105 - mindformers[mindformers/trainer/base_trainer.py:226] - INFO - parallel_config will be change to default config: [ParallelConfig]
_recompute:[ParallelConfig]
_recompute:True
_select_recompute:False
_select_comm_recompute:False
_parallel_optimizer_comm_recompute:False
_mp_comm_recompute:True
_recompute_slice_activation:True

select_recompute:False
use_seq_parallel:False
_optimizer_shard:None
_gradient_aggregation_group:4
_embed_dp_mp_config:[ParallelConfig]
_dp_mp_config:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_vocab_emb_dp:True
use_seq_parallel:False
select_recompute:False

_pp_config:[ParallelConfig]
_pipeline_stage:1
_micro_batch_num:1

_moe_config:[ParallelConfig]
_dpmp:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False

_expert_parallel:1
use_seq_parallel:False
select_recompute:False

.
2024-07-26 22:51:48,106 - mindformers[mindformers/trainer/base_trainer.py:387] - INFO - .........Build Network From Config..........
2024-07-26 22:51:48,106 - mindformers[mindformers/version_control.py:61] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1
2024-07-26 22:51:48,107 - mindformers[mindformers/version_control.py:65] - INFO - 
The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: 
export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.
2024-07-26 22:51:48,107 - mindformers[mindformers/version_control.py:71] - INFO - The Cell Reuse compilation acceleration feature does not support single-card mode.This feature is disabled by default. ENABLE_CELL_REUSE=1 does not take effect.
2024-07-26 22:51:48,107 - mindformers[mindformers/version_control.py:74] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.
[WARNING] DEVICE(186972,ffff9c8f8010,python):2024-07-26-22:51:48.373.985 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:95] Initialize] Reserved memory size for other components(536870912) is less than recommend size(1891084032), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory'
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:52:09.814.100 [mindspore/ops/primitive.py:203] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. 
If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL)
2024-07-26 22:52:16,164 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:52:16.167.396 [mindspore/common/_decorator.py:40] 'Parameter' is deprecated from version 2.3 and will be removed in a future version, use 'add_pipeline_stage' instead.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:52:16.167.617 [mindspore/common/parameter.py:806] This interface may be deleted in the future.
2024-07-26 22:52:16,274 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:16,383 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:16,491 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:16,599 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:16,707 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:16,815 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:16,923 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:17,033 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:17,141 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-26 22:52:25,531 - mindformers[mindformers/models/modeling_utils.py:1438] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
2024-07-26 22:52:25,531 - mindformers[mindformers/models/modeling_utils.py:591] - INFO - Set jit config for jit level:O0 and infer boost:on.
2024-07-26 22:52:28,392 - mindformers[mindformers/models/modeling_utils.py:1438] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
[INFO] 2024-07-26 22:52:28,394 [186972] [SDK] : Start to freeze model for delta, mode: lora, include list: None, exclude list: None
[INFO] 2024-07-26 22:52:28,395 [186972] [SDK] : Start to freeze model, include list: ['*'], exclude list: ['*mindpet_delta_lora*']
[INFO] 2024-07-26 22:52:28,402 [186972] [SDK] : End to freeze model.
[INFO] 2024-07-26 22:52:28,402 [186972] [SDK] : End to freeze model for delta.
2024-07-26 22:52:28,403 - mindformers[mindformers/models/modeling_utils.py:591] - INFO - Set jit config for jit level:O0 and infer boost:on.
2024-07-26 22:52:28,419 - mindformers[mindformers/trainer/base_trainer.py:543] - INFO - Network Parameters: 3407872.
2024-07-26 22:52:29,622 - mindformers[mindformers/trainer/utils.py:736] - INFO - ............Start load checkpoint from checkpoint............
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:07.635.332 [mindspore/train/serialization.py:195] The type of model.tok_embeddings.embedding_weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:21.209.069 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:21.774.776 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:22.150.34 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:22.676.068 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:25.443.07 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:28.365.562 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:31.813.985 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:33.739.499 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:34.273.077 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:34.535.356 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:35.190.142 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:37.776.071 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:41.280.708 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:44.837.496 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:46.786.135 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:47.343.289 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:47.569.148 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:48.231.242 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:50.887.451 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:54.207.497 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:57.589.045 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:54:59.567.757 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:00.148.847 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:00.374.705 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:01.533.51 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:03.743.298 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:07.766.5 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:10.283.174 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:12.253.206 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:12.795.361 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:13.212.10 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:13.676.776 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:16.350.338 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:19.705.160 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:22.997.113 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:25.541.5 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:25.532.037 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:25.804.622 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:26.499.555 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:29.142.896 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:32.584.696 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:35.899.589 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:37.862.149 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:38.395.922 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:38.626.819 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:39.302.622 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:41.682.715 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:45.129.084 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:48.866.723 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:50.823.619 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:51.360.205 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:51.604.079 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:52.242.120 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:54.650.458 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:55:57.966.800 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:01.481.899 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:03.525.995 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:04.694.01 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:04.302.544 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:04.954.883 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:07.626.472 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:11.122.549 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:14.618.960 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:16.559.160 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:17.112.773 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:17.341.348 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:17.992.336 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:20.375.211 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:23.934.496 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:27.250.213 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:29.235.914 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:29.785.603 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:30.165.41 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:30.686.393 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:33.457.68 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:36.804.305 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:40.133.744 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:42.596.26 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:42.586.528 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:42.820.055 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:43.488.328 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:45.838.694 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:49.235.608 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:52.557.721 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:54.520.078 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:55.458.47 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:55.282.939 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:55.923.108 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:56:58.284.132 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:01.817.175 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:05.242.459 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:07.173.154 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:07.720.598 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:07.973.011 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:08.604.911 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:10.961.448 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:14.289.281 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:17.824.561 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:19.780.957 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:20.337.147 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:20.567.334 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:21.228.130 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:23.598.592 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:26.977.614 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:30.316.131 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:32.263.659 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:32.797.145 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:33.451.76 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:33.710.352 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:36.196.917 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:39.600.377 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:42.899.968 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:44.843.730 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:45.391.246 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:45.626.185 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:46.261.796 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:48.610.403 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:51.891.962 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:55.244.694 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:57.219.229 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:57.752.115 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:57.989.788 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:57:58.642.050 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:01.280.5 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:04.298.877 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:07.593.499 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:09.698.135 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:10.336.968 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:10.566.688 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:11.218.092 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:13.810.744 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:17.175.544 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:20.509.859 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:22.524.001 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:23.104.676 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:23.336.245 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:24.311.01 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:26.402.093 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:29.768.482 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:33.982.56 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:35.386.83 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:35.588.872 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:35.818.386 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:36.463.629 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:38.905.861 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:42.241.782 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:45.558.125 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:47.493.125 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:48.310.80 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:48.259.741 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:48.922.281 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:51.341.254 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:54.680.388 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:58:58.125.244 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:00.106.462 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:00.639.711 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:00.887.931 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:01.544.375 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:03.863.061 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:07.185.316 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:10.563.050 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:12.495.808 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:13.456.87 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:13.279.576 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:13.941.984 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:16.313.231 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:19.743.502 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:23.131.299 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:25.178.191 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:25.708.148 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:25.952.797 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:26.613.290 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:28.979.569 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:32.348.335 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:36.177.172 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:38.256.536 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:38.818.185 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:39.505.23 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:39.714.206 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:42.434.77 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:45.345.003 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:48.656.028 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:50.590.465 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:51.111.877 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:51.342.470 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:51.994.320 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:54.436.540 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-22:59:57.817.107 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:01.220.325 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:03.187.159 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:03.746.555 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:03.997.144 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:04.660.300 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:07.235.28 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:10.517.122 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:13.959.450 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:15.886.675 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:16.428.578 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:16.656.835 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:17.330.369 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:19.714.542 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:23.284.036 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:26.799.398 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:28.821.838 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:29.366.672 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:29.602.660 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:30.259.508 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:32.661.417 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:35.985.792 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:39.357.554 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:41.310.678 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:41.883.559 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:42.178.894 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:42.837.815 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:45.938.373 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:49.447.051 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:52.877.256 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:54.817.368 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:55.421.334 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:55.649.627 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:56.317.114 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:00:58.703.427 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:01:02.573.54 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:01:05.486.168 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:01:25.753.896 [mindspore/train/serialization.py:195] The type of lm_head.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:01:39.770.027 [mindspore/train/serialization.py:1456] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.
[WARNING] ME(186972:281473308393488,MainProcess):2024-07-26-23:01:39.770.376 [mindspore/train/serialization.py:1460] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded.
2024-07-26 23:01:39,770 - mindformers[mindformers/trainer/utils.py:767] - INFO - Network parameters are not loaded: (['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'], [])
{'auto_trans_ckpt': False,
 'auto_tune': False,
 'autotune_per_step': 10,
 'callbacks': [OrderedDict([('type', 'MFLossMonitor')]),
               OrderedDict([('type', 'CheckpointMointor'),
                            ('prefix', 'llama3_8b'),
                            ('save_checkpoint_steps', 1400),
                            ('integrated_save', False),
                            ('async_save', False)]),
               OrderedDict([('type', 'ObsMonitor')])],
 'context': {'device_id': 0,
             'device_target': 'Ascend',
             'enable_graph_kernel': False,
             'graph_kernel_flags': '--disable_expand_ops=Softmax,Dropout '
                                   '--enable_parallel_fusion=true '
                                   '--reduce_fuse_depth=8 '
                                   '--enable_auto_tensor_inplace=true',
             'max_call_depth': 10000,
             'runtime_num_threads': 1,
             'save_graphs': False,
             'save_graphs_path': './graph'},
 'device_num': 1,
 'do_eval': False,
 'eval_callbacks': [OrderedDict([('type', 'ObsMonitor')])],
 'eval_dataset': {'auto_tune': False,
                  'autotune_per_step': 10,
                  'batch_size': 1,
                  'data_loader': {'dataset_dir': '',
                                  'shuffle': False,
                                  'type': 'MindDataset'},
                  'do_eval': True,
                  'drop_remainder': False,
                  'filepath_prefix': './autotune',
                  'input_columns': ['input_ids'],
                  'num_parallel_workers': 1,
                  'numa_enable': False,
                  'output_columns': ['input_ids'],
                  'prefetch_size': 1,
                  'profile': False,
                  'python_multiprocessing': False,
                  'repeat': 1,
                  'seed': 0},
 'eval_dataset_task': {'dataset_config': {'auto_tune': False,
                                          'autotune_per_step': 10,
                                          'batch_size': 1,
                                          'data_loader': {'dataset_dir': '',
                                                          'shuffle': False,
                                                          'type': 'MindDataset'},
                                          'do_eval': True,
                                          'drop_remainder': False,
                                          'filepath_prefix': './autotune',
                                          'input_columns': ['input_ids'],
                                          'num_parallel_workers': 1,
                                          'numa_enable': False,
                                          'output_columns': ['input_ids'],
                                          'prefetch_size': 1,
                                          'profile': False,
                                          'python_multiprocessing': False,
                                          'repeat': 1,
                                          'seed': 0},
                       'type': 'CausalLanguageModelDataset'},
 'filepath_prefix': './autotune',
 'init_start_profile': False,
 'layer_decay': 0.65,
 'layer_scale': False,
 'load_checkpoint': '/home/ma-user/work/mindformers/research/output/checkpoint_network/rank_0/llama3_8b_rank_0-network.ckpt',
 'local_rank': 0,
 'lr_scale_factor': 256,
 'metric': [{'type': 'PerplexityMetric'}],
 'micro_batch_interleave_num': 1,
 'model': {'arch': {'type': 'LlamaForCausalLM'},
           'model_config': {'batch_size': 1,
                            'block_size': 64,
                            'bos_token_id': 128000,
                            'checkpoint_name_or_path': None,
                            'compute_dtype': 'float16',
                            'do_sample': False,
                            'eos_token_id': 128001,
                            'extend_method': 'None',
                            'fine_grain_interleave': 1,
                            'hidden_size': 4096,
                            'ignore_token_id': -100,
                            'intermediate_size': 14336,
                            'is_dynamic': False,
                            'layernorm_compute_type': 'float32',
                            'max_decode_length': 128,
                            'max_new_tokens': 128,
                            'min_new_tokens': 1,
                            'n_kv_heads': 8,
                            'num_heads': 32,
                            'num_layers': 32,
                            'offset': 0,
                            'pad_token_id': 128002,
                            'param_init_type': 'float16',
                            'pet_config': {'lora_alpha': 16,
                                           'lora_dropout': 0.0,
                                           'lora_rank': 8,
                                           'target_modules': '.*wq|.*wv'},
                            'repetition_penalty': 1,
                            'rms_norm_eps': 1e-05,
                            'rotary_dtype': 'float32',
                            'scaling_factor': 1.0,
                            'seq_length': 256,
                            'softmax_compute_type': 'float32',
                            'theta': 500000,
                            'top_k': 3,
                            'top_p': 1,
                            'type': 'LlamaConfig',
                            'use_flash_attention': True,
                            'use_past': True,
                            'vocab_size': 128256}},
 'moe_config': <mindformers.modules.transformer.moe.MoEConfig object at 0xfffe91eccc70>,
 'only_save_strategy': False,
 'output_dir': './output',
 'parallel': {'enable_alltoall': False,
              'enable_parallel_optimizer': True,
              'full_batch': True,
              'gradients_mean': False,
              'parallel_mode': 1,
              'parallel_optimizer_config': {'gradient_accumulation_shard': False,
                                            'parallel_optimizer_threshold': 64},
              'search_mode': 'sharding_propagation',
              'strategy_ckpt_config': {'only_trainable_params': False,
                                       'save_file': './ckpt_strategy.ckpt'},
              'strategy_ckpt_save_file': './output/strategy/ckpt_strategy_rank_0.ckpt'},
 'parallel_config': <mindformers.modules.transformer.transformer.TransformerOpParallelConfig object at 0xfffdfc547520>,
 'processor': {'return_tensors': 'ms',
               'tokenizer': {'model_max_length': 8192,
                             'pad_token': '<|reserved_special_token_0|>',
                             'type': 'Llama3Tokenizer',
                             'vocab_file': '/home/ma-user/work/tokenizer.model'},
               'type': 'LlamaProcessor'},
 'profile': False,
 'profile_communication': False,
 'profile_memory': True,
 'profile_start_step': 4,
 'profile_stop_step': 8,
 'rank_id': 0,
 'recompute_config': <mindformers.modules.transformer.transformer.TransformerRecomputeConfig object at 0xfffdfc547220>,
 'remote_save_url': '',
 'resume_training': False,
 'run_mode': 'predict',
 'runner_config': {'batch_size': 1,
                   'epochs': 1,
                   'gradient_accumulation_steps': 1,
                   'sink_mode': True,
                   'sink_size': 2},
 'runner_wrapper': {'scale_sense': 1.0,
                    'type': 'MFTrainOneStepCell',
                    'use_clip_grad': True},
 'seed': 0,
 'src_strategy_path_or_dir': '',
 'train_dataset': {'auto_tune': False,
                   'autotune_per_step': 10,
                   'batch_size': 1,
                   'data_loader': {'dataset_dir': '',
                                   'shuffle': True,
                                   'type': 'MindDataset'},
                   'do_eval': False,
                   'drop_remainder': True,
                   'filepath_prefix': './autotune',
                   'input_columns': ['input_ids', 'labels'],
                   'num_parallel_workers': 1,
                   'numa_enable': False,
                   'output_columns': ['input_ids', 'labels'],
                   'prefetch_size': 1,
                   'profile': False,
                   'python_multiprocessing': False,
                   'repeat': 1,
                   'seed': 0},
 'train_dataset_task': {'dataset_config': {'auto_tune': False,
                                           'autotune_per_step': 10,
                                           'batch_size': 1,
                                           'data_loader': {'dataset_dir': '',
                                                           'shuffle': True,
                                                           'type': 'MindDataset'},
                                           'do_eval': False,
                                           'drop_remainder': True,
                                           'filepath_prefix': './autotune',
                                           'input_columns': ['input_ids',
                                                             'labels'],
                                           'num_parallel_workers': 1,
                                           'numa_enable': False,
                                           'output_columns': ['input_ids',
                                                              'labels'],
                                           'prefetch_size': 1,
                                           'profile': False,
                                           'python_multiprocessing': False,
                                           'repeat': 1,
                                           'seed': 0},
                        'type': 'CausalLanguageModelDataset'},
 'trainer': {'model_name': 'llama3_8b',
             'type': 'CausalLanguageModelingTrainer'},
 'use_parallel': False}
2024-07-26 23:01:40,021 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:01:40,021 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:01:40,022 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:36,463 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 56.44035840034485 s; generated tokens: 30 tokens; generate speed: 0.5315345410672783 tokens/s
2024-07-26 23:02:36,469 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:36,479 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:36,479 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:36,479 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:37,089 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6096024513244629 s; generated tokens: 18 tokens; generate speed: 29.527440319329425 tokens/s
2024-07-26 23:02:37,095 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:37,102 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:37,103 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:37,103 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:37,717 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6138691902160645 s; generated tokens: 18 tokens; generate speed: 29.322207869178957 tokens/s
2024-07-26 23:02:37,723 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:37,730 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:37,730 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:37,731 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:38,735 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0037550926208496 s; generated tokens: 30 tokens; generate speed: 29.887768660449485 tokens/s
2024-07-26 23:02:38,740 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:38,748 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:38,748 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:38,749 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:39,356 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6070189476013184 s; generated tokens: 18 tokens; generate speed: 29.653110617268823 tokens/s
2024-07-26 23:02:39,361 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:39,376 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:39,376 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:39,376 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:39,979 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6027481555938721 s; generated tokens: 18 tokens; generate speed: 29.863218714066523 tokens/s
2024-07-26 23:02:39,985 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:39,992 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:39,992 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:39,993 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:40,994 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0008461475372314 s; generated tokens: 30 tokens; generate speed: 29.97463703469369 tokens/s
2024-07-26 23:02:41,001 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:41,011 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:41,011 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:41,012 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:41,962 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9498627185821533 s; generated tokens: 29 tokens; generate speed: 30.530727685878535 tokens/s
2024-07-26 23:02:41,968 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:41,976 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:41,976 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:41,977 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:42,553 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5762360095977783 s; generated tokens: 17 tokens; generate speed: 29.50180085390058 tokens/s
2024-07-26 23:02:42,562 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:42,570 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:42,571 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:42,571 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:43,856 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.285050868988037 s; generated tokens: 38 tokens; generate speed: 29.570813823054777 tokens/s
2024-07-26 23:02:43,862 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:43,870 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:43,871 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:43,871 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:44,099 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22731614112854004 s; generated tokens: 6 tokens; generate speed: 26.394958009634657 tokens/s
2024-07-26 23:02:44,104 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:44,111 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:44,111 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:44,112 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:45,405 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2927167415618896 s; generated tokens: 38 tokens; generate speed: 29.395457472058062 tokens/s
2024-07-26 23:02:45,410 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:45,418 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:45,418 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:45,419 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:46,037 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6175568103790283 s; generated tokens: 18 tokens; generate speed: 29.147116018285697 tokens/s
2024-07-26 23:02:46,042 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:46,050 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:46,050 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:46,050 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:46,636 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5854134559631348 s; generated tokens: 17 tokens; generate speed: 29.039305172839317 tokens/s
2024-07-26 23:02:46,641 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:46,655 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:46,656 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:46,656 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:46,880 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22358131408691406 s; generated tokens: 6 tokens; generate speed: 26.835874118118767 tokens/s
2024-07-26 23:02:46,885 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:46,893 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:46,893 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:46,893 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:47,409 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5154540538787842 s; generated tokens: 15 tokens; generate speed: 29.100556852982763 tokens/s
2024-07-26 23:02:47,415 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:47,422 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:47,423 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:47,423 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:47,651 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22812938690185547 s; generated tokens: 6 tokens; generate speed: 26.30086409069817 tokens/s
2024-07-26 23:02:47,657 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:47,664 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:47,664 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:47,665 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:47,864 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19916081428527832 s; generated tokens: 5 tokens; generate speed: 25.105340214355575 tokens/s
2024-07-26 23:02:47,870 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:47,877 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:47,877 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:47,878 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:48,108 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.23060989379882812 s; generated tokens: 6 tokens; generate speed: 26.017964369013946 tokens/s
2024-07-26 23:02:48,114 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:48,121 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:48,122 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:48,122 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:48,748 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6255862712860107 s; generated tokens: 18 tokens; generate speed: 28.773009936739182 tokens/s
2024-07-26 23:02:48,753 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:48,761 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:48,761 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:48,761 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:50,120 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3582994937896729 s; generated tokens: 39 tokens; generate speed: 28.71237174004203 tokens/s
2024-07-26 23:02:50,125 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:50,133 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:50,133 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:50,134 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:50,712 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5778439044952393 s; generated tokens: 17 tokens; generate speed: 29.419709834699933 tokens/s
2024-07-26 23:02:50,717 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:50,725 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:50,725 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:50,725 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:51,363 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6373894214630127 s; generated tokens: 18 tokens; generate speed: 28.24019256341632 tokens/s
2024-07-26 23:02:51,368 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:51,376 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:51,376 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:51,376 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:51,601 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22423076629638672 s; generated tokens: 6 tokens; generate speed: 26.75814786303339 tokens/s
2024-07-26 23:02:51,606 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:51,614 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:51,614 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:51,614 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:51,807 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19227838516235352 s; generated tokens: 5 tokens; generate speed: 26.003962929989065 tokens/s
2024-07-26 23:02:51,812 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:51,819 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:51,819 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:51,820 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:52,842 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0216491222381592 s; generated tokens: 30 tokens; generate speed: 29.364288919739927 tokens/s
2024-07-26 23:02:52,848 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:52,855 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:52,856 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:52,856 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:53,881 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0245411396026611 s; generated tokens: 30 tokens; generate speed: 29.281401049092707 tokens/s
2024-07-26 23:02:53,886 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:53,894 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:53,894 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:53,895 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:54,809 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9135222434997559 s; generated tokens: 27 tokens; generate speed: 29.555930566683806 tokens/s
2024-07-26 23:02:54,814 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:54,822 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:54,822 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:54,822 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:55,690 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8669712543487549 s; generated tokens: 26 tokens; generate speed: 29.98946028439027 tokens/s
2024-07-26 23:02:55,695 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:55,703 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:55,703 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:55,704 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:56,947 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2431511878967285 s; generated tokens: 38 tokens; generate speed: 30.567480745678015 tokens/s
2024-07-26 23:02:56,953 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:56,961 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:56,961 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:56,961 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:58,265 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3037447929382324 s; generated tokens: 39 tokens; generate speed: 29.9138299238045 tokens/s
2024-07-26 23:02:58,271 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:58,279 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:58,279 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:58,280 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:58,858 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.578211784362793 s; generated tokens: 17 tokens; generate speed: 29.400991919828336 tokens/s
2024-07-26 23:02:58,864 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:58,871 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:58,872 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:58,872 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:02:59,485 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6128578186035156 s; generated tokens: 18 tokens; generate speed: 29.370596986125722 tokens/s
2024-07-26 23:02:59,490 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:02:59,498 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:02:59,498 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:02:59,499 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:00,433 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9338822364807129 s; generated tokens: 28 tokens; generate speed: 29.982367054669076 tokens/s
2024-07-26 23:03:00,438 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:00,447 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:00,447 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:00,447 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:01,876 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.4288127422332764 s; generated tokens: 44 tokens; generate speed: 30.794798156143752 tokens/s
2024-07-26 23:03:01,883 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:01,891 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:01,891 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:01,892 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:02,859 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9672439098358154 s; generated tokens: 29 tokens; generate speed: 29.98209624801111 tokens/s
2024-07-26 23:03:02,865 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:02,873 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:02,874 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:02,874 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:03,104 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22994279861450195 s; generated tokens: 5 tokens; generate speed: 21.7445383379128 tokens/s
2024-07-26 23:03:03,110 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:03,117 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:03,117 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:03,118 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:03,739 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6213171482086182 s; generated tokens: 18 tokens; generate speed: 28.970711740208053 tokens/s
2024-07-26 23:03:03,745 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:03,753 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:03,753 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:03,753 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:03,942 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.1885664463043213 s; generated tokens: 5 tokens; generate speed: 26.51585209348784 tokens/s
2024-07-26 23:03:03,948 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:03,955 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:03,955 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:03,955 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:04,558 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6019058227539062 s; generated tokens: 17 tokens; generate speed: 28.243621107069067 tokens/s
2024-07-26 23:03:04,563 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:04,571 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:04,571 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:04,571 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:05,166 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5944585800170898 s; generated tokens: 18 tokens; generate speed: 30.279653797717117 tokens/s
2024-07-26 23:03:05,171 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:05,179 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:05,179 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:05,179 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:06,060 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8804564476013184 s; generated tokens: 27 tokens; generate speed: 30.665912065903726 tokens/s
2024-07-26 23:03:06,066 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:06,073 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:06,074 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:06,074 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:07,118 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0434374809265137 s; generated tokens: 30 tokens; generate speed: 28.751123616301086 tokens/s
2024-07-26 23:03:07,123 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:07,131 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:07,131 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:07,132 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:07,373 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2409508228302002 s; generated tokens: 6 tokens; generate speed: 24.90134679568305 tokens/s
2024-07-26 23:03:07,378 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:07,386 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:07,386 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:07,386 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:07,605 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.21893978118896484 s; generated tokens: 6 tokens; generate speed: 27.404795818360014 tokens/s
2024-07-26 23:03:07,611 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:07,618 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:07,618 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:07,619 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:08,216 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5966987609863281 s; generated tokens: 18 tokens; generate speed: 30.16597515678841 tokens/s
2024-07-26 23:03:08,221 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:08,229 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:08,229 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:08,229 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:08,845 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6154279708862305 s; generated tokens: 18 tokens; generate speed: 29.24793940398839 tokens/s
2024-07-26 23:03:08,851 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:08,859 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:08,859 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:08,860 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:09,435 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5748462677001953 s; generated tokens: 17 tokens; generate speed: 29.57312407717703 tokens/s
2024-07-26 23:03:09,440 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:09,448 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:09,448 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:09,449 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:09,690 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.24169015884399414 s; generated tokens: 6 tokens; generate speed: 24.825172976417598 tokens/s
2024-07-26 23:03:09,696 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:09,703 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:09,704 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:09,704 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:10,583 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.8783547878265381 s; generated tokens: 26 tokens; generate speed: 29.600794986654765 tokens/s
2024-07-26 23:03:10,588 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:10,596 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:10,596 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:10,597 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:12,545 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.9485843181610107 s; generated tokens: 59 tokens; generate speed: 30.278392087072547 tokens/s
2024-07-26 23:03:12,551 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:12,559 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:12,559 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:12,560 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:13,541 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9809412956237793 s; generated tokens: 30 tokens; generate speed: 30.582869875942006 tokens/s
2024-07-26 23:03:13,546 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:13,554 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:13,554 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:13,555 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:13,792 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2373349666595459 s; generated tokens: 6 tokens; generate speed: 25.280724894646166 tokens/s
2024-07-26 23:03:13,797 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:13,805 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:13,805 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:13,805 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:14,370 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5639991760253906 s; generated tokens: 17 tokens; generate speed: 30.141888007358858 tokens/s
2024-07-26 23:03:14,376 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:14,383 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:14,383 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:14,384 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:14,604 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.21973013877868652 s; generated tokens: 6 tokens; generate speed: 27.3062222294559 tokens/s
2024-07-26 23:03:14,609 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:14,616 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:14,616 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:14,617 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:15,628 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0108211040496826 s; generated tokens: 30 tokens; generate speed: 29.678842160902764 tokens/s
2024-07-26 23:03:15,633 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:15,641 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:15,641 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:15,642 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:16,611 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9691362380981445 s; generated tokens: 29 tokens; generate speed: 29.9235534282675 tokens/s
2024-07-26 23:03:16,616 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:16,624 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:16,624 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:16,625 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:17,201 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5755913257598877 s; generated tokens: 17 tokens; generate speed: 29.534843975553027 tokens/s
2024-07-26 23:03:17,206 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:17,214 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:17,214 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:17,214 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:17,813 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5987544059753418 s; generated tokens: 18 tokens; generate speed: 30.062409262239793 tokens/s
2024-07-26 23:03:17,819 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:17,826 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:17,826 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:17,827 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:18,825 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9982409477233887 s; generated tokens: 30 tokens; generate speed: 30.05286455982265 tokens/s
2024-07-26 23:03:18,832 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:18,840 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:18,840 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:18,841 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:19,579 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7379508018493652 s; generated tokens: 22 tokens; generate speed: 29.81228551397491 tokens/s
2024-07-26 23:03:19,585 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:19,593 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:19,593 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:19,594 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:20,389 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7949855327606201 s; generated tokens: 22 tokens; generate speed: 27.67345957052085 tokens/s
2024-07-26 23:03:20,394 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:20,402 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:20,402 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:20,403 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:21,724 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3211264610290527 s; generated tokens: 39 tokens; generate speed: 29.520262556562596 tokens/s
2024-07-26 23:03:21,729 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:21,737 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:21,737 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:21,738 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:22,212 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.4742002487182617 s; generated tokens: 14 tokens; generate speed: 29.523392359749415 tokens/s
2024-07-26 23:03:22,218 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:22,225 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:22,225 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:22,225 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:22,415 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.1889054775238037 s; generated tokens: 5 tokens; generate speed: 26.468263734543946 tokens/s
2024-07-26 23:03:22,420 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:22,427 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:22,427 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:22,428 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:23,488 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0598533153533936 s; generated tokens: 31 tokens; generate speed: 29.24933059218999 tokens/s
2024-07-26 23:03:23,493 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:23,501 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:23,501 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:23,501 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:23,722 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2206106185913086 s; generated tokens: 6 tokens; generate speed: 27.197240270266764 tokens/s
2024-07-26 23:03:23,727 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:23,734 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:23,735 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:23,735 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:24,325 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5894031524658203 s; generated tokens: 17 tokens; generate speed: 28.84273680736011 tokens/s
2024-07-26 23:03:24,330 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:24,338 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:24,338 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:24,338 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:24,528 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.18949270248413086 s; generated tokens: 5 tokens; generate speed: 26.386240390543414 tokens/s
2024-07-26 23:03:24,533 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:24,540 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:24,540 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:24,541 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:25,540 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9986121654510498 s; generated tokens: 30 tokens; generate speed: 30.041692899314622 tokens/s
2024-07-26 23:03:25,545 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:25,553 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:25,553 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:25,554 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:26,508 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9542677402496338 s; generated tokens: 28 tokens; generate speed: 29.341870021379197 tokens/s
2024-07-26 23:03:26,514 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:26,521 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:26,522 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:26,522 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:27,123 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6006672382354736 s; generated tokens: 18 tokens; generate speed: 29.966675147585857 tokens/s
2024-07-26 23:03:27,128 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:27,136 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:27,136 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:27,136 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:27,757 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6201691627502441 s; generated tokens: 17 tokens; generate speed: 27.41187569631913 tokens/s
2024-07-26 23:03:27,762 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:27,769 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:27,770 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:27,770 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:28,760 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9893167018890381 s; generated tokens: 30 tokens; generate speed: 30.323959903554528 tokens/s
2024-07-26 23:03:28,765 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:28,773 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:28,773 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:28,773 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:29,792 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0188379287719727 s; generated tokens: 31 tokens; generate speed: 30.426821700056816 tokens/s
2024-07-26 23:03:29,798 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:29,805 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:29,806 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:29,806 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:30,404 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5977814197540283 s; generated tokens: 17 tokens; generate speed: 28.438488447826067 tokens/s
2024-07-26 23:03:30,409 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:30,417 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:30,417 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:30,417 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:31,389 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9713671207427979 s; generated tokens: 29 tokens; generate speed: 29.854829735047957 tokens/s
2024-07-26 23:03:31,395 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:31,403 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:31,403 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:31,403 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:32,063 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6590211391448975 s; generated tokens: 19 tokens; generate speed: 28.83063815624056 tokens/s
2024-07-26 23:03:32,068 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:32,075 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:32,076 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:32,076 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:33,301 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.224815845489502 s; generated tokens: 37 tokens; generate speed: 30.20862290135773 tokens/s
2024-07-26 23:03:33,307 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:33,314 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:33,315 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:33,315 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:34,828 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.5128445625305176 s; generated tokens: 46 tokens; generate speed: 30.406296284038813 tokens/s
2024-07-26 23:03:34,835 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:34,845 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:34,845 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:34,846 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:35,479 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6325123310089111 s; generated tokens: 19 tokens; generate speed: 30.038940062549262 tokens/s
2024-07-26 23:03:35,485 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:35,492 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:35,493 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:35,493 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:36,093 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.600348949432373 s; generated tokens: 18 tokens; generate speed: 29.982562669625576 tokens/s
2024-07-26 23:03:36,099 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:36,106 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:36,107 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:36,107 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:36,298 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19067144393920898 s; generated tokens: 5 tokens; generate speed: 26.223119187129722 tokens/s
2024-07-26 23:03:36,303 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:36,312 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:36,313 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:36,313 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:37,648 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3347656726837158 s; generated tokens: 38 tokens; generate speed: 28.469416600740246 tokens/s
2024-07-26 23:03:37,654 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:37,664 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:37,664 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:37,665 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:38,277 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6124627590179443 s; generated tokens: 18 tokens; generate speed: 29.389542033318346 tokens/s
2024-07-26 23:03:38,283 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:38,290 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:38,290 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:38,291 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:38,514 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22329378128051758 s; generated tokens: 6 tokens; generate speed: 26.87043036125745 tokens/s
2024-07-26 23:03:38,520 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:38,527 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:38,527 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:38,528 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:39,132 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6039371490478516 s; generated tokens: 18 tokens; generate speed: 29.804425888320065 tokens/s
2024-07-26 23:03:39,137 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:39,145 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:39,145 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:39,145 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:39,597 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.4513731002807617 s; generated tokens: 12 tokens; generate speed: 26.585545289552694 tokens/s
2024-07-26 23:03:39,602 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:39,610 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:39,610 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:39,610 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:39,833 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2223646640777588 s; generated tokens: 6 tokens; generate speed: 26.98270440082988 tokens/s
2024-07-26 23:03:39,862 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:39,870 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:39,870 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:39,870 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:40,409 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5388064384460449 s; generated tokens: 16 tokens; generate speed: 29.695265049439847 tokens/s
2024-07-26 23:03:40,415 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:40,422 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:40,422 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:40,423 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:40,645 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22209668159484863 s; generated tokens: 6 tokens; generate speed: 27.01526180812224 tokens/s
2024-07-26 23:03:40,650 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:40,657 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:40,658 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:40,658 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:40,902 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.24400830268859863 s; generated tokens: 6 tokens; generate speed: 24.589327223250883 tokens/s
2024-07-26 23:03:40,908 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:40,915 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:40,915 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:40,916 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:41,106 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19031667709350586 s; generated tokens: 5 tokens; generate speed: 26.27200136298835 tokens/s
2024-07-26 23:03:41,111 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:41,119 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:41,119 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:41,119 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:41,309 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.18979859352111816 s; generated tokens: 5 tokens; generate speed: 26.343714709580652 tokens/s
2024-07-26 23:03:41,314 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:41,322 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:41,322 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:41,322 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:41,933 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.610363245010376 s; generated tokens: 18 tokens; generate speed: 29.490635530804294 tokens/s
2024-07-26 23:03:41,938 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:41,946 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:41,946 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:41,946 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:43,249 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.302001714706421 s; generated tokens: 38 tokens; generate speed: 29.185829458426134 tokens/s
2024-07-26 23:03:43,255 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:43,262 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:43,263 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:43,263 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:43,832 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5683412551879883 s; generated tokens: 17 tokens; generate speed: 29.911606530088985 tokens/s
2024-07-26 23:03:43,837 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:43,845 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:43,845 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:43,845 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:45,029 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.183011770248413 s; generated tokens: 35 tokens; generate speed: 29.585504455843726 tokens/s
2024-07-26 23:03:45,034 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:45,042 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:45,042 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:45,043 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:45,654 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.610870361328125 s; generated tokens: 18 tokens; generate speed: 29.4661537692961 tokens/s
2024-07-26 23:03:45,659 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:45,667 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:45,667 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:45,667 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:45,893 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2259821891784668 s; generated tokens: 6 tokens; generate speed: 26.550765004146278 tokens/s
2024-07-26 23:03:45,899 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:45,906 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:45,906 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:45,906 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:47,060 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.1533300876617432 s; generated tokens: 35 tokens; generate speed: 30.34690621048382 tokens/s
2024-07-26 23:03:47,084 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:47,092 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:47,093 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:47,093 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:47,710 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6171958446502686 s; generated tokens: 18 tokens; generate speed: 29.16416264953894 tokens/s
2024-07-26 23:03:47,716 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:47,723 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:47,723 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:47,724 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:47,945 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2210690975189209 s; generated tokens: 6 tokens; generate speed: 27.140835455242545 tokens/s
2024-07-26 23:03:47,950 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:47,958 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:47,958 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:47,958 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:49,268 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3098187446594238 s; generated tokens: 39 tokens; generate speed: 29.775112135947246 tokens/s
2024-07-26 23:03:49,274 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:49,281 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:49,282 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:49,282 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:49,864 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.581615686416626 s; generated tokens: 17 tokens; generate speed: 29.228922804228617 tokens/s
2024-07-26 23:03:49,869 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:49,877 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:49,877 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:49,877 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:50,503 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.625903844833374 s; generated tokens: 18 tokens; generate speed: 28.758410974119993 tokens/s
2024-07-26 23:03:50,509 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:50,516 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:50,516 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:50,517 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:51,058 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5407314300537109 s; generated tokens: 16 tokens; generate speed: 29.58955058042533 tokens/s
2024-07-26 23:03:51,063 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:51,070 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:51,071 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:51,071 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:51,660 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5888221263885498 s; generated tokens: 17 tokens; generate speed: 28.87119766416879 tokens/s
2024-07-26 23:03:51,667 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:51,674 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:51,675 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:51,675 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:52,603 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9274084568023682 s; generated tokens: 28 tokens; generate speed: 30.191659127782607 tokens/s
2024-07-26 23:03:52,608 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:52,616 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:52,616 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:52,616 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:53,981 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.364537239074707 s; generated tokens: 39 tokens; generate speed: 28.581118113306974 tokens/s
2024-07-26 23:03:53,987 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:53,995 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:53,995 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:53,996 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:55,003 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0074329376220703 s; generated tokens: 30 tokens; generate speed: 29.778657099311793 tokens/s
2024-07-26 23:03:55,009 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:55,017 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:55,017 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:55,017 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:55,712 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6943955421447754 s; generated tokens: 21 tokens; generate speed: 30.242129629947545 tokens/s
2024-07-26 23:03:55,717 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:55,725 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:55,725 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:55,725 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:56,761 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0348315238952637 s; generated tokens: 30 tokens; generate speed: 28.99022624192528 tokens/s
2024-07-26 23:03:56,766 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:56,774 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:56,774 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:56,774 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:57,815 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.040229320526123 s; generated tokens: 30 tokens; generate speed: 28.83979465684232 tokens/s
2024-07-26 23:03:57,820 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:57,828 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:57,828 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:57,829 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:58,422 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5931987762451172 s; generated tokens: 17 tokens; generate speed: 28.658184542470106 tokens/s
2024-07-26 23:03:58,427 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:58,435 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:58,435 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:58,436 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:58,979 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5427815914154053 s; generated tokens: 16 tokens; generate speed: 29.47778674342471 tokens/s
2024-07-26 23:03:58,984 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:58,992 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:58,992 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:58,992 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:59,566 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5733215808868408 s; generated tokens: 17 tokens; generate speed: 29.651770606129286 tokens/s
2024-07-26 23:03:59,571 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:59,579 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:59,579 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:59,579 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:03:59,769 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.18939542770385742 s; generated tokens: 5 tokens; generate speed: 26.39979254313416 tokens/s
2024-07-26 23:03:59,774 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:03:59,781 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:03:59,781 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:03:59,782 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:00,317 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5347340106964111 s; generated tokens: 15 tokens; generate speed: 28.0513296329604 tokens/s
2024-07-26 23:04:00,322 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:00,330 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:00,330 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:00,331 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:01,018 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6871111392974854 s; generated tokens: 20 tokens; generate speed: 29.107372674016542 tokens/s
2024-07-26 23:04:01,023 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:01,031 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:01,031 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:01,031 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:02,016 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9839315414428711 s; generated tokens: 29 tokens; generate speed: 29.473595243703034 tokens/s
2024-07-26 23:04:02,021 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:02,029 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:02,029 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:02,029 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:03,019 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9897747039794922 s; generated tokens: 30 tokens; generate speed: 30.3099279860173 tokens/s
2024-07-26 23:04:03,025 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:03,032 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:03,033 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:03,033 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:04,089 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0554380416870117 s; generated tokens: 30 tokens; generate speed: 28.424217069197176 tokens/s
2024-07-26 23:04:04,094 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:04,102 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:04,102 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:04,102 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:05,299 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.196418285369873 s; generated tokens: 37 tokens; generate speed: 30.925639011410997 tokens/s
2024-07-26 23:04:05,304 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:05,312 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:05,313 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:05,313 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:06,325 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.011369228363037 s; generated tokens: 30 tokens; generate speed: 29.66275733794752 tokens/s
2024-07-26 23:04:06,330 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:06,338 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:06,338 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:06,338 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:06,917 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5781831741333008 s; generated tokens: 17 tokens; generate speed: 29.40244676867859 tokens/s
2024-07-26 23:04:06,922 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:06,930 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:06,930 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:06,930 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:07,151 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2209775447845459 s; generated tokens: 6 tokens; generate speed: 27.15208011678303 tokens/s
2024-07-26 23:04:07,157 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:07,164 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:07,164 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:07,165 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:08,174 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.009373426437378 s; generated tokens: 30 tokens; generate speed: 29.721408563217427 tokens/s
2024-07-26 23:04:08,180 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:08,188 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:08,188 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:08,188 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:08,758 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5697500705718994 s; generated tokens: 17 tokens; generate speed: 29.83764439543793 tokens/s
2024-07-26 23:04:08,764 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:08,771 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:08,772 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:08,772 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:09,773 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.000868320465088 s; generated tokens: 30 tokens; generate speed: 29.973972985836408 tokens/s
2024-07-26 23:04:09,780 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:09,788 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:09,788 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:09,789 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:11,526 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.7373757362365723 s; generated tokens: 51 tokens; generate speed: 29.354617390060934 tokens/s
2024-07-26 23:04:11,532 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:11,540 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:11,540 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:11,541 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:12,212 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6715631484985352 s; generated tokens: 20 tokens; generate speed: 29.78126486647685 tokens/s
2024-07-26 23:04:12,218 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:12,226 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:12,226 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:12,226 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:13,222 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9952492713928223 s; generated tokens: 30 tokens; generate speed: 30.143202172874616 tokens/s
2024-07-26 23:04:13,227 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:13,259 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:13,260 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:13,260 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:13,981 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7206048965454102 s; generated tokens: 21 tokens; generate speed: 29.14218332497363 tokens/s
2024-07-26 23:04:13,986 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:13,994 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:13,994 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:13,995 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:15,278 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2826318740844727 s; generated tokens: 39 tokens; generate speed: 30.406230180298408 tokens/s
2024-07-26 23:04:15,284 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:15,295 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:15,295 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:15,296 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:15,519 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22248554229736328 s; generated tokens: 6 tokens; generate speed: 26.968044476259468 tokens/s
2024-07-26 23:04:15,524 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:15,531 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:15,532 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:15,532 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:15,771 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.23901724815368652 s; generated tokens: 6 tokens; generate speed: 25.10279089207001 tokens/s
2024-07-26 23:04:15,777 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:15,784 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:15,784 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:15,784 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:15,992 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2075517177581787 s; generated tokens: 5 tokens; generate speed: 24.090381202364064 tokens/s
2024-07-26 23:04:15,997 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:16,005 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:16,005 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:16,005 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:16,609 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6036648750305176 s; generated tokens: 18 tokens; generate speed: 29.81786872905274 tokens/s
2024-07-26 23:04:16,615 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:16,623 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:16,623 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:16,624 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:17,184 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5597333908081055 s; generated tokens: 16 tokens; generate speed: 28.58503756029326 tokens/s
2024-07-26 23:04:17,189 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:17,197 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:17,197 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:17,197 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:17,734 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5360677242279053 s; generated tokens: 16 tokens; generate speed: 29.846975068392137 tokens/s
2024-07-26 23:04:17,739 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:17,746 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:17,747 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:17,747 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:19,024 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.2765777111053467 s; generated tokens: 38 tokens; generate speed: 29.767087165494257 tokens/s
2024-07-26 23:04:19,029 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:19,037 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:19,037 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:19,037 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:19,977 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9396324157714844 s; generated tokens: 28 tokens; generate speed: 29.79888680938133 tokens/s
2024-07-26 23:04:19,983 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:19,990 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:19,991 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:19,991 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:20,543 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5520169734954834 s; generated tokens: 16 tokens; generate speed: 28.984615995926276 tokens/s
2024-07-26 23:04:20,549 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:20,556 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:20,556 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:20,557 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:21,553 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9957396984100342 s; generated tokens: 30 tokens; generate speed: 30.12835588246914 tokens/s
2024-07-26 23:04:21,558 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:21,565 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:21,566 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:21,566 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:22,104 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5381042957305908 s; generated tokens: 16 tokens; generate speed: 29.73401276842922 tokens/s
2024-07-26 23:04:22,110 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:22,118 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:22,118 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:22,118 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:22,736 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6175446510314941 s; generated tokens: 18 tokens; generate speed: 29.147689919966645 tokens/s
2024-07-26 23:04:22,742 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:22,749 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:22,750 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:22,750 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:23,741 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9908111095428467 s; generated tokens: 30 tokens; generate speed: 30.27822327692893 tokens/s
2024-07-26 23:04:23,747 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:23,755 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:23,755 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:23,756 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:23,980 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22376751899719238 s; generated tokens: 6 tokens; generate speed: 26.813543032915703 tokens/s
2024-07-26 23:04:23,985 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:23,993 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:23,993 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:23,993 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:24,588 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5939669609069824 s; generated tokens: 17 tokens; generate speed: 28.62112056542867 tokens/s
2024-07-26 23:04:24,593 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:24,600 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:24,601 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:24,601 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:25,637 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0353412628173828 s; generated tokens: 30 tokens; generate speed: 28.975953221804033 tokens/s
2024-07-26 23:04:25,642 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:25,650 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:25,650 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:25,650 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:25,866 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2152390480041504 s; generated tokens: 5 tokens; generate speed: 23.229985666465065 tokens/s
2024-07-26 23:04:25,871 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:25,878 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:25,878 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:25,879 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:26,133 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2538774013519287 s; generated tokens: 7 tokens; generate speed: 27.57236352162158 tokens/s
2024-07-26 23:04:26,138 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:26,145 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:26,146 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:26,146 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:27,128 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9819607734680176 s; generated tokens: 30 tokens; generate speed: 30.551118548298202 tokens/s
2024-07-26 23:04:27,134 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:27,142 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:27,142 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:27,142 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:28,157 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0143132209777832 s; generated tokens: 30 tokens; generate speed: 29.57666269111669 tokens/s
2024-07-26 23:04:28,162 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:28,170 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:28,170 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:28,170 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:28,725 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5548722743988037 s; generated tokens: 16 tokens; generate speed: 28.835464913679054 tokens/s
2024-07-26 23:04:28,731 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:28,738 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:28,738 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:28,739 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:28,929 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.19029784202575684 s; generated tokens: 5 tokens; generate speed: 26.274601681101824 tokens/s
2024-07-26 23:04:28,935 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:28,942 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:28,942 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:28,942 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:29,620 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6772992610931396 s; generated tokens: 19 tokens; generate speed: 28.05259224605472 tokens/s
2024-07-26 23:04:29,625 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:29,633 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:29,633 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:29,633 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:30,952 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3184740543365479 s; generated tokens: 39 tokens; generate speed: 29.57964919501179 tokens/s
2024-07-26 23:04:30,957 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:30,965 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:30,966 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:30,966 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:31,599 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.633277177810669 s; generated tokens: 19 tokens; generate speed: 30.002660234315968 tokens/s
2024-07-26 23:04:31,605 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:31,612 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:31,613 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:31,613 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:32,245 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6314747333526611 s; generated tokens: 18 tokens; generate speed: 28.50470343355369 tokens/s
2024-07-26 23:04:32,251 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:32,258 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:32,258 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:32,259 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:33,540 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.280768871307373 s; generated tokens: 38 tokens; generate speed: 29.669677996788494 tokens/s
2024-07-26 23:04:33,545 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:33,553 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:33,553 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:33,553 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:34,092 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5388383865356445 s; generated tokens: 16 tokens; generate speed: 29.693504397243956 tokens/s
2024-07-26 23:04:34,098 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:34,105 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:34,105 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:34,106 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:35,120 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0146162509918213 s; generated tokens: 29 tokens; generate speed: 28.582234881071077 tokens/s
2024-07-26 23:04:35,126 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:35,134 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:35,134 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:35,134 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:35,357 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2229607105255127 s; generated tokens: 6 tokens; generate speed: 26.91057086182652 tokens/s
2024-07-26 23:04:35,363 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:35,370 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:35,370 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:35,371 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:36,352 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9813389778137207 s; generated tokens: 30 tokens; generate speed: 30.570476337173115 tokens/s
2024-07-26 23:04:36,358 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:36,365 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:36,365 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:36,366 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:37,434 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0677731037139893 s; generated tokens: 30 tokens; generate speed: 28.095856596923344 tokens/s
2024-07-26 23:04:37,440 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:37,447 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:37,448 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:37,448 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:38,049 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6008822917938232 s; generated tokens: 18 tokens; generate speed: 29.955950184959388 tokens/s
2024-07-26 23:04:38,054 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:38,062 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:38,062 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:38,062 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:38,662 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5997045040130615 s; generated tokens: 18 tokens; generate speed: 30.01478207942217 tokens/s
2024-07-26 23:04:38,668 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:38,675 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:38,675 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:38,676 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:39,318 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6417496204376221 s; generated tokens: 18 tokens; generate speed: 28.048322004032407 tokens/s
2024-07-26 23:04:39,325 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:39,333 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:39,333 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:39,333 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:40,329 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9955341815948486 s; generated tokens: 30 tokens; generate speed: 30.134575542087276 tokens/s
2024-07-26 23:04:40,334 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:40,342 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:40,342 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:40,343 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:40,965 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.621762752532959 s; generated tokens: 18 tokens; generate speed: 28.949949038714472 tokens/s
2024-07-26 23:04:40,971 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:40,979 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:40,979 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:40,980 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:41,973 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.9926190376281738 s; generated tokens: 30 tokens; generate speed: 30.223075382156562 tokens/s
2024-07-26 23:04:41,978 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:41,986 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:41,986 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:41,986 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:42,563 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5766563415527344 s; generated tokens: 17 tokens; generate speed: 29.480296625586274 tokens/s
2024-07-26 23:04:42,570 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:42,582 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:42,582 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:42,583 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:43,197 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6137020587921143 s; generated tokens: 17 tokens; generate speed: 27.700738096690316 tokens/s
2024-07-26 23:04:43,202 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:43,210 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:43,210 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:43,210 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:44,278 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.0672152042388916 s; generated tokens: 31 tokens; generate speed: 29.04756217571726 tokens/s
2024-07-26 23:04:44,283 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:44,291 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:44,291 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:44,291 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:44,858 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5667617321014404 s; generated tokens: 17 tokens; generate speed: 29.99496796822778 tokens/s
2024-07-26 23:04:44,864 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:44,871 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:44,871 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:44,872 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:45,534 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.661884069442749 s; generated tokens: 19 tokens; generate speed: 28.70593337591039 tokens/s
2024-07-26 23:04:45,539 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:45,547 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:45,547 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:45,547 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:45,799 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2516815662384033 s; generated tokens: 7 tokens; generate speed: 27.812922911363746 tokens/s
2024-07-26 23:04:45,804 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:45,811 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:45,812 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:45,812 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:46,410 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5981009006500244 s; generated tokens: 17 tokens; generate speed: 28.423297777221475 tokens/s
2024-07-26 23:04:46,416 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:46,423 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:46,424 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:46,424 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:46,670 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.24582362174987793 s; generated tokens: 6 tokens; generate speed: 24.407743882745798 tokens/s
2024-07-26 23:04:46,675 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:46,683 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:46,683 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:46,683 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:46,874 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.1901538372039795 s; generated tokens: 5 tokens; generate speed: 26.294499619465796 tokens/s
2024-07-26 23:04:46,879 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:46,886 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:46,886 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:46,887 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:48,214 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.3270378112792969 s; generated tokens: 40 tokens; generate speed: 30.142321236076178 tokens/s
2024-07-26 23:04:48,220 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:48,227 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:48,228 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:48,228 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:48,850 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6212375164031982 s; generated tokens: 18 tokens; generate speed: 28.97442527974689 tokens/s
2024-07-26 23:04:48,855 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:48,862 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:48,863 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:48,863 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:49,492 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6292214393615723 s; generated tokens: 18 tokens; generate speed: 28.606781132987717 tokens/s
2024-07-26 23:04:49,498 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:49,505 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:49,505 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:49,506 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:49,953 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.4467151165008545 s; generated tokens: 13 tokens; generate speed: 29.101320998111184 tokens/s
2024-07-26 23:04:49,958 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:49,965 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:49,966 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:49,966 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:50,722 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7561991214752197 s; generated tokens: 22 tokens; generate speed: 29.09286638297282 tokens/s
2024-07-26 23:04:50,728 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:50,735 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:50,736 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:50,736 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:51,352 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6157824993133545 s; generated tokens: 18 tokens; generate speed: 29.231100299328745 tokens/s
2024-07-26 23:04:51,357 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:51,365 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:51,365 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:51,365 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:51,970 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6044504642486572 s; generated tokens: 18 tokens; generate speed: 29.779115187502292 tokens/s
2024-07-26 23:04:51,975 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:51,983 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:51,983 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:51,984 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:53,307 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.322730302810669 s; generated tokens: 40 tokens; generate speed: 30.240480553748576 tokens/s
2024-07-26 23:04:53,313 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:53,321 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:53,321 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:53,321 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:54,111 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.7892162799835205 s; generated tokens: 23 tokens; generate speed: 29.142835219365036 tokens/s
2024-07-26 23:04:54,116 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:54,124 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:54,124 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:54,124 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:55,720 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 1.595090627670288 s; generated tokens: 48 tokens; generate speed: 30.09233404506079 tokens/s
2024-07-26 23:04:55,725 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:55,733 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:55,733 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:55,733 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:56,278 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.5442295074462891 s; generated tokens: 16 tokens; generate speed: 29.399361447852158 tokens/s
2024-07-26 23:04:56,284 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:56,291 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:56,291 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:56,292 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:56,514 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.22151494026184082 s; generated tokens: 6 tokens; generate speed: 27.086209141955504 tokens/s
2024-07-26 23:04:56,519 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:56,526 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:56,526 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:56,527 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:59,039 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 2.512237787246704 s; generated tokens: 75 tokens; generate speed: 29.85386191575301 tokens/s
2024-07-26 23:04:59,046 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:59,054 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:59,055 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:59,055 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:59,246 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.1905665397644043 s; generated tokens: 5 tokens; generate speed: 26.23755464197154 tokens/s
2024-07-26 23:04:59,251 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:59,258 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:59,258 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:59,258 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:04:59,890 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6309618949890137 s; generated tokens: 19 tokens; generate speed: 30.112753481461553 tokens/s
2024-07-26 23:04:59,895 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:04:59,902 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:04:59,903 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:04:59,903 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:05:00,535 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.6320633888244629 s; generated tokens: 18 tokens; generate speed: 28.47815633409353 tokens/s
2024-07-26 23:05:00,541 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:05:00,548 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:05:00,548 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:05:00,549 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:05:00,758 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.2086644172668457 s; generated tokens: 5 tokens; generate speed: 23.961919648264058 tokens/s
2024-07-26 23:05:00,763 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:05:00,770 - mindformers[mindformers/generation/text_generator.py:694] - WARNING - When do_sample is set to False, top_k will be set to 0, making them inactive.
2024-07-26 23:05:00,770 - mindformers[mindformers/generation/text_generator.py:702] - WARNING - max_length 512 can not exceeds model seq_length 256, set max_length = seq_length.
2024-07-26 23:05:00,771 - mindformers[mindformers/modules/block_tables.py:63] - INFO - init cache engine success.
2024-07-26 23:05:01,404 - mindformers[mindformers/generation/text_generator.py:889] - INFO - total time: 0.633063793182373 s; generated tokens: 19 tokens; generate speed: 30.01277312747292 tokens/s
2024-07-26 23:05:01,409 - mindformers[mindformers/modules/block_tables.py:129] - INFO - Clear block table cache engines.
2024-07-26 23:05:01,415 - mindformers[mindformers/trainer/base_trainer.py:951] - INFO - output result is: [{'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7451.51 - -1709.92 \n\n### Response: -7451.51 - -1709.92 = -7451.51 + 1709.92 = -5741.59']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1337.47 + 5068.04 \n\n### Response: -1337.47 + 5068.04 = 3730.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6211.70 * -6871.61 \n\n### Response: -6211.70 * -6871.61 = 42667.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3985.41 - -8173.86 \n\n### Response: -3985.41 - -8173.86 = -3985.41 + 8173.86 = 4188.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1075.16 - 8090.56 \n\n### Response: 1075.16 - 8090.56 = -7015.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9299.25 * 1012.66 \n\n### Response: -9390.8 = -9299.25 * 1012.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2864.35 - -8690.01 \n\n### Response: -2864.35 - -8690.01 = -2864.35 + 8690.01 = 5825.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7310.69 + -6470.86 \n\n### Response: 7310.69 + -6470.86 = 7310.69 - 6470.86 = 839.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3476.06 + 2490.05 \n\n### Response: -3476.06 + 2490.05 = -987.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 19  71 \n\n### Response: \n(19 - 71) / 19 = -3.73\n3.73 * 100 = -373.0\n -373.0 %']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1647.72 * -2175.26 \n\n### Response: -3578.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -13x + 10 = 0\n\n### Response:  -13x = -10.0 x = -10.0 / -13  = 0.770.77']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1980.46 - -4548.03 \n\n### Response: -1980.46 + 4548.03 = 2567.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9349.89 + 8736.20 \n\n### Response: -9349.89 + 8736.20 = -613.69']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7881.79 + -3132.78 \n\n### Response: -11014.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7374.53 * -4084.42 \n\n### Response: -3.01 * 10.2 = -30.62']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6811.55 - 2494.54 \n\n### Response: 4317.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6974.95 \n\n### Response: 83.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3957.83 - 3083.39 \n\n### Response: -7041.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8230.71 - 2598.23 \n\n### Response: 8230.71 - 2598.23 = 5632.48']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 53x + 27 = 0\n\n### Response:  53x = -27.0 x = -27.0 / 53  = -0.51-0.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2670.86 / 8327.57 \n\n### Response: 2670.86 / 8327.57 = 0.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1295.35 + 7059.64 \n\n### Response: -1295.35 + 7059.64 = 5764.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5113.34 - 239.46 \n\n### Response: 4873.88']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4157.45 \n\n### Response: 64.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8141.51 - -9883.79 \n\n### Response: -8141.51 - -9883.79 = -8141.51 + 9883.79 = 1742.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3619.12 + -4630.69 \n\n### Response: 3619.12 + -4630.69 = 3619.12 - 4630.69 = -1011.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 50  42 \n\n### Response: \n(50 - 42) / 50 * 100 = 0.16 * 100 = 16.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -337.33  2 \n\n### Response: -337.33 * -337.33 = 337.33 * 337.33 = 113888.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 56  20 \n\n### Response: \n(56 - 20) / 56 * 100 = 64.29 / 56 * 100 = 1.14 * 100 = 114.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5x + -100 = 0\n\n### Response:  -5x = 100.0 x = 100.0 / -5  = -20.0-20.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8115.42 / -8891.52 \n\n### Response: 8115.42 / -8891.52 = -0.91']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4670.73 + 5116.49 \n\n### Response: 4670.73 + 5116.49 = 9787.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2921.61 - -426.91 \n\n### Response: 2921.61 - -426.91 = 2921.61 + 426.91 = 3348.52']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 47  12 \n\n### Response: \n(47 - 12) / 47 * 100 = 74.46 / 47 * 100 = 0.58 * 100 = 58.0%\n= 0.58']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4023.23 + -4657.63 \n\n### Response: 4023.23 + -4657.63 = 4023.23 - 4657.63 = -634.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6365.40 \n\n### Response: 80.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6402.63 + 9129.29 \n\n### Response: -6402.63 + 9129.29 = 2726.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8049.63 \n\n### Response: 89.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8874.39 / -5271.14 \n\n### Response: 8874.39 / -5271.14 = -1.68']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -721.97  1 \n\n### Response: -721.97 = -721.97 * 1 = -721.97']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -33x + 79 = 0\n\n### Response: -33x = -79\n-33x / -33 = 79 / -33\nx = -2.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5396.67 + -7513.38 \n\n### Response: 5396.67 + -7513.38 = 5396.67 - 7513.38 = -2116.71']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5555.48 - 2227.05 \n\n### Response: -7782.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3585.58 * -7185.14 \n\n### Response: -2578.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8326.91 + 8323.56 \n\n### Response: 8326.91 + 8323.56 = 16650.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6412.43 + 8195.96 \n\n### Response: 6412.43 + 8195.96 = 14608.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 48  7 \n\n### Response: \n = 48 * 7 = 336 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2068.77 + -1347.07 \n\n### Response: -3415.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 0.64  y = 93x^80 \n\n### Response: \n x = 0.64  y = 93x^80  0.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -44x + 70 = 0\n\n### Response: -44x = -70\n -44x + 70 = 0  -44x = -70 x = -70 / -44  = 1.591.59']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5351.95 + -9780.91 \n\n### Response: -5351.95 + -9780.91 = -5351.95 - 9780.91 = -15132.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6585.23 * -469.39 \n\n### Response: -3090.02']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5591.19 / -7097.76 \n\n### Response: 5591.19 / -7097.76 = -0.79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2910.65 * -4198.96 \n\n### Response: -122200.1']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5861.56 - -6927.43 \n\n### Response: -5861.56 - -6927.43 = -5861.56 + 6927.43 = 1065.87']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5452.84 / -2723.07 \n\n### Response: -5452.84 / -2723.07 = 5452.84 / 2723.07 = 2.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8508.06 / 4921.11 \n\n### Response: 8508.06 / 4921.11 = 1.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3859.13 + 8440.41 \n\n### Response: -3859.13 + 8440.41 = 4581.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6983.88 - -8060.14 \n\n### Response: -6983.88 - -8060.14 = -6983.88 + 8060.14 = 1076.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[17, 99, 52]\n\n### Response: \n17 + 99 + 52 = 168\n168 / 3 = 56.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 680.12  3 \n\n### Response:\xa0\n680.12 * 680.12 * 680.12 = 345324.0008']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -97x + -92 = 0\n\n### Response:  -97x = 92.0 x = 92.0 / -97  = -0.95-0.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 123.84  1 \n\n### Response:123.84  1  123.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5708.06 \n\n### Response: 75.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7194.48 * -6220.64 \n\n### Response: -7194.48 * -6220.64 = 7194.48 * 6220.64 = 4479961.44']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8830.69 * -1065.17 \n\n### Response: -9392.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1855.82 - 1345.12 \n\n### Response: 1855.82 - 1345.12 = 510.7']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8.74 * -9037.79 \n\n### Response: -7.9']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3321.89 * -3531.67 \n\n### Response: -3321.89 * -3531.67 = 3321.89 * 3531.67 = 11748.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3460.04 - -315.20 \n\n### Response: 3460.04 - -315.20 = 3460.04 + 315.20 = 3775.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6185.13 - 2193.41 \n\n### Response: 6185.13 - 2193.41 = 3991.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5208.71 / 3443.94 \n\n### Response: -5208.71 / 3443.94 = -1.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1432.15 + -7448.73 \n\n### Response: 1432.15 + -7448.73 = 1432.15 - 7448.73 = -6016.58']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7375.26 * -8346.62 \n\n### Response: -7375.26 * -8346.62 = 7375.26 * 8346.62 = 6157341.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1552.54 / 6004.21 \n\n### Response: -1552.54 / 6004.21 = -0.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2508.22 / -8899.74 \n\n### Response: -2508.22 / -8899.74 = 2508.22 / 8899.74 = 0.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3459.21 * 4229.30 \n\n### Response: -3459.21 * 4229.30 = -1458450.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[71, 54, 62, 70, 53]\n\n### Response: \n71 + 54 + 62 + 70 + 53 = 310\n310 / 5 = 62.0\n: 62.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -368.19  4 \n\n### Response: -368.19 * -368.19 * -368.19 * -368.19 = 368.19 * 368.19 * 368.19 * 368.19 = 5240.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9245.32 * 2915.01 \n\n### Response: -9245.32 * 2915.01 = -2695411.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3362.63 * 7545.83 \n\n### Response: 3362.63 * 7545.83 = 253880.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -514.60 / 293.74 \n\n### Response: -1.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -80x + 94 = 0\n\n### Response:  -80x = -94.0 x = -94.0 / -80  = 1.181.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3279.11 - 7172.93 \n\n### Response: -3279.11 - 7172.93 = -10452.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9247.11 - 7331.30 \n\n### Response: -16578.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1738.37 + 4806.48 \n\n### Response: -1738.37 + 4806.48 = 3068.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 10.63  2 \n\n### Response: 10.63^2 = 112.65']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7735.89 + 3030.00 \n\n### Response: -4705.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1058.80 * -607.50 \n\n### Response: -1058.80 * -607.50 = 645.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -430.88 - 1101.44 \n\n### Response: -1532.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1923.64 - 8110.60 \n\n### Response: -10034.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 282.03 \n\n### Response: 16.81']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3124.14 / 1192.09 \n\n### Response: -2.62']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2666.20 * 110.52 \n\n### Response: 2666.20 * 110.52 = 294299.0048']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 4.77  y = 86x^97 \n\n### Response: \n x = 4.77  y = 86x^97  = 86 * 4.77^97 = 1001.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7781.42 / -5327.71 \n\n### Response: -7781.42 / -5327.71 = 1.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[27, 89, 99, 64, 76, 50, 100, 49]\n\n### Response: \n[27, 89, 99, 64, 76, 50, 100, 49] : 69.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4294.20 + 9857.73 \n\n### Response: -4294.20 + 9857.73 = 5563.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1214.14 - 1182.21 \n\n### Response: -2396.35']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 475.47  5 \n\n### Response: 475.47 * 475.47 * 475.47 * 475.47 * 475.47 = 1.14 * 10^9']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5078.04 - 8883.67 \n\n### Response: 5078.04 - 8883.67 = -3805.63']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2023.47 - 1907.67 \n\n### Response: -3931.14']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2x + 60 = 0\n\n### Response:  2x = -60.0 x = -60.0 / 2  = -30.0-30.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5415.08 / 8305.15 \n\n### Response: 5415.08 / 8305.15 = 0.65']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2356.30 + 9645.15 \n\n### Response: 2356.30 + 9645.15 = 12001.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 676.46  2 \n\n### Response: 676.46 * 676.46 = 458955.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7076.54 / -2319.93 \n\n### Response: 7076.54 / -2319.93 = -3.05']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -101.17 * -8210.19 \n\n### Response: -101.17 * -8210.19 = 101.17 * 8210.19 = 83097.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -67x + -29 = 0\n\n### Response:  -67x = 29.0 x = 29.0 / -67  = -0.43-0.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4415.70 - -2186.85 \n\n### Response: 4415.70 - -2186.85 = 4415.70 + 2186.85 = 6602.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -513.32  3 \n\n### Response: -513.32 * -513.32 * -513.32 = 131798.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3180.61 - -7868.88 \n\n### Response: 3180.61 - -7868.88 = 3180.61 + 7868.88 = 11049.49']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7157.98 + -8238.21 \n\n### Response: 7157.98 + -8238.21 = 7157.98 - 8238.21 = -1080.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 359.19 * -7366.84 \n\n### Response: 359.19 * -7366.84 = -2645.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -809.94  2 \n\n### Response: -809.94 * -809.94 = 654900.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5049.65 / 9032.66 \n\n### Response: -5049.65 / 9032.66 = -0.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 126.99  1 \n\n### Response:1.12699']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 28  82%\n\n### Response: \n= 28 * 1.82 = 50.96']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 60  21 \n\n### Response: \n60 * 21 = 1260\n 1260 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7648.20 / -1462.33 \n\n### Response: -7648.20 / -1462.33 = 7648.20 / 1462.33 = 5.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5486.28 + -8198.83 \n\n### Response: 5486.28 + -8198.83 = 5486.28 - 8198.83 = -2712.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9628.09 - -9285.90 \n\n### Response: 9628.09 - -9285.90 = 9628.09 + 9285.90 = 18913.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 1.53  y = 15x^63 \n\n### Response: \n x = 1.53  y = 15x^63  = 15 * 1.53^63 = 2.14']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9096.92 + -4287.79 \n\n### Response: 9096.92 + -4287.79 = 9096.92 - 4287.79 = 4809.13']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7872.21 / -5143.52 \n\n### Response: 7872.21 / -5143.52 = -1.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8408.81 + 5175.48 \n\n### Response: -3233.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6960.49 + -2479.37 \n\n### Response: 6960.49 + -2479.37 = 6960.49 - 2479.37 = 4481.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7114.90 / 5453.99 \n\n### Response: -7114.90 / 5453.99 = -1.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3069.64 + -4540.58 \n\n### Response: 3069.64 + -4540.58 = 3069.64 - 4540.58 = -1470.94']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[36, 23, 33, 56, 55, 72, 44]\n\n### Response: \n = 44.29\n[36, 23, 33, 56, 55, 72, 44]  = 319\n7 = \n319 / 7 = 44.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 30  44 \n\n### Response: \n30 * 44 = 1320\n 1320 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7284.02 + -2762.62 \n\n### Response: 7284.02 + -2762.62 = 7284.02 - 2762.62 = 4521.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 18  34 \n\n### Response: \n =  *  = 18 * 34 = 612 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[26, 41, 56, 79, 81, 5, 76]\n\n### Response: \n = 26 + 41 + 56 + 79 + 81 + 5 + 76 / 7 = 364 / 7 = 52.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6642.70 + 2293.71 \n\n### Response: -4348.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2836.04 + -6589.37 \n\n### Response: -9425.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2782.13 / 72.66 \n\n### Response: -38.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3140.68 + 6112.77 \n\n### Response: 3140.68 + 6112.77 = 9253.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9 / 1 \n\n### Response: \n9 * 1 = 9\n9 = 9']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -700.22 / -8699.15 \n\n### Response: -700.22 / -8699.15 = 0.08']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -35x + 80 = 0\n\n### Response:  -35x = -80.0 x = -80.0 / -35  = 2.292.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -413.93 * -3531.49 \n\n### Response: -413.93 * -3531.49 = 413.93 * 3531.49 = 14637.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 941.34  2 \n\n### Response: 941.34 * 941.34 = 884354.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4845.92 * -9135.70 \n\n### Response: -4845.92 * -9135.70 = 4845.92 * 9135.70 = 44278.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 168.34  2 \n\n### Response: 168.34 * 168.34 = 28334.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8109.51 - 4209.08 \n\n### Response: 8109.51 - 4209.08 = 3890.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1163.03 - -9231.14 \n\n### Response: -1163.03 - -9231.14 = -1163.03 + 9231.14 = 8068.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7722.38 - 4159.92 \n\n### Response: 3562.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3815.76 / -6281.84 \n\n### Response: 3815.76 / -6281.84 = -0.61']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9927.99 - -4181.96 \n\n### Response: 9927.99 - -4181.96 = 9927.99 + 4181.96 = 14109.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5807.61 \n\n### Response: 76.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4715.32 * -5259.47 \n\n### Response: -2478191.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5651.40 - -4831.27 \n\n### Response: 5651.40 - -4831.27 = 5651.40 + 4831.27 = 10482.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9194.16 + -5958.91 \n\n### Response: -9194.16 + -5958.91 = -9194.16 - 5958.91 = -15153.07']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 45.65 / 4297.83 \n\n### Response: 45.65 / 4297.83 = 0.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9237.51 \n\n### Response: 96.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4701.55 * 8769.06 \n\n### Response: -4701.55 * 8769.06 = -4127760.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 11x + 64 = 0\n\n### Response:  11x = -64.0 x = -64.0 / 11  = -5.82-5.82']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5851.95 * 2017.43 \n\n### Response: 5851.95 * 2017.43 = 1179652.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4342.43 + 8332.32 \n\n### Response: 4342.43 + 8332.32 = 12674.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -28x + 91 = 0\n\n### Response:  -28x = -91.0 x = -91.0 / -28  = 3.253.25']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 734.05 \n\n### Response:1.57\n734.05  1.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9576.85 / -7526.45 \n\n### Response: -9576.85 / -7526.45 = 9576.85 / 7526.45 = 1.27']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3286.03 * -8033.87 \n\n### Response: -264299.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5462.74 + -8565.38 \n\n### Response: -5462.74 + -8565.38 = -5462.74 - 8565.38 = -14028.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4129.11 - -6919.07 \n\n### Response: 4129.11 - -6919.07 = 4129.11 + 6919.07 = 11048.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1437.03 + 2879.42 \n\n### Response: 1437.03 + 2879.42 = 4316.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3906.35 * 2271.03 \n\n### Response: 3906.35 * 2271.03 = 887900.6']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6911.95 - 5700.39 \n\n### Response: 6911.95 - 5700.39 = 1211.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1908.46 + -4882.32 \n\n### Response: 1908.46 + -4882.32 = 1908.46 - 4882.32 = -2973.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3899.33 - 1603.27 \n\n### Response: 3899.33 - 1603.27 = 2296.06']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4917.70 - -3484.94 \n\n### Response: 4917.70 - -3484.94 = 4917.70 + 3484.94 = 8402.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -570.03 + 2854.20 \n\n### Response: -570.03 + 2854.20 = 2284.17']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9386.28 / 2862.76 \n\n### Response: 9386.28 / 2862.76 = 3.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[29, 21, 47]\n\n### Response: \n29 + 21 + 47 = 97\n97 / 3 = 32.33\n: 32.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3190.15 \n\n### Response:1.79\n3190.15  1.79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2998.34 * 3471.30 \n\n### Response: 2998.34 * 3471.30 = 1039998.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -617.68 * -3365.23 \n\n### Response: -207,855.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2012.37 / 1480.07 \n\n### Response: 2012.37 / 1480.07 = 1.36']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -453.61 - 8996.39 \n\n### Response: -9450.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8621.88 / 5012.04 \n\n### Response: -1.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 31x + 79 = 0\n\n### Response: \n 31x = -79.0 x = -79.0 / 31  = -2.55-2.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5401.27 + 3750.03 \n\n### Response: 5401.27 + 3750.03 = 9151.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3743.44 + 2044.79 \n\n### Response: 3743.44 + 2044.79 = 5788.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 561.81  3 \n\n### Response:\xa0\n561.81 ** 3 = 168.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1  84 \n\n### Response: \n(1 - 84) / 1 = -83 / 1 = -83.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7132.91 * -2496.53 \n\n### Response: 7132.91 * -2496.53 = -17800.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5181.89 * 1825.05 \n\n### Response: 5181.89 * 1825.05 = 9441.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[12, 28, 21, 86, 56, 96]\n\n### Response: \n12 + 28 + 21 + 86 + 56 + 96 = 299\n299 / 6 = 49.83\n: 49.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 263.65  3 \n\n### Response:\xa0\n263.65 * 263.65 * 263.65 = 184996.5.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -871.47  4 \n\n### Response: -871.47 * -871.47 * -871.47 * -871.47 = 871.47 * 871.47 * 871.47 * 871.47 = 7.1e+12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 538.10 / 4758.54 \n\n### Response: 538.10 / 4758.54 = 0.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3288.38 - 5111.78 \n\n### Response: -8399.16']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -979.16  5 \n\n### Response: -979.16 * -979.16 * -979.16 * -979.16 * -979.16 = 979.16 * 979.16 * 979.16 * 979.16 * 979.16 = 979.16 ^ 5 = 9.12 * 10 ^ 5 = 912000.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 264.95 \n\n### Response: 16.38']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7233.93 * 5750.17 \n\n### Response: 7233.93 * 5750.17 = 4157561.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4363.54 + 8053.97 \n\n### Response: 4363.54 + 8053.97 = 12417.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6571.23 \n\n### Response: 81.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7728.88 * 7531.07 \n\n### Response: 7728.88 * 7531.07 = 5823002.54']}]
2024-07-26 23:05:01,416 - mindformers[mindformers/trainer/base_trainer.py:952] - INFO - output result is saved at: text_generation_result.txt
2024-07-26 23:05:01,417 - mindformers[mindformers/trainer/base_trainer.py:953] - INFO - .........Predict Over!.............
2024-07-26 23:05:01,417 - mindformers[mindformers/research/llama3/run_llama3_test.py:181] - INFO - [{'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7451.51 - -1709.92 \n\n### Response: -7451.51 - -1709.92 = -7451.51 + 1709.92 = -5741.59']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1337.47 + 5068.04 \n\n### Response: -1337.47 + 5068.04 = 3730.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6211.70 * -6871.61 \n\n### Response: -6211.70 * -6871.61 = 42667.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3985.41 - -8173.86 \n\n### Response: -3985.41 - -8173.86 = -3985.41 + 8173.86 = 4188.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1075.16 - 8090.56 \n\n### Response: 1075.16 - 8090.56 = -7015.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9299.25 * 1012.66 \n\n### Response: -9390.8 = -9299.25 * 1012.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2864.35 - -8690.01 \n\n### Response: -2864.35 - -8690.01 = -2864.35 + 8690.01 = 5825.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7310.69 + -6470.86 \n\n### Response: 7310.69 + -6470.86 = 7310.69 - 6470.86 = 839.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3476.06 + 2490.05 \n\n### Response: -3476.06 + 2490.05 = -987.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 19  71 \n\n### Response: \n(19 - 71) / 19 = -3.73\n3.73 * 100 = -373.0\n -373.0 %']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1647.72 * -2175.26 \n\n### Response: -3578.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -13x + 10 = 0\n\n### Response:  -13x = -10.0 x = -10.0 / -13  = 0.770.77']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1980.46 - -4548.03 \n\n### Response: -1980.46 + 4548.03 = 2567.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9349.89 + 8736.20 \n\n### Response: -9349.89 + 8736.20 = -613.69']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7881.79 + -3132.78 \n\n### Response: -11014.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7374.53 * -4084.42 \n\n### Response: -3.01 * 10.2 = -30.62']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6811.55 - 2494.54 \n\n### Response: 4317.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6974.95 \n\n### Response: 83.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3957.83 - 3083.39 \n\n### Response: -7041.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8230.71 - 2598.23 \n\n### Response: 8230.71 - 2598.23 = 5632.48']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 53x + 27 = 0\n\n### Response:  53x = -27.0 x = -27.0 / 53  = -0.51-0.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2670.86 / 8327.57 \n\n### Response: 2670.86 / 8327.57 = 0.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1295.35 + 7059.64 \n\n### Response: -1295.35 + 7059.64 = 5764.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5113.34 - 239.46 \n\n### Response: 4873.88']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4157.45 \n\n### Response: 64.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8141.51 - -9883.79 \n\n### Response: -8141.51 - -9883.79 = -8141.51 + 9883.79 = 1742.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3619.12 + -4630.69 \n\n### Response: 3619.12 + -4630.69 = 3619.12 - 4630.69 = -1011.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 50  42 \n\n### Response: \n(50 - 42) / 50 * 100 = 0.16 * 100 = 16.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -337.33  2 \n\n### Response: -337.33 * -337.33 = 337.33 * 337.33 = 113888.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 56  20 \n\n### Response: \n(56 - 20) / 56 * 100 = 64.29 / 56 * 100 = 1.14 * 100 = 114.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5x + -100 = 0\n\n### Response:  -5x = 100.0 x = 100.0 / -5  = -20.0-20.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8115.42 / -8891.52 \n\n### Response: 8115.42 / -8891.52 = -0.91']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4670.73 + 5116.49 \n\n### Response: 4670.73 + 5116.49 = 9787.22']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2921.61 - -426.91 \n\n### Response: 2921.61 - -426.91 = 2921.61 + 426.91 = 3348.52']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 47  12 \n\n### Response: \n(47 - 12) / 47 * 100 = 74.46 / 47 * 100 = 0.58 * 100 = 58.0%\n= 0.58']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4023.23 + -4657.63 \n\n### Response: 4023.23 + -4657.63 = 4023.23 - 4657.63 = -634.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6365.40 \n\n### Response: 80.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6402.63 + 9129.29 \n\n### Response: -6402.63 + 9129.29 = 2726.66']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8049.63 \n\n### Response: 89.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8874.39 / -5271.14 \n\n### Response: 8874.39 / -5271.14 = -1.68']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -721.97  1 \n\n### Response: -721.97 = -721.97 * 1 = -721.97']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -33x + 79 = 0\n\n### Response: -33x = -79\n-33x / -33 = 79 / -33\nx = -2.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5396.67 + -7513.38 \n\n### Response: 5396.67 + -7513.38 = 5396.67 - 7513.38 = -2116.71']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5555.48 - 2227.05 \n\n### Response: -7782.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3585.58 * -7185.14 \n\n### Response: -2578.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8326.91 + 8323.56 \n\n### Response: 8326.91 + 8323.56 = 16650.47']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6412.43 + 8195.96 \n\n### Response: 6412.43 + 8195.96 = 14608.39']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 48  7 \n\n### Response: \n = 48 * 7 = 336 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2068.77 + -1347.07 \n\n### Response: -3415.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 0.64  y = 93x^80 \n\n### Response: \n x = 0.64  y = 93x^80  0.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -44x + 70 = 0\n\n### Response: -44x = -70\n -44x + 70 = 0  -44x = -70 x = -70 / -44  = 1.591.59']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5351.95 + -9780.91 \n\n### Response: -5351.95 + -9780.91 = -5351.95 - 9780.91 = -15132.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6585.23 * -469.39 \n\n### Response: -3090.02']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5591.19 / -7097.76 \n\n### Response: 5591.19 / -7097.76 = -0.79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2910.65 * -4198.96 \n\n### Response: -122200.1']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5861.56 - -6927.43 \n\n### Response: -5861.56 - -6927.43 = -5861.56 + 6927.43 = 1065.87']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5452.84 / -2723.07 \n\n### Response: -5452.84 / -2723.07 = 5452.84 / 2723.07 = 2.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8508.06 / 4921.11 \n\n### Response: 8508.06 / 4921.11 = 1.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3859.13 + 8440.41 \n\n### Response: -3859.13 + 8440.41 = 4581.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6983.88 - -8060.14 \n\n### Response: -6983.88 - -8060.14 = -6983.88 + 8060.14 = 1076.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[17, 99, 52]\n\n### Response: \n17 + 99 + 52 = 168\n168 / 3 = 56.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 680.12  3 \n\n### Response:\xa0\n680.12 * 680.12 * 680.12 = 345324.0008']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -97x + -92 = 0\n\n### Response:  -97x = 92.0 x = 92.0 / -97  = -0.95-0.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 123.84  1 \n\n### Response:123.84  1  123.84']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5708.06 \n\n### Response: 75.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7194.48 * -6220.64 \n\n### Response: -7194.48 * -6220.64 = 7194.48 * 6220.64 = 4479961.44']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8830.69 * -1065.17 \n\n### Response: -9392.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1855.82 - 1345.12 \n\n### Response: 1855.82 - 1345.12 = 510.7']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8.74 * -9037.79 \n\n### Response: -7.9']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3321.89 * -3531.67 \n\n### Response: -3321.89 * -3531.67 = 3321.89 * 3531.67 = 11748.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3460.04 - -315.20 \n\n### Response: 3460.04 - -315.20 = 3460.04 + 315.20 = 3775.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6185.13 - 2193.41 \n\n### Response: 6185.13 - 2193.41 = 3991.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5208.71 / 3443.94 \n\n### Response: -5208.71 / 3443.94 = -1.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1432.15 + -7448.73 \n\n### Response: 1432.15 + -7448.73 = 1432.15 - 7448.73 = -6016.58']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7375.26 * -8346.62 \n\n### Response: -7375.26 * -8346.62 = 7375.26 * 8346.62 = 6157341.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1552.54 / 6004.21 \n\n### Response: -1552.54 / 6004.21 = -0.26']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2508.22 / -8899.74 \n\n### Response: -2508.22 / -8899.74 = 2508.22 / 8899.74 = 0.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3459.21 * 4229.30 \n\n### Response: -3459.21 * 4229.30 = -1458450.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[71, 54, 62, 70, 53]\n\n### Response: \n71 + 54 + 62 + 70 + 53 = 310\n310 / 5 = 62.0\n: 62.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -368.19  4 \n\n### Response: -368.19 * -368.19 * -368.19 * -368.19 = 368.19 * 368.19 * 368.19 * 368.19 = 5240.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9245.32 * 2915.01 \n\n### Response: -9245.32 * 2915.01 = -2695411.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3362.63 * 7545.83 \n\n### Response: 3362.63 * 7545.83 = 253880.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -514.60 / 293.74 \n\n### Response: -1.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -80x + 94 = 0\n\n### Response:  -80x = -94.0 x = -94.0 / -80  = 1.181.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3279.11 - 7172.93 \n\n### Response: -3279.11 - 7172.93 = -10452.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9247.11 - 7331.30 \n\n### Response: -16578.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1738.37 + 4806.48 \n\n### Response: -1738.37 + 4806.48 = 3068.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 10.63  2 \n\n### Response: 10.63^2 = 112.65']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7735.89 + 3030.00 \n\n### Response: -4705.89']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1058.80 * -607.50 \n\n### Response: -1058.80 * -607.50 = 645.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -430.88 - 1101.44 \n\n### Response: -1532.32']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1923.64 - 8110.60 \n\n### Response: -10034.24']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 282.03 \n\n### Response: 16.81']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3124.14 / 1192.09 \n\n### Response: -2.62']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2666.20 * 110.52 \n\n### Response: 2666.20 * 110.52 = 294299.0048']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 4.77  y = 86x^97 \n\n### Response: \n x = 4.77  y = 86x^97  = 86 * 4.77^97 = 1001.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7781.42 / -5327.71 \n\n### Response: -7781.42 / -5327.71 = 1.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[27, 89, 99, 64, 76, 50, 100, 49]\n\n### Response: \n[27, 89, 99, 64, 76, 50, 100, 49] : 69.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4294.20 + 9857.73 \n\n### Response: -4294.20 + 9857.73 = 5563.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1214.14 - 1182.21 \n\n### Response: -2396.35']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 475.47  5 \n\n### Response: 475.47 * 475.47 * 475.47 * 475.47 * 475.47 = 1.14 * 10^9']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5078.04 - 8883.67 \n\n### Response: 5078.04 - 8883.67 = -3805.63']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2023.47 - 1907.67 \n\n### Response: -3931.14']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2x + 60 = 0\n\n### Response:  2x = -60.0 x = -60.0 / 2  = -30.0-30.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5415.08 / 8305.15 \n\n### Response: 5415.08 / 8305.15 = 0.65']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2356.30 + 9645.15 \n\n### Response: 2356.30 + 9645.15 = 12001.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 676.46  2 \n\n### Response: 676.46 * 676.46 = 458955.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7076.54 / -2319.93 \n\n### Response: 7076.54 / -2319.93 = -3.05']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -101.17 * -8210.19 \n\n### Response: -101.17 * -8210.19 = 101.17 * 8210.19 = 83097.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -67x + -29 = 0\n\n### Response:  -67x = 29.0 x = 29.0 / -67  = -0.43-0.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4415.70 - -2186.85 \n\n### Response: 4415.70 - -2186.85 = 4415.70 + 2186.85 = 6602.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -513.32  3 \n\n### Response: -513.32 * -513.32 * -513.32 = 131798.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3180.61 - -7868.88 \n\n### Response: 3180.61 - -7868.88 = 3180.61 + 7868.88 = 11049.49']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7157.98 + -8238.21 \n\n### Response: 7157.98 + -8238.21 = 7157.98 - 8238.21 = -1080.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 359.19 * -7366.84 \n\n### Response: 359.19 * -7366.84 = -2645.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -809.94  2 \n\n### Response: -809.94 * -809.94 = 654900.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5049.65 / 9032.66 \n\n### Response: -5049.65 / 9032.66 = -0.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 126.99  1 \n\n### Response:1.12699']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 28  82%\n\n### Response: \n= 28 * 1.82 = 50.96']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 60  21 \n\n### Response: \n60 * 21 = 1260\n 1260 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7648.20 / -1462.33 \n\n### Response: -7648.20 / -1462.33 = 7648.20 / 1462.33 = 5.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5486.28 + -8198.83 \n\n### Response: 5486.28 + -8198.83 = 5486.28 - 8198.83 = -2712.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9628.09 - -9285.90 \n\n### Response: 9628.09 - -9285.90 = 9628.09 + 9285.90 = 18913.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n x = 1.53  y = 15x^63 \n\n### Response: \n x = 1.53  y = 15x^63  = 15 * 1.53^63 = 2.14']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9096.92 + -4287.79 \n\n### Response: 9096.92 + -4287.79 = 9096.92 - 4287.79 = 4809.13']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7872.21 / -5143.52 \n\n### Response: 7872.21 / -5143.52 = -1.53']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8408.81 + 5175.48 \n\n### Response: -3233.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6960.49 + -2479.37 \n\n### Response: 6960.49 + -2479.37 = 6960.49 - 2479.37 = 4481.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -7114.90 / 5453.99 \n\n### Response: -7114.90 / 5453.99 = -1.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3069.64 + -4540.58 \n\n### Response: 3069.64 + -4540.58 = 3069.64 - 4540.58 = -1470.94']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[36, 23, 33, 56, 55, 72, 44]\n\n### Response: \n = 44.29\n[36, 23, 33, 56, 55, 72, 44]  = 319\n7 = \n319 / 7 = 44.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 30  44 \n\n### Response: \n30 * 44 = 1320\n 1320 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7284.02 + -2762.62 \n\n### Response: 7284.02 + -2762.62 = 7284.02 - 2762.62 = 4521.4']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 18  34 \n\n### Response: \n =  *  = 18 * 34 = 612 ']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[26, 41, 56, 79, 81, 5, 76]\n\n### Response: \n = 26 + 41 + 56 + 79 + 81 + 5 + 76 / 7 = 364 / 7 = 52.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -6642.70 + 2293.71 \n\n### Response: -4348.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2836.04 + -6589.37 \n\n### Response: -9425.41']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -2782.13 / 72.66 \n\n### Response: -38.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3140.68 + 6112.77 \n\n### Response: 3140.68 + 6112.77 = 9253.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9 / 1 \n\n### Response: \n9 * 1 = 9\n9 = 9']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -700.22 / -8699.15 \n\n### Response: -700.22 / -8699.15 = 0.08']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -35x + 80 = 0\n\n### Response:  -35x = -80.0 x = -80.0 / -35  = 2.292.29']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -413.93 * -3531.49 \n\n### Response: -413.93 * -3531.49 = 413.93 * 3531.49 = 14637.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 941.34  2 \n\n### Response: 941.34 * 941.34 = 884354.73']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4845.92 * -9135.70 \n\n### Response: -4845.92 * -9135.70 = 4845.92 * 9135.70 = 44278.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 168.34  2 \n\n### Response: 168.34 * 168.34 = 28334.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 8109.51 - 4209.08 \n\n### Response: 8109.51 - 4209.08 = 3890.43']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -1163.03 - -9231.14 \n\n### Response: -1163.03 - -9231.14 = -1163.03 + 9231.14 = 8068.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7722.38 - 4159.92 \n\n### Response: 3562.46']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3815.76 / -6281.84 \n\n### Response: 3815.76 / -6281.84 = -0.61']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9927.99 - -4181.96 \n\n### Response: 9927.99 - -4181.96 = 9927.99 + 4181.96 = 14109.95']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5807.61 \n\n### Response: 76.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4715.32 * -5259.47 \n\n### Response: -2478191.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5651.40 - -4831.27 \n\n### Response: 5651.40 - -4831.27 = 5651.40 + 4831.27 = 10482.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9194.16 + -5958.91 \n\n### Response: -9194.16 + -5958.91 = -9194.16 - 5958.91 = -15153.07']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 45.65 / 4297.83 \n\n### Response: 45.65 / 4297.83 = 0.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9237.51 \n\n### Response: 96.67']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -4701.55 * 8769.06 \n\n### Response: -4701.55 * 8769.06 = -4127760.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 11x + 64 = 0\n\n### Response:  11x = -64.0 x = -64.0 / 11  = -5.82-5.82']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5851.95 * 2017.43 \n\n### Response: 5851.95 * 2017.43 = 1179652.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4342.43 + 8332.32 \n\n### Response: 4342.43 + 8332.32 = 12674.75']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -28x + 91 = 0\n\n### Response:  -28x = -91.0 x = -91.0 / -28  = 3.253.25']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 734.05 \n\n### Response:1.57\n734.05  1.57']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -9576.85 / -7526.45 \n\n### Response: -9576.85 / -7526.45 = 9576.85 / 7526.45 = 1.27']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3286.03 * -8033.87 \n\n### Response: -264299.01']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -5462.74 + -8565.38 \n\n### Response: -5462.74 + -8565.38 = -5462.74 - 8565.38 = -14028.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4129.11 - -6919.07 \n\n### Response: 4129.11 - -6919.07 = 4129.11 + 6919.07 = 11048.18']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1437.03 + 2879.42 \n\n### Response: 1437.03 + 2879.42 = 4316.45']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3906.35 * 2271.03 \n\n### Response: 3906.35 * 2271.03 = 887900.6']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6911.95 - 5700.39 \n\n### Response: 6911.95 - 5700.39 = 1211.56']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1908.46 + -4882.32 \n\n### Response: 1908.46 + -4882.32 = 1908.46 - 4882.32 = -2973.86']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3899.33 - 1603.27 \n\n### Response: 3899.33 - 1603.27 = 2296.06']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4917.70 - -3484.94 \n\n### Response: 4917.70 - -3484.94 = 4917.70 + 3484.94 = 8402.64']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -570.03 + 2854.20 \n\n### Response: -570.03 + 2854.20 = 2284.17']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 9386.28 / 2862.76 \n\n### Response: 9386.28 / 2862.76 = 3.28']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[29, 21, 47]\n\n### Response: \n29 + 21 + 47 = 97\n97 / 3 = 32.33\n: 32.33']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3190.15 \n\n### Response:1.79\n3190.15  1.79']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2998.34 * 3471.30 \n\n### Response: 2998.34 * 3471.30 = 1039998.03']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -617.68 * -3365.23 \n\n### Response: -207,855.98']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 2012.37 / 1480.07 \n\n### Response: 2012.37 / 1480.07 = 1.36']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -453.61 - 8996.39 \n\n### Response: -9450.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -8621.88 / 5012.04 \n\n### Response: -1.72']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 31x + 79 = 0\n\n### Response: \n 31x = -79.0 x = -79.0 / 31  = -2.55-2.55']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5401.27 + 3750.03 \n\n### Response: 5401.27 + 3750.03 = 9151.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 3743.44 + 2044.79 \n\n### Response: 3743.44 + 2044.79 = 5788.23']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 561.81  3 \n\n### Response:\xa0\n561.81 ** 3 = 168.5']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 1  84 \n\n### Response: \n(1 - 84) / 1 = -83 / 1 = -83.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7132.91 * -2496.53 \n\n### Response: 7132.91 * -2496.53 = -17800.04']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 5181.89 * 1825.05 \n\n### Response: 5181.89 * 1825.05 = 9441.99']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n[12, 28, 21, 86, 56, 96]\n\n### Response: \n12 + 28 + 21 + 86 + 56 + 96 = 299\n299 / 6 = 49.83\n: 49.83']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 263.65  3 \n\n### Response:\xa0\n263.65 * 263.65 * 263.65 = 184996.5.3']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -871.47  4 \n\n### Response: -871.47 * -871.47 * -871.47 * -871.47 = 871.47 * 871.47 * 871.47 * 871.47 = 7.1e+12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 538.10 / 4758.54 \n\n### Response: 538.10 / 4758.54 = 0.11']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -3288.38 - 5111.78 \n\n### Response: -8399.16']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n -979.16  5 \n\n### Response: -979.16 * -979.16 * -979.16 * -979.16 * -979.16 = 979.16 * 979.16 * 979.16 * 979.16 * 979.16 = 979.16 ^ 5 = 9.12 * 10 ^ 5 = 912000.0']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 264.95 \n\n### Response: 16.38']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7233.93 * 5750.17 \n\n### Response: 7233.93 * 5750.17 = 4157561.54']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 4363.54 + 8053.97 \n\n### Response: 4363.54 + 8053.97 = 12417.51']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 6571.23 \n\n### Response: 81.12']}, {'text_generation_text': ['Below is an instruction that describes a grade school math problem. Write a response that gives the correct answer.\n\n### Instruction:\n 7728.88 * 7531.07 \n\n### Response: 7728.88 * 7531.07 = 5823002.54']}]
