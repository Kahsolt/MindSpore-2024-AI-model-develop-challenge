/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
********************** infer list len:  200
2024-07-05 14:03:41,018 - mindformers[mindformers/trainer/trainer.py:919] - INFO - Load configs in /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml to build trainer.
2024-07-05 14:03:41,019 - mindformers[mindformers/trainer/trainer.py:949] - INFO - ..........Init Config..........
2024-07-05 14:03:41,019 - mindformers[mindformers/core/parallel_config.py:45] - INFO - initial recompute_config from dict: {'recompute': False, 'select_recompute': False, 'parallel_optimizer_comm_recompute': False, 'mp_comm_recompute': True, 'recompute_slice_activation': True}
2024-07-05 14:03:41,019 - mindformers[mindformers/core/parallel_config.py:51] - INFO - initial parallel_config from dict: {'data_parallel': 1, 'model_parallel': 1, 'pipeline_stage': 1, 'use_seq_parallel': False, 'micro_batch_num': 1, 'vocab_emb_dp': True, 'gradient_aggregation_group': 4}
2024-07-05 14:03:41,020 - mindformers[mindformers/tools/utils.py:153] - INFO - set output path to '/home/ma-user/work/mindformers/research/output'
2024-07-05 14:03:41,021 - mindformers[mindformers/tools/utils.py:168] - INFO - set strategy path to './output/strategy/ckpt_strategy_rank_0.ckpt'
2024-07-05 14:03:41,021 - mindformers[mindformers/trainer/base_trainer.py:85] - INFO - Now Running Task is: text_generation, Model is: llama3_8b
2024-07-05 14:03:41,022 - mindformers[mindformers/trainer/base_trainer.py:111] - WARNING - Input model name is not in the supported list or unspecified.
2024-07-05 14:03:41,022 - mindformers[mindformers/trainer/base_trainer.py:112] - WARNING - See the list of supported task and model name: ['baichuan2_13b', 'baichuan2_7b', 'baichuan_7b', 'bloom_176b', 'bloom_560m', 'bloom_65b', 'bloom_7.1b', 'codegeex2_6b', 'codellama_34b', 'common', 'deepseek_33b', 'glm2_6b', 'glm2_6b_lora', 'glm2_6b_ptuning2', 'glm3_6b', 'glm_6b', 'glm_6b_chat', 'glm_6b_lora', 'glm_6b_lora_chat', 'gpt2', 'gpt2_13b', 'gpt2_52b', 'gpt2_lora', 'gpt2_xl', 'gpt2_xl_lora', 'internlm_7b', 'internlm_7b_lora', 'llama2_13b', 'llama2_70b', 'llama2_7b', 'llama_13b', 'llama_65b', 'llama_7b', 'llama_7b_lora', 'pangualpha_13b', 'pangualpha_2_6b', 'qwen_7b', 'qwen_7b_lora', 'skywork_13b', 'yi_34b', 'yi_6b', 'ziya_13b']
2024-07-05 14:03:41,022 - mindformers[mindformers/trainer/base_trainer.py:113] - WARNING - The default model config: /home/ma-user/work/mindformers/configs/gpt2/run_gpt2.yaml will now be used for the text_generation task 
2024-07-05 14:03:41,022 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-07-05 14:03:41,023 - mindformers[mindformers/trainer/trainer.py:335] - INFO - ==========Trainer Init Success!==========
2024-07-05 14:03:41,023 - mindformers[mindformers/trainer/trainer.py:1004] - INFO - ..........Init Model..........
2024-07-05 14:03:41,023 - mindformers[mindformers/trainer/base_trainer.py:213] - INFO - The current parallel mode is stand_alone, batch size per card will not be changed: batch_size_per_card = 1
2024-07-05 14:03:41,023 - mindformers[mindformers/trainer/base_trainer.py:217] - INFO - global_batch_size = batch_size_per_card * device_num * gradient_accumulation_steps = 1 = 1 * 1 * 1
2024-07-05 14:03:41,024 - mindformers[mindformers/trainer/base_trainer.py:226] - INFO - parallel_config will be change to default config: [ParallelConfig]
_recompute:[ParallelConfig]
_recompute:False
_select_recompute:False
_select_comm_recompute:False
_parallel_optimizer_comm_recompute:False
_mp_comm_recompute:True
_recompute_slice_activation:True
select_recompute:False
use_seq_parallel:False
_optimizer_shard:None
_gradient_aggregation_group:4
_embed_dp_mp_config:[ParallelConfig]
_dp_mp_config:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False
_vocab_emb_dp:True
use_seq_parallel:False
select_recompute:False
_pp_config:[ParallelConfig]
_pipeline_stage:1
_micro_batch_num:1
_moe_config:[ParallelConfig]
_dpmp:[ParallelConfig]
_data_parallel:1
_model_parallel:1
use_seq_parallel:False
select_recompute:False
_expert_parallel:1
use_seq_parallel:False
select_recompute:False
.
2024-07-05 14:03:41,024 - mindformers[mindformers/trainer/base_trainer.py:387] - INFO - .........Build Network From Config..........
2024-07-05 14:03:41,025 - mindformers[mindformers/version_control.py:61] - INFO - The Cell Reuse compilation acceleration feature is not supported when the environment variable ENABLE_CELL_REUSE is 0 or MindSpore version is earlier than 2.1.0 or stand_alone mode or pipeline_stages <= 1
2024-07-05 14:03:41,025 - mindformers[mindformers/version_control.py:65] - INFO - 
The current ENABLE_CELL_REUSE=0, please set the environment variable as follows: 
export ENABLE_CELL_REUSE=1 to enable the Cell Reuse compilation acceleration feature.
2024-07-05 14:03:41,025 - mindformers[mindformers/version_control.py:71] - INFO - The Cell Reuse compilation acceleration feature does not support single-card mode.This feature is disabled by default. ENABLE_CELL_REUSE=1 does not take effect.
2024-07-05 14:03:41,026 - mindformers[mindformers/version_control.py:74] - INFO - The Cell Reuse compilation acceleration feature only works in pipeline parallel mode(pipeline_stage>1).Current pipeline stage=1, the feature is disabled by default.
[WARNING] DEVICE(13247,ffffb8337010,python):2024-07-05-14:03:41.294.537 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:95] Initialize] Reserved memory size for other components(536870912) is less than recommend size(1892153088), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory'
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:04:02.893.539 [mindspore/ops/primitive.py:203] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. 
If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL)
2024-07-05 14:04:13,577 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:04:13.579.775 [mindspore/common/_decorator.py:40] 'Parameter' is deprecated from version 2.3 and will be removed in a future version, use 'add_pipeline_stage' instead.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:04:13.579.918 [mindspore/common/parameter.py:806] This interface may be deleted in the future.
2024-07-05 14:04:16,489 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:19,478 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:22,465 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:25,275 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:28,304 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:31,398 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:34,394 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:37,290 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:04:40,296 - mindformers[mindformers/models/llama/llama_transformer.py:468] - INFO - MoE config is None, use normal FFN
2024-07-05 14:05:53,641 - mindformers[mindformers/models/modeling_utils.py:1438] - INFO - model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None.
2024-07-05 14:05:53,642 - mindformers[mindformers/models/modeling_utils.py:591] - INFO - Set jit config for jit level:O0 and infer boost:on.
2024-07-05 14:05:53,657 - mindformers[mindformers/trainer/base_trainer.py:543] - INFO - Network Parameters: 8030261248.
2024-07-05 14:05:54,707 - mindformers[mindformers/trainer/utils.py:736] - INFO - ............Start load checkpoint from checkpoint............
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:28.322.776 [mindspore/train/serialization.py:195] The type of model.tok_embeddings.embedding_weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:41.224.899 [mindspore/train/serialization.py:195] The type of model.layers.0.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:41.228.710 [mindspore/train/serialization.py:195] The type of model.layers.0.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:41.802.121 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:42.330.642 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:42.568.637 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:43.233.979 [mindspore/train/serialization.py:195] The type of model.layers.0.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:45.558.784 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:48.819.436 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:52.598.35 [mindspore/train/serialization.py:195] The type of model.layers.0.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:53.476.305 [mindspore/train/serialization.py:195] The type of model.layers.1.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:53.480.036 [mindspore/train/serialization.py:195] The type of model.layers.1.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:54.226.67 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:54.546.519 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:54.771.048 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:55.417.478 [mindspore/train/serialization.py:195] The type of model.layers.1.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:07:57.725.341 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:01.725.3 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:04.269.547 [mindspore/train/serialization.py:195] The type of model.layers.1.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:05.632.362 [mindspore/train/serialization.py:195] The type of model.layers.2.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:05.636.114 [mindspore/train/serialization.py:195] The type of model.layers.2.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:06.166.796 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:06.728.382 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:06.970.241 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:07.597.962 [mindspore/train/serialization.py:195] The type of model.layers.2.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:09.908.719 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:13.362.539 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:16.827.430 [mindspore/train/serialization.py:195] The type of model.layers.2.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:18.224.878 [mindspore/train/serialization.py:195] The type of model.layers.3.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:18.228.636 [mindspore/train/serialization.py:195] The type of model.layers.3.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:18.784.083 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:19.307.688 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:19.535.969 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:20.187.790 [mindspore/train/serialization.py:195] The type of model.layers.3.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:22.625.796 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:25.911.233 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:29.350.858 [mindspore/train/serialization.py:195] The type of model.layers.3.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:30.741.028 [mindspore/train/serialization.py:195] The type of model.layers.4.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:30.744.828 [mindspore/train/serialization.py:195] The type of model.layers.4.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:31.296.126 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:31.821.200 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:32.497.68 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:32.686.189 [mindspore/train/serialization.py:195] The type of model.layers.4.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:35.124.91 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:38.362.856 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:41.628.347 [mindspore/train/serialization.py:195] The type of model.layers.4.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:43.199.80 [mindspore/train/serialization.py:195] The type of model.layers.5.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:43.238.70 [mindspore/train/serialization.py:195] The type of model.layers.5.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:43.584.784 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:44.104.439 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:44.357.280 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:44.980.425 [mindspore/train/serialization.py:195] The type of model.layers.5.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:47.297.061 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:50.763.194 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:54.698.27 [mindspore/train/serialization.py:195] The type of model.layers.5.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:55.472.159 [mindspore/train/serialization.py:195] The type of model.layers.6.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:55.475.983 [mindspore/train/serialization.py:195] The type of model.layers.6.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:56.475.3 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:56.545.495 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:56.788.960 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:57.446.914 [mindspore/train/serialization.py:195] The type of model.layers.6.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:08:59.798.646 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:03.123.317 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:06.439.218 [mindspore/train/serialization.py:195] The type of model.layers.6.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:07.832.666 [mindspore/train/serialization.py:195] The type of model.layers.7.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:07.836.587 [mindspore/train/serialization.py:195] The type of model.layers.7.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:08.369.155 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:08.895.683 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:09.121.973 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:09.759.703 [mindspore/train/serialization.py:195] The type of model.layers.7.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:12.138.478 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:15.469.244 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:18.798.559 [mindspore/train/serialization.py:195] The type of model.layers.7.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:20.174.335 [mindspore/train/serialization.py:195] The type of model.layers.8.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:20.178.180 [mindspore/train/serialization.py:195] The type of model.layers.8.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:20.736.334 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:21.278.811 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:21.503.206 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:22.142.520 [mindspore/train/serialization.py:195] The type of model.layers.8.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:24.423.295 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:27.698.935 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:31.225.515 [mindspore/train/serialization.py:195] The type of model.layers.8.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:32.610.934 [mindspore/train/serialization.py:195] The type of model.layers.9.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:32.614.816 [mindspore/train/serialization.py:195] The type of model.layers.9.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:33.168.714 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:33.699.215 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:33.932.261 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:34.577.423 [mindspore/train/serialization.py:195] The type of model.layers.9.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:36.917.532 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:40.269.792 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:43.483.991 [mindspore/train/serialization.py:195] The type of model.layers.9.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:44.864.086 [mindspore/train/serialization.py:195] The type of model.layers.10.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:44.867.922 [mindspore/train/serialization.py:195] The type of model.layers.10.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:45.463.856 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:46.401.9 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:46.229.453 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:46.873.237 [mindspore/train/serialization.py:195] The type of model.layers.10.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:49.176.794 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:52.450.032 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:55.773.663 [mindspore/train/serialization.py:195] The type of model.layers.10.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:57.161.854 [mindspore/train/serialization.py:195] The type of model.layers.11.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:57.165.691 [mindspore/train/serialization.py:195] The type of model.layers.11.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:57.723.012 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:58.245.362 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:58.469.213 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:09:59.327.711 [mindspore/train/serialization.py:195] The type of model.layers.11.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:01.673.358 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:05.179.86 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:08.266.786 [mindspore/train/serialization.py:195] The type of model.layers.11.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:09.647.319 [mindspore/train/serialization.py:195] The type of model.layers.12.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:09.651.239 [mindspore/train/serialization.py:195] The type of model.layers.12.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:10.186.081 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:10.715.466 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:10.940.861 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:11.579.453 [mindspore/train/serialization.py:195] The type of model.layers.12.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:13.947.009 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:17.186.530 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:20.450.373 [mindspore/train/serialization.py:195] The type of model.layers.12.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:21.821.620 [mindspore/train/serialization.py:195] The type of model.layers.13.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:21.825.487 [mindspore/train/serialization.py:195] The type of model.layers.13.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:22.389.042 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:22.912.607 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:23.137.987 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:23.771.425 [mindspore/train/serialization.py:195] The type of model.layers.13.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:26.101.519 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:29.413.162 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:32.664.360 [mindspore/train/serialization.py:195] The type of model.layers.13.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:34.660.51 [mindspore/train/serialization.py:195] The type of model.layers.14.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:34.698.76 [mindspore/train/serialization.py:195] The type of model.layers.14.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:34.591.829 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:35.109.972 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:35.335.263 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:35.963.902 [mindspore/train/serialization.py:195] The type of model.layers.14.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:38.253.990 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:41.572.572 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:44.775.334 [mindspore/train/serialization.py:195] The type of model.layers.14.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:46.146.216 [mindspore/train/serialization.py:195] The type of model.layers.15.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:46.150.152 [mindspore/train/serialization.py:195] The type of model.layers.15.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:46.675.126 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:47.210.621 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:47.435.973 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:48.698.59 [mindspore/train/serialization.py:195] The type of model.layers.15.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:50.390.624 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:53.664.092 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:56.983.334 [mindspore/train/serialization.py:195] The type of model.layers.15.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:58.365.036 [mindspore/train/serialization.py:195] The type of model.layers.16.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:58.368.977 [mindspore/train/serialization.py:195] The type of model.layers.16.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:58.896.084 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:59.416.566 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:10:59.646.466 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:00.273.217 [mindspore/train/serialization.py:195] The type of model.layers.16.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:02.606.112 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:05.862.579 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:09.115.107 [mindspore/train/serialization.py:195] The type of model.layers.16.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:10.537.204 [mindspore/train/serialization.py:195] The type of model.layers.17.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:10.541.170 [mindspore/train/serialization.py:195] The type of model.layers.17.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:11.775.18 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:11.595.787 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:11.821.482 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:12.451.536 [mindspore/train/serialization.py:195] The type of model.layers.17.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:14.747.682 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:18.367.26 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:21.316.292 [mindspore/train/serialization.py:195] The type of model.layers.17.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:22.706.855 [mindspore/train/serialization.py:195] The type of model.layers.18.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:22.710.790 [mindspore/train/serialization.py:195] The type of model.layers.18.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:23.256.056 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:23.847.924 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:24.793.08 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:24.699.430 [mindspore/train/serialization.py:195] The type of model.layers.18.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:27.234.66 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:30.317.631 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:33.580.352 [mindspore/train/serialization.py:195] The type of model.layers.18.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:34.963.496 [mindspore/train/serialization.py:195] The type of model.layers.19.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:34.967.424 [mindspore/train/serialization.py:195] The type of model.layers.19.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:35.506.636 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:36.369.53 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:36.266.439 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:36.904.555 [mindspore/train/serialization.py:195] The type of model.layers.19.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:39.268.291 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:42.573.930 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:45.840.770 [mindspore/train/serialization.py:195] The type of model.layers.19.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:47.212.784 [mindspore/train/serialization.py:195] The type of model.layers.20.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:47.216.766 [mindspore/train/serialization.py:195] The type of model.layers.20.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:47.763.131 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:48.305.901 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:48.532.935 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:49.178.607 [mindspore/train/serialization.py:195] The type of model.layers.20.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:51.519.980 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:54.806.778 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:58.981.66 [mindspore/train/serialization.py:195] The type of model.layers.20.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:59.482.033 [mindspore/train/serialization.py:195] The type of model.layers.21.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:11:59.485.964 [mindspore/train/serialization.py:195] The type of model.layers.21.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:00.322.15 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:00.547.840 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:00.772.005 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:01.415.770 [mindspore/train/serialization.py:195] The type of model.layers.21.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:03.740.847 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:07.842.94 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:10.394.442 [mindspore/train/serialization.py:195] The type of model.layers.21.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:11.756.559 [mindspore/train/serialization.py:195] The type of model.layers.22.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:11.760.570 [mindspore/train/serialization.py:195] The type of model.layers.22.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:12.310.946 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:12.829.810 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:13.567.33 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:13.691.793 [mindspore/train/serialization.py:195] The type of model.layers.22.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:16.780.8 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:19.289.067 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:22.593.096 [mindspore/train/serialization.py:195] The type of model.layers.22.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:24.114.54 [mindspore/train/serialization.py:195] The type of model.layers.23.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:24.154.37 [mindspore/train/serialization.py:195] The type of model.layers.23.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:24.558.542 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:25.767.40 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:25.301.062 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:25.939.549 [mindspore/train/serialization.py:195] The type of model.layers.23.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:28.263.211 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:31.576.049 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:34.866.135 [mindspore/train/serialization.py:195] The type of model.layers.23.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:36.269.465 [mindspore/train/serialization.py:195] The type of model.layers.24.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:36.273.413 [mindspore/train/serialization.py:195] The type of model.layers.24.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:36.798.176 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:37.331.910 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:37.566.256 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:38.208.011 [mindspore/train/serialization.py:195] The type of model.layers.24.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:40.542.473 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:43.786.316 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:47.900.78 [mindspore/train/serialization.py:195] The type of model.layers.24.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:48.481.711 [mindspore/train/serialization.py:195] The type of model.layers.25.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:48.631.072 [mindspore/train/serialization.py:195] The type of model.layers.25.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:49.179.161 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:49.720.859 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:49.947.165 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:50.601.140 [mindspore/train/serialization.py:195] The type of model.layers.25.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:52.906.164 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:56.192.868 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:12:59.477.532 [mindspore/train/serialization.py:195] The type of model.layers.25.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:00.888.325 [mindspore/train/serialization.py:195] The type of model.layers.26.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:00.892.267 [mindspore/train/serialization.py:195] The type of model.layers.26.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:01.418.939 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:01.963.385 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:02.230.631 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:02.855.768 [mindspore/train/serialization.py:195] The type of model.layers.26.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:05.184.751 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:08.471.699 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:11.795.169 [mindspore/train/serialization.py:195] The type of model.layers.26.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:13.165.337 [mindspore/train/serialization.py:195] The type of model.layers.27.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:13.169.325 [mindspore/train/serialization.py:195] The type of model.layers.27.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:13.704.848 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:14.247.879 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:14.491.302 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:15.127.833 [mindspore/train/serialization.py:195] The type of model.layers.27.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:17.465.823 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:20.798.088 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:24.123.951 [mindspore/train/serialization.py:195] The type of model.layers.27.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:25.506.410 [mindspore/train/serialization.py:195] The type of model.layers.28.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:25.510.406 [mindspore/train/serialization.py:195] The type of model.layers.28.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:26.507.47 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:26.580.657 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:26.814.413 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:27.464.705 [mindspore/train/serialization.py:195] The type of model.layers.28.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:29.818.647 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:33.896.54 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:36.411.458 [mindspore/train/serialization.py:195] The type of model.layers.28.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:37.799.554 [mindspore/train/serialization.py:195] The type of model.layers.29.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:37.803.514 [mindspore/train/serialization.py:195] The type of model.layers.29.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:38.352.979 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:38.873.453 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:39.120.455 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:39.744.692 [mindspore/train/serialization.py:195] The type of model.layers.29.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:42.930.27 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:45.443.511 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:48.740.475 [mindspore/train/serialization.py:195] The type of model.layers.29.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:50.129.138 [mindspore/train/serialization.py:195] The type of model.layers.30.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:50.133.165 [mindspore/train/serialization.py:195] The type of model.layers.30.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:50.675.432 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:51.230.998 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:51.455.682 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:52.951.70 [mindspore/train/serialization.py:195] The type of model.layers.30.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:54.436.793 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:13:57.698.984 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:00.985.986 [mindspore/train/serialization.py:195] The type of model.layers.30.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:02.386.704 [mindspore/train/serialization.py:195] The type of model.layers.31.ffn_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:02.390.718 [mindspore/train/serialization.py:195] The type of model.layers.31.attention_norm.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:02.950.661 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wq.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:03.473.167 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wk.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:03.720.908 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wv.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:04.376.826 [mindspore/train/serialization.py:195] The type of model.layers.31.attention.wo.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:06.730.199 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w1.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:10.312.20 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w2.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:13.397.327 [mindspore/train/serialization.py:195] The type of model.layers.31.feed_forward.w3.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:14.781.784 [mindspore/train/serialization.py:195] The type of model.norm_out.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from BFloat16 to Float32 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:32.186.049 [mindspore/train/serialization.py:195] The type of lm_head.weight:BFloat16 in 'parameter_dict' is different from the type of it in 'net':Float16, then the type convert from BFloat16 to Float16 in the network.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:44.923.299 [mindspore/train/serialization.py:1456] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint.
[WARNING] ME(13247:281473772122128,MainProcess):2024-07-05-14:14:44.923.631 [mindspore/train/serialization.py:1460] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded.
2024-07-05 14:14:44,923 - mindformers[mindformers/trainer/utils.py:767] - INFO - Network parameters are not loaded: (['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'], [])
{'auto_trans_ckpt': False,
 'auto_tune': False,
 'autotune_per_step': 10,
 'callbacks': [OrderedDict([('type', 'MFLossMonitor')]),
               OrderedDict([('type', 'CheckpointMointor'),
                            ('prefix', 'llama3_8b'),
                            ('save_checkpoint_steps', 10000),
                            ('integrated_save', False),
                            ('async_save', False)]),
               OrderedDict([('type', 'ObsMonitor')])],
 'context': {'device_id': 0,
             'device_target': 'Ascend',
             'enable_graph_kernel': False,
             'graph_kernel_flags': '--disable_expand_ops=Softmax,Dropout '
                                   '--enable_parallel_fusion=true '
                                   '--reduce_fuse_depth=8 '
                                   '--enable_auto_tensor_inplace=true',
             'max_call_depth': 10000,
             'runtime_num_threads': 1,
             'save_graphs': False,
             'save_graphs_path': './graph'},
 'device_num': 1,
 'do_eval': False,
 'eval_callbacks': [OrderedDict([('type', 'ObsMonitor')])],
 'eval_dataset': {'auto_tune': False,
                  'autotune_per_step': 10,
                  'batch_size': 1,
                  'data_loader': {'dataset_dir': '',
                                  'shuffle': False,
                                  'type': 'MindDataset'},
                  'do_eval': True,
                  'drop_remainder': False,
                  'filepath_prefix': './autotune',
                  'input_columns': ['input_ids', 'labels'],
                  'num_parallel_workers': 8,
                  'numa_enable': False,
                  'output_columns': ['input_ids', 'labels'],
                  'prefetch_size': 1,
                  'profile': False,
                  'python_multiprocessing': False,
                  'repeat': 1,
                  'seed': 0},
 'eval_dataset_task': {'dataset_config': {'auto_tune': False,
                                          'autotune_per_step': 10,
                                          'batch_size': 1,
                                          'data_loader': {'dataset_dir': '',
                                                          'shuffle': False,
                                                          'type': 'MindDataset'},
                                          'do_eval': True,
                                          'drop_remainder': False,
                                          'filepath_prefix': './autotune',
                                          'input_columns': ['input_ids',
                                                            'labels'],
                                          'num_parallel_workers': 8,
                                          'numa_enable': False,
                                          'output_columns': ['input_ids',
                                                             'labels'],
                                          'prefetch_size': 1,
                                          'profile': False,
                                          'python_multiprocessing': False,
                                          'repeat': 1,
                                          'seed': 0},
                       'type': 'CausalLanguageModelDataset'},
 'filepath_prefix': './autotune',
 'init_start_profile': False,
 'layer_decay': 0.65,
 'layer_scale': False,
 'load_checkpoint': '/home/ma-user/work/llama3-8B.ckpt',
 'local_rank': 0,
 'lr_scale_factor': 256,
 'lr_schedule': {'learning_rate': 5e-05,
                 'lr_end': 0.0,
                 'total_steps': -1,
                 'type': 'CosineWithWarmUpLR',
                 'warmup_ratio': 0.03},
 'metric': [{'type': 'EmF1Metric'}],
 'micro_batch_interleave_num': 1,
 'model': {'arch': {'type': 'LlamaForCausalLM'},
           'model_config': {'batch_size': 1,
                            'bos_token_id': 128000,
                            'checkpoint_name_or_path': None,
                            'compute_dtype': 'float16',
                            'do_sample': False,
                            'eos_token_id': 128001,
                            'extend_method': 'None',
                            'fine_grain_interleave': 1,
                            'hidden_size': 4096,
                            'ignore_token_id': -100,
                            'intermediate_size': 14336,
                            'layernorm_compute_type': 'float32',
                            'max_decode_length': 700,
                            'max_new_tokens': 20,
                            'n_kv_heads': 8,
                            'num_heads': 32,
                            'num_layers': 32,
                            'offset': 0,
                            'pad_token_id': 128002,
                            'param_init_type': 'float16',
                            'repetition_penalty': 1,
                            'rms_norm_eps': 1e-05,
                            'rotary_dtype': 'float32',
                            'scaling_factor': 1.0,
                            'seq_length': 8192,
                            'softmax_compute_type': 'float32',
                            'theta': 500000,
                            'top_k': 3,
                            'top_p': 1,
                            'type': 'LlamaConfig',
                            'use_flash_attention': False,
                            'use_past': True,
                            'vocab_size': 128256}},
 'moe_config': <mindformers.modules.transformer.moe.MoEConfig object at 0xfffead90bc40>,
 'only_save_strategy': False,
 'optimizer': {'beta1': 0.9,
               'beta2': 0.95,
               'eps': 1e-08,
               'learning_rate': 5e-05,
               'type': 'FP32StateAdamWeightDecay'},
 'output_dir': './output',
 'parallel': {'enable_alltoall': False,
              'enable_parallel_optimizer': False,
              'full_batch': True,
              'gradients_mean': False,
              'parallel_mode': 1,
              'parallel_optimizer_config': {'gradient_accumulation_shard': False,
                                            'parallel_optimizer_threshold': 64},
              'search_mode': 'sharding_propagation',
              'strategy_ckpt_save_file': './output/strategy/ckpt_strategy_rank_0.ckpt'},
 'parallel_config': <mindformers.modules.transformer.transformer.TransformerOpParallelConfig object at 0xfffe1c79d340>,
 'processor': {'return_tensors': 'ms',
               'tokenizer': {'model_max_length': 8192,
                             'pad_token': '<|reserved_special_token_0|>',
                             'type': 'Llama3Tokenizer',
                             'vocab_file': '/home/ma-user/work/tokenizer.model'},
               'type': 'LlamaProcessor'},
 'profile': False,
 'profile_communication': False,
 'profile_memory': True,
 'profile_start_step': 4,
 'profile_stop_step': 8,
 'rank_id': 0,
 'recompute_config': <mindformers.modules.transformer.transformer.TransformerRecomputeConfig object at 0xfffe1c79d160>,
 'remote_save_url': '',
 'resume_training': False,
 'run_mode': 'predict',
 'runner_config': {'batch_size': 1,
                   'epochs': 2,
                   'gradient_accumulation_steps': 1,
                   'sink_mode': True,
                   'sink_size': 2},
 'runner_wrapper': {'scale_sense': 1.0,
                    'type': 'MFTrainOneStepCell',
                    'use_clip_grad': True},
 'seed': 0,
 'src_strategy_path_or_dir': '',
 'train_dataset': {'auto_tune': False,
                   'autotune_per_step': 10,
                   'batch_size': 1,
                   'data_loader': {'dataset_dir': '',
                                   'shuffle': True,
                                   'type': 'MindDataset'},
                   'do_eval': False,
                   'drop_remainder': True,
                   'filepath_prefix': './autotune',
                   'input_columns': ['input_ids'],
                   'num_parallel_workers': 8,
                   'numa_enable': False,
                   'output_columns': ['input_ids'],
                   'prefetch_size': 1,
                   'profile': False,
                   'python_multiprocessing': False,
                   'repeat': 1,
                   'seed': 0},
 'train_dataset_task': {'dataset_config': {'auto_tune': False,
                                           'autotune_per_step': 10,
                                           'batch_size': 1,
                                           'data_loader': {'dataset_dir': '',
                                                           'shuffle': True,
                                                           'type': 'MindDataset'},
                                           'do_eval': False,
                                           'drop_remainder': True,
                                           'filepath_prefix': './autotune',
                                           'input_columns': ['input_ids'],
                                           'num_parallel_workers': 8,
                                           'numa_enable': False,
                                           'output_columns': ['input_ids'],
                                           'prefetch_size': 1,
                                           'profile': False,
                                           'python_multiprocessing': False,
                                           'repeat': 1,
                                           'seed': 0},
                        'type': 'CausalLanguageModelDataset'},
 'trainer': {'model_name': 'llama3_8b',
             'type': 'CausalLanguageModelingTrainer'},
 'use_parallel': False}

2024-07-05 14:15:25,721 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 40.745837450027466 s; generated tokens: 20 tokens; generate speed: 0.49084768535016376 tokens/s
2024-07-05 14:15:27,236 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5013399124145508 s; generated tokens: 20 tokens; generate speed: 13.32143363046595 tokens/s
2024-07-05 14:15:28,748 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4999446868896484 s; generated tokens: 20 tokens; generate speed: 13.333825023556624 tokens/s
2024-07-05 14:15:30,258 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4972631931304932 s; generated tokens: 20 tokens; generate speed: 13.357704972486363 tokens/s
2024-07-05 14:15:31,776 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5055968761444092 s; generated tokens: 20 tokens; generate speed: 13.283768262867797 tokens/s
2024-07-05 14:15:33,284 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4961488246917725 s; generated tokens: 20 tokens; generate speed: 13.36765411964968 tokens/s
2024-07-05 14:15:34,799 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5028865337371826 s; generated tokens: 20 tokens; generate speed: 13.307724536107594 tokens/s
2024-07-05 14:15:36,311 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499006748199463 s; generated tokens: 20 tokens; generate speed: 13.34216808831786 tokens/s
2024-07-05 14:15:37,827 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5035324096679688 s; generated tokens: 20 tokens; generate speed: 13.302007905780151 tokens/s
2024-07-05 14:15:39,336 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4965832233428955 s; generated tokens: 20 tokens; generate speed: 13.363774020749945 tokens/s
2024-07-05 14:15:40,858 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5095839500427246 s; generated tokens: 20 tokens; generate speed: 13.248683519345814 tokens/s
2024-07-05 14:15:42,380 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5092504024505615 s; generated tokens: 20 tokens; generate speed: 13.25161150696141 tokens/s
2024-07-05 14:15:43,898 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5054354667663574 s; generated tokens: 20 tokens; generate speed: 13.285192518387761 tokens/s
2024-07-05 14:15:45,416 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5054826736450195 s; generated tokens: 20 tokens; generate speed: 13.284775939384764 tokens/s
2024-07-05 14:15:46,928 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.500316858291626 s; generated tokens: 20 tokens; generate speed: 13.33051741001798 tokens/s
2024-07-05 14:15:48,438 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4978342056274414 s; generated tokens: 20 tokens; generate speed: 13.352612675594505 tokens/s
2024-07-05 14:15:49,949 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4980859756469727 s; generated tokens: 20 tokens; generate speed: 13.350368620440944 tokens/s
2024-07-05 14:15:51,460 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4986095428466797 s; generated tokens: 20 tokens; generate speed: 13.345704420118034 tokens/s
2024-07-05 14:15:52,975 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5025875568389893 s; generated tokens: 20 tokens; generate speed: 13.310372436514934 tokens/s
2024-07-05 14:15:54,486 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4978811740875244 s; generated tokens: 20 tokens; generate speed: 13.352193983066481 tokens/s
2024-07-05 14:15:55,995 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4974000453948975 s; generated tokens: 20 tokens; generate speed: 13.35648416834765 tokens/s
2024-07-05 14:15:57,507 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499683141708374 s; generated tokens: 20 tokens; generate speed: 13.336150446564911 tokens/s
2024-07-05 14:15:59,020 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5005526542663574 s; generated tokens: 20 tokens; generate speed: 13.328422660235338 tokens/s
2024-07-05 14:16:00,533 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499650239944458 s; generated tokens: 20 tokens; generate speed: 13.336443036704834 tokens/s
2024-07-05 14:16:02,044 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4988839626312256 s; generated tokens: 20 tokens; generate speed: 13.343261051970208 tokens/s
2024-07-05 14:16:03,558 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5014042854309082 s; generated tokens: 20 tokens; generate speed: 13.320862471269642 tokens/s
2024-07-05 14:16:05,068 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4982373714447021 s; generated tokens: 20 tokens; generate speed: 13.349019575392544 tokens/s
2024-07-05 14:16:06,585 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.504777193069458 s; generated tokens: 20 tokens; generate speed: 13.291004204551918 tokens/s
2024-07-05 14:16:08,097 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499220609664917 s; generated tokens: 20 tokens; generate speed: 13.340264848993836 tokens/s
2024-07-05 14:16:09,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4984455108642578 s; generated tokens: 20 tokens; generate speed: 13.347165349018669 tokens/s
2024-07-05 14:16:11,130 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5087788105010986 s; generated tokens: 20 tokens; generate speed: 13.255753501308492 tokens/s
2024-07-05 14:16:12,651 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5086944103240967 s; generated tokens: 20 tokens; generate speed: 13.25649506164977 tokens/s
2024-07-05 14:16:14,164 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5001659393310547 s; generated tokens: 20 tokens; generate speed: 13.331858480214718 tokens/s
2024-07-05 14:16:15,677 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5001633167266846 s; generated tokens: 20 tokens; generate speed: 13.33188178713732 tokens/s
2024-07-05 14:16:17,193 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.504018783569336 s; generated tokens: 20 tokens; generate speed: 13.29770626436993 tokens/s
2024-07-05 14:16:18,712 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.50606369972229 s; generated tokens: 20 tokens; generate speed: 13.279650790127862 tokens/s
2024-07-05 14:16:20,223 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4993970394134521 s; generated tokens: 20 tokens; generate speed: 13.338695138296247 tokens/s
2024-07-05 14:16:21,735 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4996354579925537 s; generated tokens: 20 tokens; generate speed: 13.33657449442577 tokens/s
2024-07-05 14:16:23,253 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5055451393127441 s; generated tokens: 20 tokens; generate speed: 13.28422474873763 tokens/s
2024-07-05 14:16:24,770 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.504532814025879 s; generated tokens: 20 tokens; generate speed: 13.293163042741046 tokens/s
2024-07-05 14:16:25,725 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9421794414520264 s; generated tokens: 1 tokens; generate speed: 1.0613689452392043 tokens/s
2024-07-05 14:16:27,240 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5035440921783447 s; generated tokens: 20 tokens; generate speed: 13.301904549419543 tokens/s
2024-07-05 14:16:28,760 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5079853534698486 s; generated tokens: 20 tokens; generate speed: 13.262728284449409 tokens/s
2024-07-05 14:16:30,275 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5028712749481201 s; generated tokens: 20 tokens; generate speed: 13.307859650647996 tokens/s
2024-07-05 14:16:31,790 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5024077892303467 s; generated tokens: 20 tokens; generate speed: 13.311965062591694 tokens/s
2024-07-05 14:16:33,309 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5064098834991455 s; generated tokens: 20 tokens; generate speed: 13.276599031296348 tokens/s
2024-07-05 14:16:34,822 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5005533695220947 s; generated tokens: 20 tokens; generate speed: 13.32841630709191 tokens/s
2024-07-05 14:16:36,340 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.506227970123291 s; generated tokens: 20 tokens; generate speed: 13.278202501021752 tokens/s
2024-07-05 14:16:37,862 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5090696811676025 s; generated tokens: 20 tokens; generate speed: 13.253198476908986 tokens/s
2024-07-05 14:16:39,379 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.504870891571045 s; generated tokens: 20 tokens; generate speed: 13.290176660351596 tokens/s
2024-07-05 14:16:40,901 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5094680786132812 s; generated tokens: 20 tokens; generate speed: 13.249700529191454 tokens/s
2024-07-05 14:16:42,411 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4979989528656006 s; generated tokens: 20 tokens; generate speed: 13.351144179200496 tokens/s
2024-07-05 14:16:43,923 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4995379447937012 s; generated tokens: 20 tokens; generate speed: 13.337441756268127 tokens/s
2024-07-05 14:16:45,436 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.500718116760254 s; generated tokens: 20 tokens; generate speed: 13.326953127730572 tokens/s
2024-07-05 14:16:46,954 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5050420761108398 s; generated tokens: 20 tokens; generate speed: 13.288665026350458 tokens/s
2024-07-05 14:16:48,463 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4975879192352295 s; generated tokens: 20 tokens; generate speed: 13.354808584602742 tokens/s
2024-07-05 14:16:49,973 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4979453086853027 s; generated tokens: 20 tokens; generate speed: 13.351622308262604 tokens/s
2024-07-05 14:16:51,494 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.508471965789795 s; generated tokens: 20 tokens; generate speed: 13.258449910621007 tokens/s
2024-07-05 14:16:53,007 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5005686283111572 s; generated tokens: 20 tokens; generate speed: 13.328280774808261 tokens/s
2024-07-05 14:16:54,526 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.507063388824463 s; generated tokens: 20 tokens; generate speed: 13.270841922316464 tokens/s
2024-07-05 14:16:56,043 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.504256248474121 s; generated tokens: 20 tokens; generate speed: 13.295607061820409 tokens/s
2024-07-05 14:16:57,563 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5072808265686035 s; generated tokens: 20 tokens; generate speed: 13.268927493445897 tokens/s
2024-07-05 14:16:59,071 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4964954853057861 s; generated tokens: 20 tokens; generate speed: 13.36455752548649 tokens/s
2024-07-05 14:17:00,587 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.497835397720337 s; generated tokens: 20 tokens; generate speed: 13.352602048555825 tokens/s
2024-07-05 14:17:02,101 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.502472162246704 s; generated tokens: 20 tokens; generate speed: 13.31139471502303 tokens/s
2024-07-05 14:17:03,614 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5006563663482666 s; generated tokens: 20 tokens; generate speed: 13.327501517664889 tokens/s
2024-07-05 14:17:05,130 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5033729076385498 s; generated tokens: 20 tokens; generate speed: 13.303419197180666 tokens/s
2024-07-05 14:17:06,640 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.497676134109497 s; generated tokens: 20 tokens; generate speed: 13.354021970772603 tokens/s
2024-07-05 14:17:08,155 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5026521682739258 s; generated tokens: 20 tokens; generate speed: 13.30980011360427 tokens/s
2024-07-05 14:17:09,667 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5002992153167725 s; generated tokens: 20 tokens; generate speed: 13.330674172069875 tokens/s
2024-07-05 14:17:11,184 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5043001174926758 s; generated tokens: 20 tokens; generate speed: 13.29521932986047 tokens/s
2024-07-05 14:17:12,696 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4999489784240723 s; generated tokens: 20 tokens; generate speed: 13.333786873879593 tokens/s
2024-07-05 14:17:14,215 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5070950984954834 s; generated tokens: 20 tokens; generate speed: 13.27056270036694 tokens/s
2024-07-05 14:17:15,726 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4980568885803223 s; generated tokens: 20 tokens; generate speed: 13.350627838274946 tokens/s
2024-07-05 14:17:17,243 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5050251483917236 s; generated tokens: 20 tokens; generate speed: 13.288814490157913 tokens/s
2024-07-05 14:17:18,775 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5189197063446045 s; generated tokens: 20 tokens; generate speed: 13.167252960415873 tokens/s
2024-07-05 14:17:20,287 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4997532367706299 s; generated tokens: 20 tokens; generate speed: 13.335527145162462 tokens/s
2024-07-05 14:17:21,805 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.505784511566162 s; generated tokens: 20 tokens; generate speed: 13.282112975911843 tokens/s
2024-07-05 14:17:23,344 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.527301549911499 s; generated tokens: 20 tokens; generate speed: 13.094990967015596 tokens/s
2024-07-05 14:17:24,884 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.526353120803833 s; generated tokens: 20 tokens; generate speed: 13.103127793565406 tokens/s
2024-07-05 14:17:26,396 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4993865489959717 s; generated tokens: 20 tokens; generate speed: 13.338788462116405 tokens/s
2024-07-05 14:17:27,916 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5072157382965088 s; generated tokens: 20 tokens; generate speed: 13.269500504688517 tokens/s
2024-07-05 14:17:29,451 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5224223136901855 s; generated tokens: 20 tokens; generate speed: 13.136959318155409 tokens/s
2024-07-05 14:17:30,997 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5344204902648926 s; generated tokens: 20 tokens; generate speed: 13.03423678638919 tokens/s
2024-07-05 14:17:32,511 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5010740756988525 s; generated tokens: 20 tokens; generate speed: 13.32379282527322 tokens/s
2024-07-05 14:17:34,032 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5092284679412842 s; generated tokens: 20 tokens; generate speed: 13.251804100463131 tokens/s
2024-07-05 14:17:35,558 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5135676860809326 s; generated tokens: 20 tokens; generate speed: 13.213812757714075 tokens/s
2024-07-05 14:17:37,070 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4993493556976318 s; generated tokens: 20 tokens; generate speed: 13.33911934800159 tokens/s
2024-07-05 14:17:38,603 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5203466415405273 s; generated tokens: 20 tokens; generate speed: 13.154894715151622 tokens/s
2024-07-05 14:17:40,128 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.512751817703247 s; generated tokens: 20 tokens; generate speed: 13.220939327883427 tokens/s
2024-07-05 14:17:41,647 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5070481300354004 s; generated tokens: 20 tokens; generate speed: 13.270976288945862 tokens/s
2024-07-05 14:17:43,179 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5198731422424316 s; generated tokens: 20 tokens; generate speed: 13.158992973908243 tokens/s
2024-07-05 14:17:44,700 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5084493160247803 s; generated tokens: 20 tokens; generate speed: 13.258648989749316 tokens/s
2024-07-05 14:17:46,212 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4990224838256836 s; generated tokens: 20 tokens; generate speed: 13.342028032133062 tokens/s
2024-07-05 14:17:47,728 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.504321575164795 s; generated tokens: 20 tokens; generate speed: 13.295029686594136 tokens/s
2024-07-05 14:17:49,250 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5088844299316406 s; generated tokens: 20 tokens; generate speed: 13.25482562034661 tokens/s
2024-07-05 14:17:50,763 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.500025749206543 s; generated tokens: 20 tokens; generate speed: 13.333104455426346 tokens/s
2024-07-05 14:17:52,291 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5160150527954102 s; generated tokens: 20 tokens; generate speed: 13.192481145303672 tokens/s
2024-07-05 14:17:53,810 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5061235427856445 s; generated tokens: 20 tokens; generate speed: 13.279123147500293 tokens/s
2024-07-05 14:17:55,328 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.506009578704834 s; generated tokens: 20 tokens; generate speed: 13.28012801698112 tokens/s
2024-07-05 14:17:56,840 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4989204406738281 s; generated tokens: 20 tokens; generate speed: 13.342936327567296 tokens/s
2024-07-05 14:17:58,352 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5004639625549316 s; generated tokens: 20 tokens; generate speed: 13.329210496961739 tokens/s
2024-07-05 14:17:59,873 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5070109367370605 s; generated tokens: 20 tokens; generate speed: 13.271303819004434 tokens/s
2024-07-05 14:18:01,397 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5118279457092285 s; generated tokens: 20 tokens; generate speed: 13.229018590880461 tokens/s
2024-07-05 14:18:02,910 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5006475448608398 s; generated tokens: 20 tokens; generate speed: 13.327579862768287 tokens/s
2024-07-05 14:18:04,478 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5560107231140137 s; generated tokens: 20 tokens; generate speed: 12.853381858432437 tokens/s
2024-07-05 14:18:06,010 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5199570655822754 s; generated tokens: 20 tokens; generate speed: 13.158266409543788 tokens/s
2024-07-05 14:18:07,521 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.498891830444336 s; generated tokens: 20 tokens; generate speed: 13.343191012036632 tokens/s
2024-07-05 14:18:09,036 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5023832321166992 s; generated tokens: 20 tokens; generate speed: 13.31218265250612 tokens/s
2024-07-05 14:18:10,572 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5235109329223633 s; generated tokens: 20 tokens; generate speed: 13.12757235134274 tokens/s
2024-07-05 14:18:12,083 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.498380422592163 s; generated tokens: 20 tokens; generate speed: 13.347745137647 tokens/s
2024-07-05 14:18:13,594 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4990687370300293 s; generated tokens: 20 tokens; generate speed: 13.341616368855913 tokens/s
2024-07-05 14:18:15,121 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5143656730651855 s; generated tokens: 20 tokens; generate speed: 13.206849808949086 tokens/s
2024-07-05 14:18:16,633 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4995312690734863 s; generated tokens: 20 tokens; generate speed: 13.337501132842249 tokens/s
2024-07-05 14:18:18,160 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5155231952667236 s; generated tokens: 20 tokens; generate speed: 13.196762716970564 tokens/s
2024-07-05 14:18:19,675 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5026814937591553 s; generated tokens: 20 tokens; generate speed: 13.309540367045695 tokens/s
2024-07-05 14:18:21,206 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.517765760421753 s; generated tokens: 20 tokens; generate speed: 13.177263924073799 tokens/s
2024-07-05 14:18:22,740 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.521892786026001 s; generated tokens: 20 tokens; generate speed: 13.141530194268434 tokens/s
2024-07-05 14:18:24,258 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5054593086242676 s; generated tokens: 20 tokens; generate speed: 13.284982121686557 tokens/s
2024-07-05 14:18:25,788 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5179901123046875 s; generated tokens: 20 tokens; generate speed: 13.175316385714142 tokens/s
2024-07-05 14:18:27,322 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5215160846710205 s; generated tokens: 20 tokens; generate speed: 13.144783812340942 tokens/s
2024-07-05 14:18:28,832 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4980790615081787 s; generated tokens: 20 tokens; generate speed: 13.350430236882936 tokens/s
2024-07-05 14:18:30,363 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.51826810836792 s; generated tokens: 20 tokens; generate speed: 13.172903975108346 tokens/s
2024-07-05 14:18:31,879 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.503112554550171 s; generated tokens: 20 tokens; generate speed: 13.305723473240034 tokens/s
2024-07-05 14:18:33,395 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.503878116607666 s; generated tokens: 20 tokens; generate speed: 13.29895008055206 tokens/s
2024-07-05 14:18:34,934 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.52683424949646 s; generated tokens: 20 tokens; generate speed: 13.098998798720864 tokens/s
2024-07-05 14:18:36,446 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4993131160736084 s; generated tokens: 20 tokens; generate speed: 13.339441765423805 tokens/s
2024-07-05 14:18:37,957 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4989418983459473 s; generated tokens: 20 tokens; generate speed: 13.34274532059555 tokens/s
2024-07-05 14:18:39,471 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.501884937286377 s; generated tokens: 20 tokens; generate speed: 13.316599363554595 tokens/s
2024-07-05 14:18:40,983 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4990339279174805 s; generated tokens: 20 tokens; generate speed: 13.341926174936429 tokens/s
2024-07-05 14:18:42,496 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5004634857177734 s; generated tokens: 20 tokens; generate speed: 13.329214732894778 tokens/s
2024-07-05 14:18:44,005 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4962937831878662 s; generated tokens: 20 tokens; generate speed: 13.366359083167367 tokens/s
2024-07-05 14:18:45,516 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4976837635040283 s; generated tokens: 20 tokens; generate speed: 13.353953943659887 tokens/s
2024-07-05 14:18:47,033 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5044748783111572 s; generated tokens: 20 tokens; generate speed: 13.293674948199152 tokens/s
2024-07-05 14:18:48,544 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4991493225097656 s; generated tokens: 20 tokens; generate speed: 13.340899201766952 tokens/s
2024-07-05 14:18:50,056 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.498908519744873 s; generated tokens: 20 tokens; generate speed: 13.34304244491463 tokens/s
2024-07-05 14:18:51,576 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5074636936187744 s; generated tokens: 20 tokens; generate speed: 13.267317869519344 tokens/s
2024-07-05 14:18:53,094 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5057754516601562 s; generated tokens: 20 tokens; generate speed: 13.28219289134345 tokens/s
2024-07-05 14:18:54,606 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499748706817627 s; generated tokens: 20 tokens; generate speed: 13.335567424784616 tokens/s
2024-07-05 14:18:56,120 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5014095306396484 s; generated tokens: 20 tokens; generate speed: 13.320815934530108 tokens/s
2024-07-05 14:18:57,633 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4996140003204346 s; generated tokens: 20 tokens; generate speed: 13.336765324761197 tokens/s
2024-07-05 14:18:59,170 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5251319408416748 s; generated tokens: 20 tokens; generate speed: 13.11361952655886 tokens/s
2024-07-05 14:19:00,686 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5040478706359863 s; generated tokens: 20 tokens; generate speed: 13.297449097509778 tokens/s
2024-07-05 14:19:02,201 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5026378631591797 s; generated tokens: 20 tokens; generate speed: 13.309926822921625 tokens/s
2024-07-05 14:19:03,737 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5221199989318848 s; generated tokens: 20 tokens; generate speed: 13.139568505790985 tokens/s
2024-07-05 14:19:05,249 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4992196559906006 s; generated tokens: 20 tokens; generate speed: 13.340273334920438 tokens/s
2024-07-05 14:19:06,757 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4966845512390137 s; generated tokens: 20 tokens; generate speed: 13.36286927224793 tokens/s
2024-07-05 14:19:08,293 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5233452320098877 s; generated tokens: 20 tokens; generate speed: 13.129000294708103 tokens/s
2024-07-05 14:19:09,825 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5202689170837402 s; generated tokens: 20 tokens; generate speed: 13.155567265273733 tokens/s
2024-07-05 14:19:11,337 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499241590499878 s; generated tokens: 20 tokens; generate speed: 13.340078161339955 tokens/s
2024-07-05 14:19:12,874 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5246341228485107 s; generated tokens: 20 tokens; generate speed: 13.11790133795085 tokens/s
2024-07-05 14:19:14,414 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5273549556732178 s; generated tokens: 20 tokens; generate speed: 13.094533085260805 tokens/s
2024-07-05 14:19:15,933 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.506730556488037 s; generated tokens: 20 tokens; generate speed: 13.273773412160034 tokens/s
2024-07-05 14:19:17,464 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5181896686553955 s; generated tokens: 20 tokens; generate speed: 13.173584574391986 tokens/s
2024-07-05 14:19:19,003 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5268640518188477 s; generated tokens: 20 tokens; generate speed: 13.098743123970587 tokens/s
2024-07-05 14:19:20,514 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4987611770629883 s; generated tokens: 20 tokens; generate speed: 13.344354194704005 tokens/s
2024-07-05 14:19:22,025 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4991567134857178 s; generated tokens: 20 tokens; generate speed: 13.340833429947173 tokens/s
2024-07-05 14:19:23,541 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5035934448242188 s; generated tokens: 20 tokens; generate speed: 13.301467939252786 tokens/s
2024-07-05 14:19:25,077 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5231800079345703 s; generated tokens: 20 tokens; generate speed: 13.130424438225111 tokens/s
2024-07-05 14:19:26,591 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5017061233520508 s; generated tokens: 20 tokens; generate speed: 13.318185022350956 tokens/s
2024-07-05 14:19:28,110 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5069947242736816 s; generated tokens: 20 tokens; generate speed: 13.271446593576693 tokens/s
2024-07-05 14:19:29,634 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5121853351593018 s; generated tokens: 20 tokens; generate speed: 13.225892048406283 tokens/s
2024-07-05 14:19:31,171 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.524245262145996 s; generated tokens: 20 tokens; generate speed: 13.121247936071557 tokens/s
2024-07-05 14:19:32,682 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.499000072479248 s; generated tokens: 20 tokens; generate speed: 13.342227506981576 tokens/s
2024-07-05 14:19:34,221 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5266292095184326 s; generated tokens: 20 tokens; generate speed: 13.100758111597314 tokens/s
2024-07-05 14:19:35,730 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4966809749603271 s; generated tokens: 20 tokens; generate speed: 13.362901202462432 tokens/s
2024-07-05 14:19:37,250 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5077369213104248 s; generated tokens: 20 tokens; generate speed: 13.264913604833215 tokens/s
2024-07-05 14:19:38,771 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5088107585906982 s; generated tokens: 20 tokens; generate speed: 13.255472819322259 tokens/s
2024-07-05 14:19:40,296 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5122020244598389 s; generated tokens: 20 tokens; generate speed: 13.225746081872913 tokens/s
2024-07-05 14:19:41,810 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.501387596130371 s; generated tokens: 20 tokens; generate speed: 13.321010544876865 tokens/s
2024-07-05 14:19:43,330 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5080821514129639 s; generated tokens: 20 tokens; generate speed: 13.261877001369884 tokens/s
2024-07-05 14:19:44,840 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4971425533294678 s; generated tokens: 20 tokens; generate speed: 13.35878133683554 tokens/s
2024-07-05 14:19:46,356 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5029122829437256 s; generated tokens: 20 tokens; generate speed: 13.307496536541962 tokens/s
2024-07-05 14:19:47,864 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.496483325958252 s; generated tokens: 20 tokens; generate speed: 13.364666116271815 tokens/s
2024-07-05 14:19:49,388 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5111639499664307 s; generated tokens: 20 tokens; generate speed: 13.234831336761497 tokens/s
2024-07-05 14:19:50,904 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5038208961486816 s; generated tokens: 20 tokens; generate speed: 13.29945610625603 tokens/s
2024-07-05 14:19:52,417 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5004980564117432 s; generated tokens: 20 tokens; generate speed: 13.328907634727328 tokens/s
2024-07-05 14:19:53,938 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.508134365081787 s; generated tokens: 20 tokens; generate speed: 13.261417857098818 tokens/s
2024-07-05 14:19:55,449 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4984586238861084 s; generated tokens: 20 tokens; generate speed: 13.347048547881771 tokens/s
2024-07-05 14:19:56,969 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5078353881835938 s; generated tokens: 20 tokens; generate speed: 13.264047360032382 tokens/s
2024-07-05 14:19:58,509 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5265700817108154 s; generated tokens: 20 tokens; generate speed: 13.101265536126682 tokens/s
2024-07-05 14:20:00,020 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4990170001983643 s; generated tokens: 20 tokens; generate speed: 13.342076839257599 tokens/s
2024-07-05 14:20:01,543 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5109281539916992 s; generated tokens: 20 tokens; generate speed: 13.236896769156289 tokens/s
2024-07-05 14:20:03,091 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5359444618225098 s; generated tokens: 20 tokens; generate speed: 13.021304153321108 tokens/s
2024-07-05 14:20:04,609 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5048742294311523 s; generated tokens: 20 tokens; generate speed: 13.290147182306438 tokens/s
2024-07-05 14:20:06,118 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4967384338378906 s; generated tokens: 20 tokens; generate speed: 13.3623882088179 tokens/s
2024-07-05 14:20:07,646 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5158073902130127 s; generated tokens: 20 tokens; generate speed: 13.194288488849134 tokens/s
2024-07-05 14:20:09,156 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4974102973937988 s; generated tokens: 20 tokens; generate speed: 13.356392723363427 tokens/s
2024-07-05 14:20:10,678 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5094213485717773 s; generated tokens: 20 tokens; generate speed: 13.250110725493652 tokens/s
2024-07-05 14:20:12,212 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5220744609832764 s; generated tokens: 20 tokens; generate speed: 13.139961619932699 tokens/s
2024-07-05 14:20:13,722 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.4969635009765625 s; generated tokens: 20 tokens; generate speed: 13.360379185566485 tokens/s
2024-07-05 14:20:14,702 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 0.9679820537567139 s; generated tokens: 1 tokens; generate speed: 1.0330770039785606 tokens/s
2024-07-05 14:20:16,222 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5083515644073486 s; generated tokens: 20 tokens; generate speed: 13.259508241938454 tokens/s
2024-07-05 14:20:17,788 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5540449619293213 s; generated tokens: 20 tokens; generate speed: 12.86964051231203 tokens/s
2024-07-05 14:20:19,323 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5222387313842773 s; generated tokens: 20 tokens; generate speed: 13.138543638166801 tokens/s
2024-07-05 14:20:20,860 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5250000953674316 s; generated tokens: 20 tokens; generate speed: 13.114753278216172 tokens/s
2024-07-05 14:20:22,406 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5332205295562744 s; generated tokens: 20 tokens; generate speed: 13.04443790991251 tokens/s
2024-07-05 14:20:23,933 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5154452323913574 s; generated tokens: 20 tokens; generate speed: 13.197441631354899 tokens/s
2024-07-05 14:20:25,466 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.5199666023254395 s; generated tokens: 20 tokens; generate speed: 13.158183850488188 tokens/s
2024-07-05 14:20:26,992 - mindformers[mindformers/generation/text_generator.py:890] - INFO - total time: 1.51422119140625 s; generated tokens: 20 tokens; generate speed: 13.208109960095127 tokens/s
2024-07-05 14:20:27,002 - mindformers[mindformers/trainer/base_trainer.py:951] - INFO - output result is: [{'text_generation_text': [' -7451.51 - -1709.92  1. -7451.51 - -1709.92 = -7451.51']}, {'text_generation_text': [' -1337.47 + 5068.04  2.  1.5 + 2.5 + 3.5']}, {'text_generation_text': [' -6211.70 * -6871.61  6211.70 * 6871.61 = 42600000.000000000']}, {'text_generation_text': [' -3985.41 - -8173.86  1. -8173.86 2. -3985.41 3. -']}, {'text_generation_text': [' 1075.16 - 8090.56  1075.16 - 8090.56 = 1075.16 - 809']}, {'text_generation_text': [' -9299.25 * 1012.66  2. 1012.66 * 9299.25  3']}, {'text_generation_text': [' -2864.35 - -8690.01  2864.35 - 8690.01 = -5825.66\n    -']}, {'text_generation_text': [' 7310.69 + -6470.86  7310.69 + -6470.86 = 840.83 7310.']}, {'text_generation_text': [' -3476.06 + 2490.05  3476.06 - 2490.05 = 986.01\n    - ']}, {'text_generation_text': [' 19  71  2.  3 ']}, {'text_generation_text': [' 1647.72 * -2175.26  1647.72 * -2175.26 = -3575.999999999999']}, {'text_generation_text': [' -13x + 10 = 0\n    - 2.2.1.1.1.1.1.1.']}, {'text_generation_text': [' -1980.46 - -4548.03  2. 2.5 + 3.5 - 1.5 = ? ']}, {'text_generation_text': [' -9349.89 + 8736.20  2. 2.5 + 3.5 - 1.5 = ? ']}, {'text_generation_text': [' -7881.79 + -3132.78  7881.79 + 3132.78 = 11014.57\n    -']}, {'text_generation_text': [' 7374.53 * -4084.42  7374.53 * -4084.42 = -302500.00\n    -']}, {'text_generation_text': [' 6811.55 - 2494.54  6811.55 - 2494.54 = 4317.01\n ']}, {'text_generation_text': [' 6974.95  6974.95  6974.95 ']}, {'text_generation_text': [' -3957.83 - 3083.39  3957.83 - 3083.39 = 874.44\n    - ']}, {'text_generation_text': [' 8230.71 - 2598.23  8230.71 - 2598.23 = 5632.48 8230']}, {'text_generation_text': [' 53x + 27 = 0\nx = -3, 9\nx = -3, 9\nx = -']}, {'text_generation_text': [' 2670.86 / 8327.57  2.  0.000000000000000000000000000000000']}, {'text_generation_text': [' -1295.35 + 7059.64  7059.64 - (-1295.35) = 7059.64 + ']}, {'text_generation_text': [' 5113.34 - 239.46  5113.34 - 239.46 = 4873.88\n 511']}, {'text_generation_text': [' 4157.45  4157.45  4157.45 ']}, {'text_generation_text': [' -8141.51 - -9883.79  2.  -8141.51 - -9883.79 ']}, {'text_generation_text': [' 3619.12 + -4630.69  3619.12 + -4630.69 = -1011.57 3619']}, {'text_generation_text': [' 50  42  2.  3 ']}, {'text_generation_text': [' -337.33  2  2. 2  2  3. 2  ']}, {'text_generation_text': [' 56  20  2.  3cm']}, {'text_generation_text': [' -5x + -100 = 0\n    - 5x = 100\n    - x = 20\n    - x']}, {'text_generation_text': [' 8115.42 / -8891.52  8115.42 / -8891.52 = -0.91 8115.']}, {'text_generation_text': [' 4670.73 + 5116.49  4670.73 + 5116.49 = 9787.22 4670']}, {'text_generation_text': [' 2921.61 - -426.91  1. 2494.7 2. 2494.7 3. ']}, {'text_generation_text': [' 47  12  2.  3cm']}, {'text_generation_text': [' 4023.23 + -4657.63  4023.23 + -4657.63 = -630.4 4023.']}, {'text_generation_text': [' 6365.40  6365.40  6365.40 ']}, {'text_generation_text': [' -6402.63 + 9129.29  9129.29 - 6402.63 = 2726.66 2.']}, {'text_generation_text': [' 8049.63  8049.63  8049.63 ']}, {'text_generation_text': [' 8874.39 / -5271.14  8874.39 / -5271.14 = -1.68 8874.']}, {'text_generation_text': [' -721.97  1 ']}, {'text_generation_text': [' -33x + 79 = 0\n    - 33x = 79\n    - x = 79/33\n   ']}, {'text_generation_text': [' 5396.67 + -7513.38  5396.67 + -7513.38 = -2116.71\n ']}, {'text_generation_text': [' -5555.48 - 2227.05  2.  0.000000000000000000000000000000000']}, {'text_generation_text': [' 3585.58 * -7185.14  3585.58 * -7185.14 = -25799999.92\n']}, {'text_generation_text': [' 8326.91 + 8323.56  8326.91 + 8323.56 = 16650.47 8326']}, {'text_generation_text': [' 6412.43 + 8195.96  6412.43 + 8195.96 = 14608.39 6412']}, {'text_generation_text': [' 48  7  2.  1.5  0.5  3']}, {'text_generation_text': [' -2068.77 + -1347.07  2068.77 + 1347.07 = 3415.84\n    -']}, {'text_generation_text': [' x = 0.64  y = 93x^80 \n(1) 0.000000000000000000000000000000000000000']}, {'text_generation_text': [' -44x + 70 = 0\n    x = 70/44 = 1.59\n    y = 1.']}, {'text_generation_text': [' -5351.95 + -9780.91  5351.95 + 9780.91 = 15132.86\n    -']}, {'text_generation_text': [' 6585.23 * -469.39  6585.23 * -469.39 = -3095.0003\n ']}, {'text_generation_text': [' 5591.19 / -7097.76  5591.19 / -7097.76 = -0.789\n 559']}, {'text_generation_text': [' 2910.65 * -4198.96  2910.65 * -4198.96 = -12200.000000000001']}, {'text_generation_text': [' -5861.56 - -6927.43  1. -6927.43 2. -5861.56 3. -']}, {'text_generation_text': [' -5452.84 / -2723.07  2. 2.5 + 3.5 - 1.5 = ? ']}, {'text_generation_text': [' 8508.06 / 4921.11  8508.06 / 4921.11 = 1.732\n 850']}, {'text_generation_text': [' -3859.13 + 8440.41  8440.41 -3859.13 = 4581.28\n    - ']}, {'text_generation_text': [' -6983.88 - -8060.14  1. -6983.88 - -8060.14 = -6983.88']}, {'text_generation_text': ['[17, 99, 52]\n    """\n    # \n']}, {'text_generation_text': [' 680.12  3  680.12  3  2.345e+8 680']}, {'text_generation_text': [' -97x + -92 = 0\n    - 97x + 92 = 0\n    - 97x = -']}, {'text_generation_text': [' 123.84  1  123.84  1  152, 839. 36 123']}, {'text_generation_text': [' 5708.06  2.  5708.06  3. ']}, {'text_generation_text': [' -7194.48 * -6220.64  1. 4.46e+12 2. 4.46e+11']}, {'text_generation_text': [' 8830.69 * -1065.17  8830.69 * -1065.17 = -9400.0003\n']}, {'text_generation_text': [' 1855.82 - 1345.12  1855.82 - 1345.12 = 510.7 510.7']}, {'text_generation_text': [' 8.74 * -9037.79  8.74 * -9037.79 = -79032.5 8.74']}, {'text_generation_text': [' -3321.89 * -3531.67  2. 2.5 * 3.5 = ? 3. 2.']}, {'text_generation_text': [' 3460.04 - -315.20  1. 3144.84 2. 3144.84 3. ']}, {'text_generation_text': [' 6185.13 - 2193.41  6185.13 - 2193.41 = 3991.72\n    -']}, {'text_generation_text': [' -5208.71 / 3443.94  2. 3443.94 - 5208.71  3']}, {'text_generation_text': [' 1432.15 + -7448.73  1432.15 + -7448.73 = -6016.58 1432']}, {'text_generation_text': [' -7375.26 * -8346.62  7375.26 * 8346.62 = 61600000.000000000']}, {'text_generation_text': [' -1552.54 / 6004.21  2. 6004.21 - 1552.54  3']}, {'text_generation_text': [' -2508.22 / -8899.74  2. 2.5 + 2.5 + 2.5 + 2']}, {'text_generation_text': [' -3459.21 * 4229.30  3459.21 * 4229.30 = -14600000.00\n   ']}, {'text_generation_text': ['[71, 54, 62, 70, 53]\n    """\n    # \n']}, {'text_generation_text': [' -368.19  4  2019-05-08\n#  2 2  4']}, {'text_generation_text': [' -9245.32 * 2915.01  9245.32 * 2915.01 = 26929647.32 924']}, {'text_generation_text': [' 3362.63 * 7545.83  3362.63 * 7545.83 = 254, 1 5 ']}, {'text_generation_text': [' -514.60 / 293.74  2. 2.510^3 - 2.510^2']}, {'text_generation_text': [' -80x + 94 = 0\n    - 80x = 94\n    - x = 94/80\n   ']}, {'text_generation_text': [' -3279.11 - 7172.93  2.  0.000000000000000000000000000000000']}, {'text_generation_text': [' -9247.11 - 7331.30  9247.11 - 7331.30 = 1915.81\n    -']}, {'text_generation_text': [' -1738.37 + 4806.48  4806.48 - 1738.37 = 3068.11 4806']}, {'text_generation_text': [' 10.63  2  10.63  2  1.0000000000000002']}, {'text_generation_text': [' -7735.89 + 3030.00  2. 2.5 + 3.5 - 1.5 = ? ']}, {'text_generation_text': [' -1058.80 * -607.50  1. 645,000.00 2. 645,000.00 3']}, {'text_generation_text': [' -430.88 - 1101.44  1. -1531.32 2. -1531.32 3. -']}, {'text_generation_text': [' -1923.64 - 8110.60  8110.60 - 1923.64 = 6186.96\n    -']}, {'text_generation_text': [' 282.03  282.03  282.03 ']}, {'text_generation_text': [' -3124.14 / 1192.09  1. 2. 3. 4. 5. 6. 7']}, {'text_generation_text': [' 2666.20 * 110.52  2666.20 * 110.52 = 294, 201.84\n2']}, {'text_generation_text': [' x = 4.77  y = 86x^97 \n2.  Python  1! + ']}, {'text_generation_text': [' -7781.42 / -5327.71  1.45 2.45 3.45 4.45 5.45']}, {'text_generation_text': ['[27, 89, 99, 64, 76, 50, 100, 49]\n# 2.[']}, {'text_generation_text': [' -4294.20 + 9857.73  9857.73 - 4294.20 = 5563.53 2.']}, {'text_generation_text': [' -1214.14 - 1182.21  1. 32.93 2. 32.93 3. 32.']}, {'text_generation_text': [' 475.47  5  2021-01-25\n### 2.1.2.2.2.']}, {'text_generation_text': [' 5078.04 - 8883.67  8883.67 - 5078.04  8883.67']}, {'text_generation_text': [' -2023.47 - 1907.67  2023.47 - 1907.67 = 315.8\n    - ']}, {'text_generation_text': [' 2x + 60 = 0\nx = -30\nx = -30\nx = -30\nx = -30']}, {'text_generation_text': [' 5415.08 / 8305.15  5415.08 / 8305.15 = 0.652\n 541']}, {'text_generation_text': [' 2356.30 + 9645.15  2356.30 + 9645.15 = 12001.45\n    -']}, {'text_generation_text': [' 676.46  2  676.46  2  459, 201. 676.46']}, {'text_generation_text': [' 7076.54 / -2319.93  7076.54 / -2319.93 = -3.05\n 707']}, {'text_generation_text': [' -101.17 * -8210.19  101.17 * 8210.19  101.17 * -']}, {'text_generation_text': [' -67x + -29 = 0\n    - 67x + 29 = 0\n    - 67x = -']}, {'text_generation_text': [' 4415.70 - -2186.85  4415.70 - -2186.85 = 6600.85 4415']}, {'text_generation_text': [' -513.32  3  -513.32  3  -513.32  3 ']}, {'text_generation_text': [' 3180.61 - -7868.88  3180.61 - -7868.88 = -4688.27\n ']}, {'text_generation_text': [' 7157.98 + -8238.21  7157.98 + -8238.21 = -1078.23 7157']}, {'text_generation_text': [' 359.19 * -7366.84  359.19 * -7366.84 = -264. 1 1 1']}, {'text_generation_text': [' -809.94  2  -809.94  2  -654, 201. 16 -']}, {'text_generation_text': [' -5049.65 / 9032.66  2. 1. 2. 3. 4. 5. 6']}, {'text_generation_text': [' 126.99  1  126.99  1  161.99 126.99  ']}, {'text_generation_text': [' 28  82% 2. 2015  30 2016']}, {'text_generation_text': [' 60  21  2.  60  ']}, {'text_generation_text': [' -7648.20 / -1462.33  2. 2.5 + 3.5 - 1.5 = ? ']}, {'text_generation_text': [' 5486.28 + -8198.83  5486.28 + -8198.83 = -2712.55 5486']}, {'text_generation_text': [' 9628.09 - -9285.90  9628.09 - -9285.90 = 343.19 9628.']}, {'text_generation_text': [' x = 1.53  y = 15x^63 \n(1) 1.53^63\n(2) 15(1.53']}, {'text_generation_text': [' 9096.92 + -4287.79  9096.92 + -4287.79 = 4810.13 9096']}, {'text_generation_text': [' 7872.21 / -5143.52  7872.21 / -5143.52 = -1.53 7872.']}, {'text_generation_text': [' -8408.81 + 5175.48  2.  0.5 + 0.5 + 0.5']}, {'text_generation_text': [' 6960.49 + -2479.37  6960.49 + -2479.37 = 3481.12 6960']}, {'text_generation_text': [' -7114.90 / 5453.99  5453.99 -7114.90 = -1656.91 5453.']}, {'text_generation_text': [' 3069.64 + -4540.58  3069.64 + -4540.58 = -1470.94\n ']}, {'text_generation_text': ['[36, 23, 33, 56, 55, 72, 44]\n# \n# ']}, {'text_generation_text': [' 30  44  2.  20  ']}, {'text_generation_text': [' 7284.02 + -2762.62  7284.02 + -2762.62 = 4521.4 7284']}, {'text_generation_text': [' 18  34  2.  12  ']}, {'text_generation_text': ['[26, 41, 56, 79, 81, 5, 76]\n\n\n# 1.1.1.1.1.1.1.1.']}, {'text_generation_text': [' -6642.70 + 2293.71  2. 2.5 + 3.5 - 1.5 = ? ']}, {'text_generation_text': [' -2836.04 + -6589.37  2.  -2836.04 + -6589.37 ']}, {'text_generation_text': [' -2782.13 / 72.66  2782.13 / 72.66 = 38.2\n    - 2']}, {'text_generation_text': [' 3140.68 + 6112.77  3140.68 + 6112.77 = 9253.45\n    -']}, {'text_generation_text': [' 9 / 1  A. 9  B. 9  C. 9  D. 9 ']}, {'text_generation_text': [' -700.22 / -8699.15  2. 1.5 + 2.5 + 3.5 + 4']}, {'text_generation_text': [' -35x + 80 = 0\nx = 80/35 = 2.29\nx = 2.29\n']}, {'text_generation_text': [' -413.93 * -3531.49  2. 0.5 * 0.5 * 0.5 * 0']}, {'text_generation_text': [' 941.34  2  2  2  4  4  2  ']}, {'text_generation_text': [' -4845.92 * -9135.70  4845.92 * 9135.70 = 44399999.96 484']}, {'text_generation_text': [' 168.34  2  168.34  2  284.99\n 168.34']}, {'text_generation_text': [' 8109.51 - 4209.08  8109.51 - 4209.08 = 3900.43 8109']}, {'text_generation_text': [' -1163.03 - -9231.14  1. -9231.14 - -1163.03 = -9231.14']}, {'text_generation_text': [' 7722.38 - 4159.92  7722.38 - 4159.92 = 3562.46\n ']}, {'text_generation_text': [' 3815.76 / -6281.84  3815.76 / -6281.84 = -0.608\n 381']}, {'text_generation_text': [' 9927.99 - -4181.96  9927.99 - -4181.96 = 5746.03\n ']}, {'text_generation_text': [' 5807.61  2.  5807.61  3. ']}, {'text_generation_text': [' 4715.32 * -5259.47  4715.32 * -5259.47 = -2483508.96\n']}, {'text_generation_text': [' 5651.40 - -4831.27  5651.40 - -4831.27 = 5651.40 + 483']}, {'text_generation_text': [' -9194.16 + -5958.91  2.  0.000000000000000000000000000000000']}, {'text_generation_text': [' 45.65 / 4297.83  45.65 / 4297.83 = 0.0106 45.65']}, {'text_generation_text': [' 9237.51  2.  9237.51  3. ']}, {'text_generation_text': [' -4701.55 * 8769.06  2. 1. 2. 3. 4. 5. 6']}, {'text_generation_text': [' 11x + 64 = 0\n11x = -64\nx = -64/11\nx = -64/11']}, {'text_generation_text': [' 5851.95 * 2017.43  5851.95 * 2017.43 = 11799999.15 2']}, {'text_generation_text': [' 4342.43 + 8332.32  4342.43 + 8332.32 = 12674.75\n    -']}, {'text_generation_text': [' -28x + 91 = 0\n    - 28x = 91\n    - x = 91/28\n   ']}, {'text_generation_text': [' 734.05  734.05  734.05 ']}, {'text_generation_text': [' -9576.85 / -7526.45  1. 1.265 2. 1.265 3. 1.']}, {'text_generation_text': [' 3286.03 * -8033.87  3286.03 * -8033.87 = -26400000.00\n']}, {'text_generation_text': [' -5462.74 + -8565.38  1. 14023.12 2. 14023.12 3. ']}, {'text_generation_text': [' 4129.11 - -6919.07  4129.11 - -6919.07 = -2790.00 4129']}, {'text_generation_text': [' 1437.03 + 2879.42  1437.03 + 2879.42 = 4316.45 1437']}, {'text_generation_text': [' 3906.35 * 2271.03  3906.35 * 2271.03 = 888, 888. 888']}, {'text_generation_text': [' 6911.95 - 5700.39  6911.95 - 5700.39 = 1211.56 6911']}, {'text_generation_text': [' 1908.46 + -4882.32  1908.46 + -4882.32 = 679.14 1908.']}, {'text_generation_text': [' 3899.33 - 1603.27  3899.33 - 1603.27 = 2296.06\n ']}, {'text_generation_text': [' 4917.70 - -3484.94  4917.70 - -3484.94 = 14032.64 4917']}, {'text_generation_text': [' -570.03 + 2854.20  2.  0.000000000000000000000000000000000']}, {'text_generation_text': [' 9386.28 / 2862.76  9386.28 / 2862.76 = 3.28 3.28']}, {'text_generation_text': ['[29, 21, 47]\n\n\n```python\n# 1. \na = [29,']}, {'text_generation_text': [' 3190.15  2.  3190.15  3. ']}, {'text_generation_text': [' 2998.34 * 3471.30  2998.34 * 3471.30 = 1040000.00 299']}, {'text_generation_text': [' -617.68 * -3365.23  617.68 * 3365.23 = 2080.00 617.68']}, {'text_generation_text': [' 2012.37 / 1480.07  2012.37 / 1480.07 = 0.1356 2012']}, {'text_generation_text': [' -453.61 - 8996.39  1. -4540.00 2. -4540.01 3. -']}, {'text_generation_text': [' -8621.88 / 5012.04  1.72 2.72 3.72 4.72 5.72']}, {'text_generation_text': [' 31x + 79 = 0\nx = -79/31 = -2.516\nx = 79/31 =']}, {'text_generation_text': [' 5401.27 + 3750.03  5401.27 + 3750.03 = 9151.30\n    -']}, {'text_generation_text': [' 3743.44 + 2044.79  3743.44 + 2044.79 = 5788.23 3743']}, {'text_generation_text': [' 561.81  3  3  561.81  3  = ']}, {'text_generation_text': [' 1  84  2.  3 ']}, {'text_generation_text': [' 7132.91 * -2496.53  7132.91 * -2496.53 = -17800000.68\n   ']}, {'text_generation_text': [' 5181.89 * 1825.05  5181.89 * 1825.05 = 9474.00\n    -']}, {'text_generation_text': ['[12, 28, 21, 86, 56, 96]forwhile\n# 2.for']}, {'text_generation_text': [' 263.65  3  263.65  3  1.8E+7 263']}, {'text_generation_text': [' -871.47  4 ']}, {'text_generation_text': [' 538.10 / 4758.54  538.10 / 4758.54 = 0.1127 538.10']}, {'text_generation_text': [' -3288.38 - 5111.78  5111.78 - 3288.38 = 1823.4 5111']}, {'text_generation_text': [' -979.16  5  5  5  5  = 5 ']}, {'text_generation_text': [' 264.95  264.95  264.95 ']}, {'text_generation_text': [' 7233.93 * 5750.17  7233.93 * 5750.17 = 41600000.000000000']}, {'text_generation_text': [' 4363.54 + 8053.97  4363.54 + 8053.97 = 12317.51\n    -']}, {'text_generation_text': [' 6571.23  2.  6571.23  3. ']}, {'text_generation_text': [' 7728.88 * 7531.07  7728.88 * 7531.07 = 58300000.000000000']}]
2024-07-05 14:20:27,003 - mindformers[mindformers/trainer/base_trainer.py:952] - INFO - output result is saved at: text_generation_result.txt
2024-07-05 14:20:27,003 - mindformers[mindformers/trainer/base_trainer.py:953] - INFO - .........Predict Over!.............
