# LLaMA2-7b æ¨ç†è°ƒä¼˜

----

### èµ„æºææ–™ä¸‹è½½

â­å®éªŒæ‰‹å†Œâ­: [2024æ˜‡è…¾AIå¤§èµ›MindSporeèµ›é“å®éªŒæŒ‡å¯¼æ‰‹å†Œ.pdf](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/2024æ˜‡è…¾AIå¤§èµ›MindSporeèµ›é“å®éªŒæŒ‡å¯¼æ‰‹å†Œ.pdf)  

âš  **ä»¥ä¸‹èµ„æºé“¾æ¥ä»…ä¾›å‚è€ƒå¼•ç”¨ï¼Œä¸è¦æ‰‹åŠ¨ä¸‹è½½**ï¼Œåé¢ [å®éªŒæ“ä½œ](#å®éªŒæ“ä½œç¯å¢ƒæ„å»º--æµ‹è¯•æµç¨‹) ç« èŠ‚ä¼šå‘Šè¯‰ä½ å¦‚ä½•ç”¨è„šæœ¬è‡ªåŠ¨åŒ–ä¸‹è½½ï¼ï¼

- LLaMA2-7b
  - checkpoint: [llama2_7b.ckpt](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic3-infer/llama2_7b.ckpt)
  - tokenizer: [tokenizer.model](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic3-infer/tokenizer.model)
- frameworks
  - runtime: [mindspore](https://gitee.com/mindspore/mindspore), (contest: [mindspore-2.3.0rc2-cp39-cp39-linux_aarch64.whl](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic2-finetune/mindspore-2.3.0rc2-cp39-cp39-linux_aarch64.whl), **NOT for x86_64**)
  - application: [mindformers](https://gitee.com/mindspore/mindformers), (contest: [mindformers.zip](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic3-infer/mindformers.zip))
  - deploy: [LLM-serving](https://gitee.com/mindspore/llm-serving), (contest: [llm-serving.zip](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic3-infer/llm-serving.zip))
- judger code: [performance_serving.zip](https://2024-ascend-innovation-contest-mindspore.obs.cn-southwest-2.myhuaweicloud.com/topic3-infer/performance_serving.zip)

#### è½¯ä»¶æ¶æ„æ¦‚è§ˆ

âš  æœ€ç»ˆè¯„æµ‹åœ¨ Ascend910b4 è®¾å¤‡ä¸Šï¼Œå…¶æŒ‡ä»¤é›†æ¶æ„ä¸º aarch64

```txt
å„èµ„æºçš„å±‚æ¬¡ä¾èµ–å…³ç³»ï¼š
|           performance_serving                |
|==============================================|  <- http
|                      server_app_post (http)  |
|  llm-serving  ===============================|  <- tcp + shared_mem
|                          agent (tcp)         |
|----------------------------------------------|
|               mindformers                    |
|----------------------------------------------|
| mindspore | llama2_7b.ckpt & tokenizer.model |

æœåŠ¡ç«¯: llm-serving ä¼šå¯åŠ¨ä¸¤ä¸ªå­æœåŠ¡ï¼Œå…¶é—´é€šè¿‡å…±äº«å†…å­˜å®ç°æ•°æ®ä¼ é€’
  - server_app_post (http): request -> llm_server -> request_engine (queue) -> worker -[tcp]-> agent
  - agent (tcp): shared_mem data -> mindformer model
å®¢æˆ·ç«¯: performance_serving
  - ä¸ºæ¯ä¸ªæµ‹è¯•æ ·ä¾‹åˆ›å»ºä¸€ä¸ªè¿›ç¨‹ï¼Œé—´éš”ä¸€å®šæ—¶é—´ä¾æ¬¡å¯åŠ¨ä»¥æ¨¡æ‹Ÿæ­£å¸¸ä¸šåŠ¡ç¯å¢ƒä¸‹çš„è¯·æ±‚å‘é€åºåˆ—
```


### å®éªŒæ“ä½œï¼šç¯å¢ƒæ„å»º & æµ‹è¯•æµç¨‹

> ğŸ‰ æˆ‘ä»¬å·²ç»é­”æ”¹äº†ä»£ç ï¼Œå¯ä»¥å…¼å®¹æ”¯æŒåœ¨ äº‘ç«¯Linux+Ascend æˆ– æœ¬åœ°Windows+CPU ä¸¤ä¸ªç¯å¢ƒä¸‹è·‘ :)

> æ¨ç†ä¼˜åŒ–çš„ä¸»è¦ä¿®æ”¹ç›®æ ‡: llm-serving > mindformers > mindspore > performance_serving
> *) æˆ‘ä»¬åˆ é™¤äº† performance_serving ä¸­éƒ¨åˆ†å†—ä½™æ— ç”¨çš„ä»£ç é€»è¾‘ï¼Œå¯èƒ½ä¼šå¯¼è‡´è¯„åˆ†ç•¥å¾®åé«˜ï¼›ä½†ä¸»åŠæ–¹æ ¡éªŒæ—¶å¯ä»¥ç”¨åŸrepoæ¥æµ‹ï¼Œæ¥å£æ˜¯å…¼å®¹çš„

âšª ä¸¤ä¸ªç¯å¢ƒçš„åŒºåˆ«

```
è½¯ç¡¬ä»¶ç¯å¢ƒä¸åŒ:
- æœ¬åœ°: Windows + CPU (32G RAM)
- äº‘ç«¯: Linux + Ascend 
  - CPU: Kunpeng-920, 192 core (4 sockets * 48 core-per-socket), 192G RAM; aarch64
  - NPU: Ascend-910b4, 32G HBM
ä½¿ç”¨çš„é…ç½®æ–‡ä»¶ä¸åŒ:
- æœ¬åœ°
  - llm-serving\configs\llama\llama_7b_kbk_pa_dyn_debug.yaml
  - mindformers\configs\llama2\predict_llama2_7b_debug.yaml
- äº‘ç«¯
  - llm-serving\configs\llama\llama_7b_kbk_pa_dyn.yaml
  - mindformers\configs\llama2\predict_llama2_7b.yaml
```

#### æœ¬åœ° (æ‰“æ¡©è°ƒè¯•)

> æ‰“æ¡©è°ƒè¯•ä¸éœ€è¦ä¸‹è½½ç¬¨é‡çš„ llama2_7b.ckpt ä¹Ÿå¯ä»¥è¿›è¡Œ ;)

âšª å®‰è£…

- `conda create -n llm python==3.9.19`
- `conda activate llm`
- `pip install -r requirements.txt`
- è·‘è„šæœ¬ `material\download.cmd`
  - æŠŠ `material\file_npy_base.zip` è§£å‹åˆ° `.\file_npy_base\`
  - å…³äº llama2_7b.ckpt å’Œ tokenizer.model çš„å¤„ç†ï¼Œè¯·å‚è€ƒæ³¨é‡Š
  - å…¶ä»–èµ„æºç›®å‰çœ‹æ¥ä¸ç”¨ä¸‹è½½ï¼Œåº”è¯¥éƒ½å·²ç»åµŒå…¥æœ¬ä»“åº“äº†

âšª å®éªŒ

- å¯åŠ¨å‘½ä»¤è¡Œç¯å¢ƒ `init.cmd`
- å‚è€ƒ `run.cmd` å’Œ [experiments](./experiments/) ç›®å½•


#### äº‘ä¸Š (å®æµ‹)

âšª å®‰è£…

- overwrite `llm-serving`, `mindformers` and `performance_serving` with this repo's modified version

âšª å®éªŒ

â„¹ å¦å¤–å‚è€ƒ [run.sh](./run.sh)

- åˆå§‹åŒ–å‘½ä»¤è¡Œç¯å¢ƒ (âš  äº‘å®éªŒç¯å¢ƒä¸ä¿å­˜ç³»ç»ŸçŠ¶æ€ï¼Œæ¯æ¬¡éƒ½è¦é‡è£…åŒ…)
  - `source ./init.sh`
- å¯åŠ¨ llm-serving æœåŠ¡
  - `cd /home/ma-user/work/llm-serving/`
  - `python examples/start.py --task 1 --config /home/ma-user/work/llm-serving/configs/llama/llama_7b_kbk_pa_dyn.yaml`
- é€Ÿåº¦æµ‹è¯•: æµ‹æ•°æ®é›† [performance_serving/alpaca_5010.json](performance_serving/alpaca_5010.json) å‰ 1500 ä¸ªæ ·æœ¬çš„æ¨ç†æ—¶é•¿
  - `cd /home/ma-user/work/performance_serving/`
  - `python test_serving_performance.py --task 1 -X 0.5 -T 3000`
  - åŸºå‡†è®¾ç½®: -X 0.5 -T 3000, æ¨ç†æ—¶é—´: 3551.9252s (âš  å¿…é¡»ä¿è¯ -X ä¹˜ä»¥ -T ç­‰äº 1500ï¼Œå¯è‡ªè¡Œæ”¹åŠ¨)
- ç²¾åº¦æµ‹è¯•: æµ‹æ•°æ®é›† [performance_serving/alpaca_521.json](performance_serving/alpaca_521.json) å‰ 500 ä¸ªæ ·æœ¬çš„æ¨ç† logits ç»“æœ
  - `cd /home/ma-user/work/performance_serving/`
  - `python test_serving_performance.py --task 2 -X 0.1 -T 5000`
    - âš  æ­¤å¤„ `-X 0.1 -T 5000` ä¸ºå›ºå®šçš„ç«èµ›è®¾ç½®ä¸å¯æ”¹åŠ¨
  - logits æ ¡éªŒ: `python acc_allclose.py --base_path /home/ma-user/work/file_npy_base --new_path /home/ma-user/work/file_npy`


----
by Armit
2024/06/11 
